[0m12:20:16.383004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109283620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbf3890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bbf3b10>]}


============================== 12:20:16.385057 | 72a5869d-eae3-4807-86b9-8af64a586f3a ==============================
[0m12:20:16.385057 [info ] [MainThread]: Running with dbt=1.10.9
[0m12:20:16.385286 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'log_path': 'logs', 'printer_width': '80', 'use_colors': 'True', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'cache_selected_only': 'False', 'fail_fast': 'False', 'invocation_command': 'dbt init flights_dbt', 'quiet': 'False', 'no_print': 'None', 'empty': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'target_path': 'None', 'write_json': 'True', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'static_parser': 'True', 'use_experimental_parser': 'False', 'profiles_dir': '/Users/artakerqeli/.dbt'}
[0m12:20:16.390922 [debug] [MainThread]: Starter project path: /Users/artakerqeli/flights_dbt/.venv/lib/python3.13/site-packages/dbt/include/starter_project
[0m12:20:16.392711 [info ] [MainThread]: 
Your new dbt project "flights_dbt" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m12:20:16.392820 [info ] [MainThread]: Setting up your profile.
[0m12:20:25.238490 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m12:20:25.238681 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m12:20:25.238775 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m12:22:31.760356 [info ] [MainThread]: Profile flights_dbt written to /Users/artakerqeli/.dbt/profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m12:22:31.813875 [debug] [MainThread]: Resource report: {"command_name": "init", "command_success": true, "command_wall_clock_time": 135.46425, "process_in_blocks": "0", "process_kernel_time": 0.313243, "process_mem_max_rss": "200146944", "process_out_blocks": "0", "process_user_time": 1.318812}
[0m12:22:31.815689 [debug] [MainThread]: Command `dbt init` succeeded at 12:22:31.815430 after 135.47 seconds
[0m12:22:31.816257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bce4180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d682570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c13f680>]}
[0m12:22:31.816590 [debug] [MainThread]: Flushing usage events
[0m12:22:32.455755 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:56:08.109362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061a3620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071b7890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071b7b10>]}


============================== 20:56:08.111754 | aa730190-e693-491f-9aaa-1df4519d4f0c ==============================
[0m20:56:08.111754 [info ] [MainThread]: Running with dbt=1.10.9
[0m20:56:08.112004 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'warn_error': 'None', 'printer_width': '80', 'partial_parse': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt run', 'fail_fast': 'False', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'introspect': 'True', 'target_path': 'None', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'False', 'version_check': 'True', 'log_format': 'default', 'debug': 'False', 'write_json': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'static_parser': 'True', 'profiles_dir': '/Users/artakerqeli/.dbt'}
[0m20:56:08.497000 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m20:56:08.497476 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m20:56:08.497883 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m20:56:09.157220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064e7360>]}
[0m20:56:09.176584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1083bead0>]}
[0m20:56:09.176832 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m20:56:09.231571 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m20:56:09.292183 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m20:56:09.292485 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/example/my_first_dbt_model.sql
[0m20:56:09.427267 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m20:56:09.432352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9d5150>]}
[0m20:56:09.470745 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m20:56:09.471696 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m20:56:09.477312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e10b890>]}
[0m20:56:09.477472 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m20:56:09.477569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e311fd0>]}
[0m20:56:09.478465 [info ] [MainThread]: 
[0m20:56:09.478634 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:56:09.478732 [info ] [MainThread]: 
[0m20:56:09.478943 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:56:09.479040 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:56:09.481664 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m20:56:09.481767 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m20:56:09.485320 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m20:56:09.485435 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m20:56:09.485530 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:56:10.295678 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c0-d248-1165-9ccd-b6ad23efa63b) - Created
[0m20:56:10.839872 [debug] [ThreadPool]: SQL status: OK in 1.350 seconds
[0m20:56:10.849013 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c0-d248-1165-9ccd-b6ad23efa63b, command-id=01f089c0-d265-1e14-8989-d9e141afae23) - Closing
[0m20:56:10.849546 [debug] [ThreadPool]: On list_flight_db: Close
[0m20:56:10.849775 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c0-d248-1165-9ccd-b6ad23efa63b) - Closing
[0m20:56:11.056224 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m20:56:11.056814 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m20:56:11.071384 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m20:56:11.071777 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m20:56:11.072022 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:56:11.855362 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c0-d338-15ef-8809-eef438f91f30) - Created
[0m20:56:12.405598 [debug] [ThreadPool]: SQL status: OK in 1.330 seconds
[0m20:56:12.410305 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c0-d338-15ef-8809-eef438f91f30, command-id=01f089c0-d353-1ad1-b060-983102c98898) - Closing
[0m20:56:12.411351 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m20:56:12.411657 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c0-d338-15ef-8809-eef438f91f30) - Closing
[0m20:56:12.602942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb32c30>]}
[0m20:56:12.607848 [debug] [Thread-3 (]: Began running node model.flights_dbt.bronze_flights
[0m20:56:12.608309 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airlines
[0m20:56:12.608639 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_airports
[0m20:56:12.608927 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m20:56:12.609521 [info ] [Thread-3 (]: 3 of 10 START sql view model raw.bronze_flights ................................ [RUN]
[0m20:56:12.609977 [info ] [Thread-1 (]: 1 of 10 START sql view model raw.bronze_airlines ............................... [RUN]
[0m20:56:12.610408 [info ] [Thread-2 (]: 2 of 10 START sql view model raw.bronze_airports ............................... [RUN]
[0m20:56:12.610834 [info ] [Thread-4 (]: 4 of 10 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m20:56:12.611448 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m20:56:12.611862 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airlines) - Creating connection
[0m20:56:12.612222 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m20:56:12.612563 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m20:56:12.612870 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m20:56:12.613192 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airlines'
[0m20:56:12.613434 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m20:56:12.613673 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m20:56:12.613941 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.bronze_flights
[0m20:56:12.614192 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airlines
[0m20:56:12.614415 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_airports
[0m20:56:12.614637 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m20:56:12.623212 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airlines"
[0m20:56:12.625912 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m20:56:12.628307 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m20:56:12.630294 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m20:56:12.631356 [debug] [Thread-3 (]: Began executing node model.flights_dbt.bronze_flights
[0m20:56:12.637459 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airlines
[0m20:56:12.641711 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:56:12.642947 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m20:56:12.644340 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m20:56:12.644519 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_airports
[0m20:56:12.644146 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:56:12.644816 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:56:12.645903 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m20:56:12.647004 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m20:56:12.647203 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e79ad50>]}
[0m20:56:12.647369 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9cc520>]}
[0m20:56:12.647628 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:56:12.647890 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:56:12.655350 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m20:56:12.655833 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airlines`
[0m20:56:12.656003 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ebdd630>]}
[0m20:56:12.656160 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9731d0>]}
[0m20:56:12.660299 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m20:56:12.660631 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airlines"
[0m20:56:12.660977 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m20:56:12.661301 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m20:56:12.661760 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m20:56:12.662097 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m20:56:12.662288 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m20:56:12.662518 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    SELECT
    flight_id,
    origin,
    destination AS dest,  -- or the correct column name
    airline,
    arr_time
FROM `flight_db`.`raw`.`flights`
  )

[0m20:56:12.662654 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:56:12.662847 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airlines"
[0m20:56:12.662992 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view `flight_db`.`raw`.`bronze_airlines` as
select
    airline,
    name,
    country
from `flight_db`.`raw`.`airlines`
  )

[0m20:56:12.663115 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m20:56:12.663315 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m20:56:12.663504 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    dep_time,
    arr_time
  )

[0m20:56:12.663633 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m20:56:12.663791 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m20:56:12.663935 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m20:56:12.664132 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m20:56:13.440533 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c0-d427-1583-8f51-55a8a0589830) - Created
[0m20:56:13.442151 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c0-d426-1fa5-9317-8ca836f39bfe) - Created
[0m20:56:13.443517 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c0-d426-1fa5-9a87-8a387ce10104) - Created
[0m20:56:13.444290 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c0-d429-133a-90e3-893e4b768a72) - Created
[0m20:56:13.722581 [debug] [Thread-4 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    dep_time,
    arr_time
  )

: [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column, variable, or function parameter with name `flight_id` cannot be resolved.  SQLSTATE: 42703; line 9 pos 4
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column, variable, or function parameter with name `flight_id` cannot be resolved.  SQLSTATE: 42703; line 9 pos 4
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column, variable, or function parameter with name `flight_id` cannot be resolved.  SQLSTATE: 42703; line 9 pos 4
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c0-d449-1012-872d-35502855d874
[0m20:56:13.723903 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m20:56:13.724303 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c0-d426-1fa5-9317-8ca836f39bfe) - Closing
[0m20:56:13.901863 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view `flight_db`.`raw`.`bronze_airlines` as
select
    airline,
    name,
    country
from `flight_db`.`raw`.`airlines`
  )

: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view `flight_db`.`raw`.`bronze_airlines` as
----^^^
select
    airline,
    name,
    country
from `flight_db`.`raw`.`airlines`
  )

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view `flight_db`.`raw`.`bronze_airlines` as
----^^^
select
    airline,
    name,
    country
from `flight_db`.`raw`.`airlines`
  )

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view `flight_db`.`raw`.`bronze_airlines` as
----^^^
select
    airline,
    name,
    country
from `flight_db`.`raw`.`airlines`
  )

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:117)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:153)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:446)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:615)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:246)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:155)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)
	at com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:61)
	at com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:136)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:444)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:440)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:790)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:781)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:569)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:901)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:296)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:896)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f089c0-d448-1d9d-b399-d4f68d50fd5f
[0m20:56:13.923595 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: Close
[0m20:56:13.924662 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c0-d426-1fa5-9a87-8a387ce10104) - Closing
[0m20:56:13.939573 [debug] [Thread-4 (]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column, variable, or function parameter with name `flight_id` cannot be resolved.  SQLSTATE: 42703; line 9 pos 4
  compiled code at target/run/flights_dbt/models/example/my_first_dbt_model.sql
[0m20:56:14.123796 [debug] [Thread-1 (]: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airlines`
    
    as (
      create or replace view `flight_db`.`raw`.`bronze_airlines` as
  ----^^^
  select
      airline,
      name,
      country
  from `flight_db`.`raw`.`airlines`
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m20:56:14.124551 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10705b000>]}
[0m20:56:14.124882 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef47070>]}
[0m20:56:14.125471 [error] [Thread-4 (]: 4 of 10 ERROR creating sql view model raw.my_first_dbt_model ................... [[31mERROR[0m in 1.51s]
[0m20:56:14.126526 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m20:56:14.126071 [error] [Thread-1 (]: 1 of 10 ERROR creating sql view model raw.bronze_airlines ...................... [[31mERROR[0m in 1.51s]
[0m20:56:14.126923 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_flights
[0m20:56:14.127256 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.my_first_dbt_model' to be skipped because of status 'error'.  Reason: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column, variable, or function parameter with name `flight_id` cannot be resolved.  SQLSTATE: 42703; line 9 pos 4
  compiled code at target/run/flights_dbt/models/example/my_first_dbt_model.sql.
[0m20:56:14.127640 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airlines
[0m20:56:14.127993 [info ] [Thread-4 (]: 5 of 10 START sql view model raw.silver_flights ................................ [RUN]
[0m20:56:14.129096 [debug] [Thread-1 (]: Began running node model.flights_dbt.stg_airlines
[0m20:56:14.129467 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.bronze_airlines' to be skipped because of status 'error'.  Reason: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airlines`
    
    as (
      create or replace view `flight_db`.`raw`.`bronze_airlines` as
  ----^^^
  select
      airline,
      name,
      country
  from `flight_db`.`raw`.`airlines`
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql.
[0m20:56:14.129892 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m20:56:14.130252 [info ] [Thread-1 (]: 6 of 10 START sql table model raw.stg_airlines ................................. [RUN]
[0m20:56:14.130713 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m20:56:14.131096 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m20:56:14.131345 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_flights
[0m20:56:14.131572 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m20:56:14.133459 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m20:56:14.133780 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.stg_airlines
[0m20:56:14.136854 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m20:56:14.137491 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_flights
[0m20:56:14.138519 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m20:56:14.139310 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m20:56:14.139865 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m20:56:14.140023 [debug] [Thread-1 (]: Began executing node model.flights_dbt.stg_airlines
[0m20:56:14.146968 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m20:56:14.159708 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m20:56:14.159862 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m20:56:14.160054 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    create or replace view `flight_db`.`raw`.`silver_flights` as
select
    f.flight_id,
    f.airline,
    f.origin,
    f.dest,
    f.arr_time
from `flight_db`.`raw`.`flights` f
  )

[0m20:56:14.160255 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m20:56:14.160508 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m20:56:14.160719 [debug] [Thread-1 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m20:56:14.160872 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m20:56:14.606363 [debug] [Thread-2 (]: SQL status: OK in 1.940 seconds
[0m20:56:14.608147 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c0-d427-1583-8f51-55a8a0589830, command-id=01f089c0-d448-168c-8a30-8d6697ad20aa) - Closing
[0m20:56:14.621656 [debug] [Thread-2 (]: Applying tags to relation None
[0m20:56:14.624827 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: Close
[0m20:56:14.625130 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c0-d427-1583-8f51-55a8a0589830) - Closing
[0m20:56:14.626982 [debug] [Thread-3 (]: SQL status: OK in 1.960 seconds
[0m20:56:14.627965 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c0-d429-133a-90e3-893e4b768a72, command-id=01f089c0-d44b-1b8a-afb9-402503a1dd6b) - Closing
[0m20:56:14.628568 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:56:14.820767 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c0-d4fd-1319-ad63-a2faf29059ab) - Created
[0m20:56:14.833415 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: Close
[0m20:56:14.834143 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c0-d429-133a-90e3-893e4b768a72) - Closing
[0m20:56:14.885349 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c0-d504-1d3a-85d8-273ead3898ab) - Created
[0m20:56:15.042557 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb94710>]}
[0m20:56:15.043500 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb95790>]}
[0m20:56:15.044343 [info ] [Thread-2 (]: 2 of 10 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.43s]
[0m20:56:15.044814 [info ] [Thread-3 (]: 3 of 10 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.43s]
[0m20:56:15.045499 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_airports
[0m20:56:15.045912 [debug] [Thread-3 (]: Finished running node model.flights_dbt.bronze_flights
[0m20:56:15.046272 [debug] [Thread-2 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m20:56:15.046668 [debug] [Thread-3 (]: Began running node model.flights_dbt.silver_airlines
[0m20:56:15.047123 [info ] [Thread-2 (]: 7 of 10 SKIP relation raw.my_second_dbt_model .................................. [[33mSKIP[0m]
[0m20:56:15.047489 [info ] [Thread-3 (]: 8 of 10 SKIP relation raw.silver_airlines ...................................... [[33mSKIP[0m]
[0m20:56:15.047782 [debug] [Thread-2 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m20:56:15.048014 [debug] [Thread-3 (]: Finished running node model.flights_dbt.silver_airlines
[0m20:56:15.048259 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_airports
[0m20:56:15.048684 [info ] [Thread-2 (]: 9 of 10 START sql view model raw.silver_airports ............................... [RUN]
[0m20:56:15.049244 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m20:56:15.049622 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m20:56:15.049914 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_airports
[0m20:56:15.063410 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m20:56:15.064032 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_airports
[0m20:56:15.065383 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m20:56:15.066037 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m20:56:15.066487 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m20:56:15.066821 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m20:56:15.067026 [debug] [Thread-2 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m20:56:15.067199 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m20:56:15.222370 [debug] [Thread-4 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    create or replace view `flight_db`.`raw`.`silver_flights` as
select
    f.flight_id,
    f.airline,
    f.origin,
    f.dest,
    f.arr_time
from `flight_db`.`raw`.`flights` f
  )

: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    create or replace view `flight_db`.`raw`.`silver_flights` as
----^^^
select
    f.flight_id,
    f.airline,
    f.origin,
    f.dest,
    f.arr_time
from `flight_db`.`raw`.`flights` f
  )

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    create or replace view `flight_db`.`raw`.`silver_flights` as
----^^^
select
    f.flight_id,
    f.airline,
    f.origin,
    f.dest,
    f.arr_time
from `flight_db`.`raw`.`flights` f
  )

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    create or replace view `flight_db`.`raw`.`silver_flights` as
----^^^
select
    f.flight_id,
    f.airline,
    f.origin,
    f.dest,
    f.arr_time
from `flight_db`.`raw`.`flights` f
  )

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:117)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:153)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:446)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:615)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:246)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:155)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)
	at com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:61)
	at com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:136)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:444)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:440)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:790)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:781)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:569)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:901)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:296)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:896)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f089c0-d517-139d-8ee4-ee355e4d9db2
[0m20:56:15.223814 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: Close
[0m20:56:15.224186 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c0-d4fd-1319-ad63-a2faf29059ab) - Closing
[0m20:56:15.424107 [debug] [Thread-4 (]: Database Error in model silver_flights (models/silver/silver_flights.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */
  
    
    
    create or replace view `flight_db`.`raw`.`silver_flights`
    
    as (
      create or replace view `flight_db`.`raw`.`silver_flights` as
  ----^^^
  select
      f.flight_id,
      f.airline,
      f.origin,
      f.dest,
      f.arr_time
  from `flight_db`.`raw`.`flights` f
    )
  
  compiled code at target/run/flights_dbt/models/silver/silver_flights.sql
[0m20:56:15.424620 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea773b0>]}
[0m20:56:15.425150 [error] [Thread-4 (]: 5 of 10 ERROR creating sql view model raw.silver_flights ....................... [[31mERROR[0m in 1.29s]
[0m20:56:15.425578 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_flights
[0m20:56:15.425931 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.silver_flights' to be skipped because of status 'error'.  Reason: Database Error in model silver_flights (models/silver/silver_flights.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */
  
    
    
    create or replace view `flight_db`.`raw`.`silver_flights`
    
    as (
      create or replace view `flight_db`.`raw`.`silver_flights` as
  ----^^^
  select
      f.flight_id,
      f.airline,
      f.origin,
      f.dest,
      f.arr_time
  from `flight_db`.`raw`.`flights` f
    )
  
  compiled code at target/run/flights_dbt/models/silver/silver_flights.sql.
[0m20:56:15.725333 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c0-d587-165f-a953-0c69cc4b66e2) - Created
[0m20:56:16.419453 [debug] [Thread-2 (]: SQL status: OK in 1.350 seconds
[0m20:56:16.421069 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c0-d587-165f-a953-0c69cc4b66e2, command-id=01f089c0-d5a6-1340-adab-18d56a9137c6) - Closing
[0m20:56:16.422036 [debug] [Thread-2 (]: Applying tags to relation None
[0m20:56:16.423044 [debug] [Thread-2 (]: On model.flights_dbt.silver_airports: Close
[0m20:56:16.423370 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c0-d587-165f-a953-0c69cc4b66e2) - Closing
[0m20:56:16.622401 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef8be30>]}
[0m20:56:16.624263 [info ] [Thread-2 (]: 9 of 10 OK created sql view model raw.silver_airports .......................... [[32mOK[0m in 1.57s]
[0m20:56:16.625051 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_airports
[0m20:56:16.625666 [debug] [Thread-3 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m20:56:16.626055 [info ] [Thread-3 (]: 10 of 10 SKIP relation raw.gold_flight_metrics ................................. [[33mSKIP[0m]
[0m20:56:16.626385 [debug] [Thread-3 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m20:56:17.263642 [debug] [Thread-1 (]: SQL status: OK in 3.100 seconds
[0m20:56:17.265192 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c0-d504-1d3a-85d8-273ead3898ab, command-id=01f089c0-d523-135c-9910-bb4ff4f84f13) - Closing
[0m20:56:17.269851 [debug] [Thread-1 (]: Applying tags to relation None
[0m20:56:17.289623 [debug] [Thread-1 (]: On model.flights_dbt.stg_airlines: Close
[0m20:56:17.289967 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c0-d504-1d3a-85d8-273ead3898ab) - Closing
[0m20:56:17.498027 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa730190-e693-491f-9aaa-1df4519d4f0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea77bf0>]}
[0m20:56:17.499690 [info ] [Thread-1 (]: 6 of 10 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.37s]
[0m20:56:17.500516 [debug] [Thread-1 (]: Finished running node model.flights_dbt.stg_airlines
[0m20:56:17.502509 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:56:17.502886 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:56:17.503445 [info ] [MainThread]: 
[0m20:56:17.503780 [info ] [MainThread]: Finished running 2 table models, 8 view models in 0 hours 0 minutes and 8.02 seconds (8.02s).
[0m20:56:17.505457 [debug] [MainThread]: Command end result
[0m20:56:17.533319 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m20:56:17.534651 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m20:56:17.538773 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m20:56:17.538951 [info ] [MainThread]: 
[0m20:56:17.539138 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m20:56:17.539277 [info ] [MainThread]: 
[0m20:56:17.539520 [error] [MainThread]: [31mFailure in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
[0m20:56:17.539718 [error] [MainThread]:   Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  [UNRESOLVED_COLUMN.WITHOUT_SUGGESTION] A column, variable, or function parameter with name `flight_id` cannot be resolved.  SQLSTATE: 42703; line 9 pos 4
  compiled code at target/run/flights_dbt/models/example/my_first_dbt_model.sql
[0m20:56:17.539835 [info ] [MainThread]: 
[0m20:56:17.540083 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/example/my_first_dbt_model.sql
[0m20:56:17.540243 [info ] [MainThread]: 
[0m20:56:17.540395 [error] [MainThread]: [31mFailure in model bronze_airlines (models/bronze/bronze_airlines.sql)[0m
[0m20:56:17.540630 [error] [MainThread]:   Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airlines`
    
    as (
      create or replace view `flight_db`.`raw`.`bronze_airlines` as
  ----^^^
  select
      airline,
      name,
      country
  from `flight_db`.`raw`.`airlines`
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m20:56:17.540805 [info ] [MainThread]: 
[0m20:56:17.540963 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/bronze/bronze_airlines.sql
[0m20:56:17.541083 [info ] [MainThread]: 
[0m20:56:17.541243 [error] [MainThread]: [31mFailure in model silver_flights (models/silver/silver_flights.sql)[0m
[0m20:56:17.541397 [error] [MainThread]:   Database Error in model silver_flights (models/silver/silver_flights.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */
  
    
    
    create or replace view `flight_db`.`raw`.`silver_flights`
    
    as (
      create or replace view `flight_db`.`raw`.`silver_flights` as
  ----^^^
  select
      f.flight_id,
      f.airline,
      f.origin,
      f.dest,
      f.arr_time
  from `flight_db`.`raw`.`flights` f
    )
  
  compiled code at target/run/flights_dbt/models/silver/silver_flights.sql
[0m20:56:17.541527 [info ] [MainThread]: 
[0m20:56:17.541711 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/silver/silver_flights.sql
[0m20:56:17.541820 [info ] [MainThread]: 
[0m20:56:17.541955 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=3 SKIP=3 NO-OP=0 TOTAL=10
[0m20:56:17.576242 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 9.498145, "process_in_blocks": "0", "process_kernel_time": 0.295452, "process_mem_max_rss": "244793344", "process_out_blocks": "0", "process_user_time": 2.420001}
[0m20:56:17.576542 [debug] [MainThread]: Command `dbt run` failed at 20:56:17.576490 after 9.50 seconds
[0m20:56:17.576762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10647ab10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10effbf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10effba70>]}
[0m20:56:17.576947 [debug] [MainThread]: Flushing usage events
[0m20:56:18.346901 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:58:25.763184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1184db620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119bfb890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119bfbb10>]}


============================== 20:58:25.765480 | 348d0615-1c0d-41f6-8db1-fe6c8e97598e ==============================
[0m20:58:25.765480 [info ] [MainThread]: Running with dbt=1.10.9
[0m20:58:25.765700 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'invocation_command': 'dbt run', 'cache_selected_only': 'False', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'target_path': 'None', 'quiet': 'False', 'fail_fast': 'False', 'introspect': 'True', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'static_parser': 'True', 'warn_error': 'None', 'printer_width': '80', 'profiles_dir': '/Users/artakerqeli/.dbt', 'log_cache_events': 'False', 'write_json': 'True', 'empty': 'False', 'log_format': 'default', 'indirect_selection': 'eager', 'version_check': 'True', 'partial_parse': 'True'}
[0m20:58:26.067655 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m20:58:26.067850 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m20:58:26.067943 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m20:58:26.503550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118c23360>]}
[0m20:58:26.522745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bb02ad0>]}
[0m20:58:26.522970 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m20:58:26.572604 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m20:58:26.629656 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m20:58:26.629905 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/silver/silver_flights.sql
[0m20:58:26.630037 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/bronze/bronze_airlines.sql
[0m20:58:26.630171 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/example/my_first_dbt_model.sql
[0m20:58:26.767490 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m20:58:26.772351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b3d4f50>]}
[0m20:58:26.807807 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m20:58:26.808899 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m20:58:26.814167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12ab0b890>]}
[0m20:58:26.814325 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m20:58:26.814425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12ad81ef0>]}
[0m20:58:26.815216 [info ] [MainThread]: 
[0m20:58:26.815338 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:58:26.815421 [info ] [MainThread]: 
[0m20:58:26.815599 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:58:26.815694 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:58:26.818229 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m20:58:26.818353 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m20:58:26.821981 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m20:58:26.822109 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m20:58:26.822199 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:58:27.817023 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c1-243b-1423-b1aa-639909422173) - Created
[0m20:58:28.409692 [debug] [ThreadPool]: SQL status: OK in 1.590 seconds
[0m20:58:28.423873 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c1-243b-1423-b1aa-639909422173, command-id=01f089c1-245c-184d-989b-157033c140bd) - Closing
[0m20:58:28.424503 [debug] [ThreadPool]: On list_flight_db: Close
[0m20:58:28.424747 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c1-243b-1423-b1aa-639909422173) - Closing
[0m20:58:28.624121 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m20:58:28.624702 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m20:58:28.638104 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m20:58:28.638456 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m20:58:28.638678 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:58:29.466816 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c1-253d-157e-acff-d0872c6aa774) - Created
[0m20:58:30.047066 [debug] [ThreadPool]: SQL status: OK in 1.410 seconds
[0m20:58:30.050406 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c1-253d-157e-acff-d0872c6aa774, command-id=01f089c1-255c-1705-9546-76d32327bb7f) - Closing
[0m20:58:30.051109 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m20:58:30.051331 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c1-253d-157e-acff-d0872c6aa774) - Closing
[0m20:58:30.245149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b536a90>]}
[0m20:58:30.250109 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_airports
[0m20:58:30.250590 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airlines
[0m20:58:30.250930 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m20:58:30.251227 [debug] [Thread-3 (]: Began running node model.flights_dbt.bronze_flights
[0m20:58:30.251809 [info ] [Thread-2 (]: 2 of 10 START sql view model raw.bronze_airports ............................... [RUN]
[0m20:58:30.252295 [info ] [Thread-1 (]: 1 of 10 START sql view model raw.bronze_airlines ............................... [RUN]
[0m20:58:30.252760 [info ] [Thread-4 (]: 4 of 10 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m20:58:30.253230 [info ] [Thread-3 (]: 3 of 10 START sql view model raw.bronze_flights ................................ [RUN]
[0m20:58:30.253898 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m20:58:30.254343 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airlines) - Creating connection
[0m20:58:30.254732 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m20:58:30.255074 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m20:58:30.255348 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m20:58:30.255598 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airlines'
[0m20:58:30.255835 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m20:58:30.256074 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m20:58:30.256330 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_airports
[0m20:58:30.256578 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airlines
[0m20:58:30.256809 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m20:58:30.257032 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.bronze_flights
[0m20:58:30.266169 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airlines"
[0m20:58:30.268793 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m20:58:30.270675 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m20:58:30.272832 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m20:58:30.273948 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_airports
[0m20:58:30.274232 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airlines
[0m20:58:30.274424 [debug] [Thread-3 (]: Began executing node model.flights_dbt.bronze_flights
[0m20:58:30.274602 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m20:58:30.283664 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m20:58:30.284907 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m20:58:30.285907 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:58:30.287019 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m20:58:30.288096 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:58:30.288361 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:58:30.288591 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:58:30.288812 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:58:30.289022 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b01eed0>]}
[0m20:58:30.289165 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b50c680>]}
[0m20:58:30.289306 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b50c5d0>]}
[0m20:58:30.289433 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b5dc910>]}
[0m20:58:30.296392 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m20:58:30.296826 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airlines`
[0m20:58:30.297184 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m20:58:30.297528 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m20:58:30.301715 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m20:58:30.302044 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airlines"
[0m20:58:30.302338 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m20:58:30.302625 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m20:58:30.303116 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airlines"
[0m20:58:30.303243 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m20:58:30.303436 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    -- models/bronze/bronze_airlines.sql

create or replace view `flight_db`.`raw`.`bronze_airlines` as
select
    airline,
    name,
    country
from `flight_db`.`raw`.`airlines`
  )

[0m20:58:30.303592 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m20:58:30.303770 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m20:58:30.303940 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m20:58:30.304056 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m20:58:30.304208 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    SELECT
    flight_id,
    origin,
    destination AS dest,  -- or the correct column name
    airline,
    arr_time
FROM `flight_db`.`raw`.`flights`
  )

[0m20:58:30.304346 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m20:58:30.304567 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    -- models/example/my_first_dbt_model.sql

select
    airline,
    origin,
    dest,
    dep_time,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m20:58:30.304741 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:58:30.304917 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m20:58:31.405108 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c1-2663-1c29-93ee-3647ed2f0983) - Created
[0m20:58:31.406720 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c1-2663-1177-9ea5-cd1eac21c968) - Created
[0m20:58:31.410105 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c1-2664-1c3d-b8a5-9a70a13d34e2) - Created
[0m20:58:31.648640 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c1-2689-1c73-a8d2-d27aaff6c12a) - Created
[0m20:58:31.747149 [debug] [Thread-4 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    -- models/example/my_first_dbt_model.sql

select
    airline,
    origin,
    dest,
    dep_time,
    arr_time
from `flight_db`.`raw`.`flights`
  )

: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `dest` cannot be resolved. Did you mean one of the following? [`dep_time`, `origin`, `airline`, `arr_delay`, `arr_time`]. SQLSTATE: 42703; line 13 pos 4
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `dest` cannot be resolved. Did you mean one of the following? [`dep_time`, `origin`, `airline`, `arr_delay`, `arr_time`]. SQLSTATE: 42703; line 13 pos 4
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `dest` cannot be resolved. Did you mean one of the following? [`dep_time`, `origin`, `airline`, `arr_delay`, `arr_time`]. SQLSTATE: 42703; line 13 pos 4
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c1-2680-1400-8cf2-893e6cbc348b
[0m20:58:31.748443 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m20:58:31.748737 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c1-2663-1177-9ea5-cd1eac21c968) - Closing
[0m20:58:31.952567 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    -- models/bronze/bronze_airlines.sql

create or replace view `flight_db`.`raw`.`bronze_airlines` as
select
    airline,
    name,
    country
from `flight_db`.`raw`.`airlines`
  )

: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    -- models/bronze/bronze_airlines.sql

create or replace view `flight_db`.`raw`.`bronze_airlines` as
^^^
select
    airline,
    name,
    country
from `flight_db`.`raw`.`airlines`
  )

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    -- models/bronze/bronze_airlines.sql

create or replace view `flight_db`.`raw`.`bronze_airlines` as
^^^
select
    airline,
    name,
    country
from `flight_db`.`raw`.`airlines`
  )

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    -- models/bronze/bronze_airlines.sql

create or replace view `flight_db`.`raw`.`bronze_airlines` as
^^^
select
    airline,
    name,
    country
from `flight_db`.`raw`.`airlines`
  )

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:117)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:153)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:446)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:615)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:246)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:155)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)
	at com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:61)
	at com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:136)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:444)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:440)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:790)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:781)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:569)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:901)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:296)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:896)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f089c1-2689-1f43-96a2-224102003471
[0m20:58:31.956410 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: Close
[0m20:58:31.956921 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c1-2664-1c3d-b8a5-9a70a13d34e2) - Closing
[0m20:58:31.969094 [debug] [Thread-4 (]: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `dest` cannot be resolved. Did you mean one of the following? [`dep_time`, `origin`, `airline`, `arr_delay`, `arr_time`]. SQLSTATE: 42703; line 13 pos 4
  compiled code at target/run/flights_dbt/models/example/my_first_dbt_model.sql
[0m20:58:32.074485 [debug] [Thread-2 (]: SQL status: OK in 1.770 seconds
[0m20:58:32.076014 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c1-2663-1c29-93ee-3647ed2f0983, command-id=01f089c1-2680-15a9-a522-7f5646cd3691) - Closing
[0m20:58:32.089430 [debug] [Thread-2 (]: Applying tags to relation None
[0m20:58:32.172375 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: Close
[0m20:58:32.173291 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c1-2663-1c29-93ee-3647ed2f0983) - Closing
[0m20:58:32.179074 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12d98add0>]}
[0m20:58:32.180237 [debug] [Thread-1 (]: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airlines`
    
    as (
      -- models/bronze/bronze_airlines.sql
  
  create or replace view `flight_db`.`raw`.`bronze_airlines` as
  ^^^
  select
      airline,
      name,
      country
  from `flight_db`.`raw`.`airlines`
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m20:58:32.181127 [error] [Thread-4 (]: 4 of 10 ERROR creating sql view model raw.my_first_dbt_model ................... [[31mERROR[0m in 1.92s]
[0m20:58:32.181774 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m20:58:32.182167 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_flights
[0m20:58:32.182595 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.my_first_dbt_model' to be skipped because of status 'error'.  Reason: Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `dest` cannot be resolved. Did you mean one of the following? [`dep_time`, `origin`, `airline`, `arr_delay`, `arr_time`]. SQLSTATE: 42703; line 13 pos 4
  compiled code at target/run/flights_dbt/models/example/my_first_dbt_model.sql.
[0m20:58:32.183000 [info ] [Thread-4 (]: 5 of 10 START sql view model raw.silver_flights ................................ [RUN]
[0m20:58:32.280093 [debug] [Thread-3 (]: SQL status: OK in 1.970 seconds
[0m20:58:32.281790 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c1-2689-1c73-a8d2-d27aaff6c12a, command-id=01f089c1-26a7-10ce-b4b6-d01b7917d67f) - Closing
[0m20:58:32.282676 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:58:32.364458 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12d91e150>]}
[0m20:58:32.365280 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m20:58:32.365692 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: Close
[0m20:58:32.366869 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m20:58:32.366539 [error] [Thread-1 (]: 1 of 10 ERROR creating sql view model raw.bronze_airlines ...................... [[31mERROR[0m in 2.11s]
[0m20:58:32.367337 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c1-2689-1c73-a8d2-d27aaff6c12a) - Closing
[0m20:58:32.367685 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_flights
[0m20:58:32.368190 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airlines
[0m20:58:32.371706 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m20:58:32.372347 [debug] [Thread-1 (]: Began running node model.flights_dbt.stg_airlines
[0m20:58:32.372875 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.bronze_airlines' to be skipped because of status 'error'.  Reason: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airlines`
    
    as (
      -- models/bronze/bronze_airlines.sql
  
  create or replace view `flight_db`.`raw`.`bronze_airlines` as
  ^^^
  select
      airline,
      name,
      country
  from `flight_db`.`raw`.`airlines`
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql.
[0m20:58:32.373491 [info ] [Thread-1 (]: 6 of 10 START sql table model raw.stg_airlines ................................. [RUN]
[0m20:58:32.374710 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_flights
[0m20:58:32.378057 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m20:58:32.379153 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m20:58:32.380012 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m20:58:32.576038 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12d936390>]}
[0m20:58:32.576824 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m20:58:32.577166 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m20:58:32.577707 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12afe8c50>]}
[0m20:58:32.578743 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m20:58:32.578408 [info ] [Thread-2 (]: 2 of 10 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.32s]
[0m20:58:32.579247 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    -- models/silver/silver_flights.sql

create or replace view `flight_db`.`raw`.`silver_flights` as
select
    airline,
    origin,
    dest,
    dep_time,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m20:58:32.580173 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.stg_airlines
[0m20:58:32.579887 [info ] [Thread-3 (]: 3 of 10 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.32s]
[0m20:58:32.580742 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_airports
[0m20:58:32.581059 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m20:58:32.585349 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m20:58:32.585856 [debug] [Thread-3 (]: Finished running node model.flights_dbt.bronze_flights
[0m20:58:32.586209 [debug] [Thread-2 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m20:58:32.587029 [debug] [Thread-3 (]: Began running node model.flights_dbt.silver_airlines
[0m20:58:32.587542 [info ] [Thread-2 (]: 7 of 10 SKIP relation raw.my_second_dbt_model .................................. [[33mSKIP[0m]
[0m20:58:32.587877 [info ] [Thread-3 (]: 8 of 10 SKIP relation raw.silver_airlines ...................................... [[33mSKIP[0m]
[0m20:58:32.588218 [debug] [Thread-2 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m20:58:32.588494 [debug] [Thread-3 (]: Finished running node model.flights_dbt.silver_airlines
[0m20:58:32.588823 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_airports
[0m20:58:32.589559 [debug] [Thread-1 (]: Began executing node model.flights_dbt.stg_airlines
[0m20:58:32.589331 [info ] [Thread-2 (]: 9 of 10 START sql view model raw.silver_airports ............................... [RUN]
[0m20:58:32.605794 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m20:58:32.606178 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m20:58:32.606402 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m20:58:32.618877 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_airports
[0m20:58:32.626975 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m20:58:32.631761 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m20:58:32.631971 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m20:58:32.632147 [debug] [Thread-1 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m20:58:32.632283 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m20:58:32.632415 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_airports
[0m20:58:32.633351 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m20:58:32.633841 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m20:58:32.634149 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m20:58:32.634358 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m20:58:32.634498 [debug] [Thread-2 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m20:58:32.634620 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m20:58:33.275431 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c1-2783-1a1b-8147-ac1621ea3dd0) - Created
[0m20:58:33.284538 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c1-2784-1410-a563-a92f7951f1be) - Created
[0m20:58:33.304457 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c1-2787-1a85-b199-7e949d258fd6) - Created
[0m20:58:33.764102 [debug] [Thread-4 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    -- models/silver/silver_flights.sql

create or replace view `flight_db`.`raw`.`silver_flights` as
select
    airline,
    origin,
    dest,
    dep_time,
    arr_time
from `flight_db`.`raw`.`flights`
  )

: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    -- models/silver/silver_flights.sql

create or replace view `flight_db`.`raw`.`silver_flights` as
^^^
select
    airline,
    origin,
    dest,
    dep_time,
    arr_time
from `flight_db`.`raw`.`flights`
  )

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    -- models/silver/silver_flights.sql

create or replace view `flight_db`.`raw`.`silver_flights` as
^^^
select
    airline,
    origin,
    dest,
    dep_time,
    arr_time
from `flight_db`.`raw`.`flights`
  )

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    -- models/silver/silver_flights.sql

create or replace view `flight_db`.`raw`.`silver_flights` as
^^^
select
    airline,
    origin,
    dest,
    dep_time,
    arr_time
from `flight_db`.`raw`.`flights`
  )

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:117)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:153)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:446)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:615)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:246)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:155)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)
	at com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:61)
	at com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:136)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:444)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:440)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:790)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:781)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:569)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:901)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:296)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:896)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f089c1-279f-1385-98fb-7bb5201ba647
[0m20:58:33.765729 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: Close
[0m20:58:33.766099 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c1-2783-1a1b-8147-ac1621ea3dd0) - Closing
[0m20:58:33.966072 [debug] [Thread-4 (]: Database Error in model silver_flights (models/silver/silver_flights.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */
  
    
    
    create or replace view `flight_db`.`raw`.`silver_flights`
    
    as (
      -- models/silver/silver_flights.sql
  
  create or replace view `flight_db`.`raw`.`silver_flights` as
  ^^^
  select
      airline,
      origin,
      dest,
      dep_time,
      arr_time
  from `flight_db`.`raw`.`flights`
    )
  
  compiled code at target/run/flights_dbt/models/silver/silver_flights.sql
[0m20:58:33.967060 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b04c650>]}
[0m20:58:33.967870 [error] [Thread-4 (]: 5 of 10 ERROR creating sql view model raw.silver_flights ....................... [[31mERROR[0m in 1.78s]
[0m20:58:33.968390 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_flights
[0m20:58:33.968860 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.silver_flights' to be skipped because of status 'error'.  Reason: Database Error in model silver_flights (models/silver/silver_flights.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */
  
    
    
    create or replace view `flight_db`.`raw`.`silver_flights`
    
    as (
      -- models/silver/silver_flights.sql
  
  create or replace view `flight_db`.`raw`.`silver_flights` as
  ^^^
  select
      airline,
      origin,
      dest,
      dep_time,
      arr_time
  from `flight_db`.`raw`.`flights`
    )
  
  compiled code at target/run/flights_dbt/models/silver/silver_flights.sql.
[0m20:58:34.047818 [debug] [Thread-2 (]: SQL status: OK in 1.410 seconds
[0m20:58:34.049945 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c1-2787-1a85-b199-7e949d258fd6, command-id=01f089c1-27a4-136a-a001-79781ceee403) - Closing
[0m20:58:34.050795 [debug] [Thread-2 (]: Applying tags to relation None
[0m20:58:34.051580 [debug] [Thread-2 (]: On model.flights_dbt.silver_airports: Close
[0m20:58:34.051884 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c1-2787-1a85-b199-7e949d258fd6) - Closing
[0m20:58:34.242380 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12ad255b0>]}
[0m20:58:34.244070 [info ] [Thread-2 (]: 9 of 10 OK created sql view model raw.silver_airports .......................... [[32mOK[0m in 1.64s]
[0m20:58:34.245165 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_airports
[0m20:58:34.246206 [debug] [Thread-3 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m20:58:34.246727 [info ] [Thread-3 (]: 10 of 10 SKIP relation raw.gold_flight_metrics ................................. [[33mSKIP[0m]
[0m20:58:34.247134 [debug] [Thread-3 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m20:58:35.560380 [debug] [Thread-1 (]: SQL status: OK in 2.930 seconds
[0m20:58:35.563005 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c1-2784-1410-a563-a92f7951f1be, command-id=01f089c1-279f-1139-9ee5-b0fccb206b0c) - Closing
[0m20:58:35.568651 [debug] [Thread-1 (]: Applying tags to relation None
[0m20:58:35.586215 [debug] [Thread-1 (]: On model.flights_dbt.stg_airlines: Close
[0m20:58:35.586532 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c1-2784-1410-a563-a92f7951f1be) - Closing
[0m20:58:35.815228 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '348d0615-1c0d-41f6-8db1-fe6c8e97598e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12ace8770>]}
[0m20:58:35.816906 [info ] [Thread-1 (]: 6 of 10 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.44s]
[0m20:58:35.817718 [debug] [Thread-1 (]: Finished running node model.flights_dbt.stg_airlines
[0m20:58:35.819775 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:58:35.820113 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:58:35.820681 [info ] [MainThread]: 
[0m20:58:35.821004 [info ] [MainThread]: Finished running 2 table models, 8 view models in 0 hours 0 minutes and 9.01 seconds (9.01s).
[0m20:58:35.822595 [debug] [MainThread]: Command end result
[0m20:58:35.853902 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m20:58:35.855490 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m20:58:35.859728 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m20:58:35.859882 [info ] [MainThread]: 
[0m20:58:35.860067 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m20:58:35.860201 [info ] [MainThread]: 
[0m20:58:35.860382 [error] [MainThread]: [31mFailure in model my_first_dbt_model (models/example/my_first_dbt_model.sql)[0m
[0m20:58:35.860542 [error] [MainThread]:   Database Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `dest` cannot be resolved. Did you mean one of the following? [`dep_time`, `origin`, `airline`, `arr_delay`, `arr_time`]. SQLSTATE: 42703; line 13 pos 4
  compiled code at target/run/flights_dbt/models/example/my_first_dbt_model.sql
[0m20:58:35.860656 [info ] [MainThread]: 
[0m20:58:35.860788 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/example/my_first_dbt_model.sql
[0m20:58:35.860896 [info ] [MainThread]: 
[0m20:58:35.861027 [error] [MainThread]: [31mFailure in model bronze_airlines (models/bronze/bronze_airlines.sql)[0m
[0m20:58:35.861180 [error] [MainThread]:   Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airlines`
    
    as (
      -- models/bronze/bronze_airlines.sql
  
  create or replace view `flight_db`.`raw`.`bronze_airlines` as
  ^^^
  select
      airline,
      name,
      country
  from `flight_db`.`raw`.`airlines`
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m20:58:35.861298 [info ] [MainThread]: 
[0m20:58:35.861423 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/bronze/bronze_airlines.sql
[0m20:58:35.861522 [info ] [MainThread]: 
[0m20:58:35.861651 [error] [MainThread]: [31mFailure in model silver_flights (models/silver/silver_flights.sql)[0m
[0m20:58:35.861800 [error] [MainThread]:   Database Error in model silver_flights (models/silver/silver_flights.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */
  
    
    
    create or replace view `flight_db`.`raw`.`silver_flights`
    
    as (
      -- models/silver/silver_flights.sql
  
  create or replace view `flight_db`.`raw`.`silver_flights` as
  ^^^
  select
      airline,
      origin,
      dest,
      dep_time,
      arr_time
  from `flight_db`.`raw`.`flights`
    )
  
  compiled code at target/run/flights_dbt/models/silver/silver_flights.sql
[0m20:58:35.861916 [info ] [MainThread]: 
[0m20:58:35.862037 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/silver/silver_flights.sql
[0m20:58:35.862141 [info ] [MainThread]: 
[0m20:58:35.862348 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=3 SKIP=3 NO-OP=0 TOTAL=10
[0m20:58:35.865567 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 10.132947, "process_in_blocks": "0", "process_kernel_time": 0.2662, "process_mem_max_rss": "248545280", "process_out_blocks": "0", "process_user_time": 2.275523}
[0m20:58:35.865828 [debug] [MainThread]: Command `dbt run` failed at 20:58:35.865777 after 10.13 seconds
[0m20:58:35.866012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1186033b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b1bd310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12db07d10>]}
[0m20:58:35.866164 [debug] [MainThread]: Flushing usage events
[0m20:58:36.916984 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:03:13.284937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10624b620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077ff890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077ffb10>]}


============================== 21:03:13.287226 | 4d7429e4-dbd2-4f00-b98e-382b376c2c05 ==============================
[0m21:03:13.287226 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:03:13.287470 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'version_check': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'static_parser': 'True', 'profiles_dir': '/Users/artakerqeli/.dbt', 'quiet': 'False', 'indirect_selection': 'eager', 'no_print': 'None', 'invocation_command': 'dbt build', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'write_json': 'True', 'debug': 'False', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'empty': 'False', 'introspect': 'True', 'warn_error': 'None', 'fail_fast': 'False', 'printer_width': '80', 'target_path': 'None'}
[0m21:03:13.587874 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:03:13.588066 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:03:13.588164 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:03:14.045787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106753360>]}
[0m21:03:14.064932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10970aad0>]}
[0m21:03:14.065160 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:03:14.143864 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:03:14.206787 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m21:03:14.207069 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/example/my_first_dbt_model.sql
[0m21:03:14.207197 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/bronze/bronze_airlines.sql
[0m21:03:14.348758 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:03:14.353805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b1e9450>]}
[0m21:03:14.390236 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:03:14.391289 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:03:14.401989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b455b80>]}
[0m21:03:14.402173 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:03:14.403143 [info ] [MainThread]: 
[0m21:03:14.403282 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:03:14.403371 [info ] [MainThread]: 
[0m21:03:14.403560 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:03:14.403659 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:03:14.406213 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:03:14.406331 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:03:14.409954 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:03:14.410118 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:03:14.410220 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:03:15.418096 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c1-cfad-1df8-ab13-af36064c5899) - Created
[0m21:03:16.023059 [debug] [ThreadPool]: SQL status: OK in 1.610 seconds
[0m21:03:16.030584 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c1-cfad-1df8-ab13-af36064c5899, command-id=01f089c1-cfd6-1d96-b40f-ded4e937e46c) - Closing
[0m21:03:16.031016 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:03:16.031215 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c1-cfad-1df8-ab13-af36064c5899) - Closing
[0m21:03:16.309789 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:03:16.310424 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:03:16.319427 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:03:16.319877 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:03:16.320123 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:03:17.214366 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c1-d0bd-16f3-9283-ffa83fcfe8c9) - Created
[0m21:03:17.826118 [debug] [ThreadPool]: SQL status: OK in 1.510 seconds
[0m21:03:17.829943 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c1-d0bd-16f3-9283-ffa83fcfe8c9, command-id=01f089c1-d0e1-1c0b-9004-379f20478f18) - Closing
[0m21:03:17.831016 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:03:17.831324 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c1-d0bd-16f3-9283-ffa83fcfe8c9) - Closing
[0m21:03:18.115834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dc8bd90>]}
[0m21:03:18.119834 [debug] [Thread-3 (]: Began running node model.flights_dbt.bronze_flights
[0m21:03:18.120295 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airlines
[0m21:03:18.120623 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_airports
[0m21:03:18.120938 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:03:18.121537 [info ] [Thread-3 (]: 3 of 14 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:03:18.122095 [info ] [Thread-1 (]: 1 of 14 START sql view model raw.bronze_airlines ............................... [RUN]
[0m21:03:18.122587 [info ] [Thread-2 (]: 2 of 14 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:03:18.123117 [info ] [Thread-4 (]: 4 of 14 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:03:18.123854 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:03:18.124385 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airlines) - Creating connection
[0m21:03:18.124759 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:03:18.125098 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:03:18.125364 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:03:18.125607 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airlines'
[0m21:03:18.125841 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:03:18.126066 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:03:18.126346 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:03:18.126583 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airlines
[0m21:03:18.126803 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:03:18.127022 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:03:18.134700 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:03:18.137626 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:03:18.140832 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airlines"
[0m21:03:18.142520 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:03:18.143752 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:03:18.149983 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airlines
[0m21:03:18.154975 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:03:18.155241 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:03:18.155462 [debug] [Thread-3 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:03:18.156743 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:03:18.158039 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:03:18.159234 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:03:18.160147 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:03:18.160392 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:03:18.160624 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11debe750>]}
[0m21:03:18.160875 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:03:18.161142 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:03:18.161327 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11de390d0>]}
[0m21:03:18.167817 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b4a3a10>]}
[0m21:03:18.168440 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:03:18.168593 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b4a35f0>]}
[0m21:03:18.169205 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airlines`
[0m21:03:18.169601 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:03:18.173760 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:03:18.174159 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:03:18.174474 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airlines"
[0m21:03:18.174768 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:03:18.175120 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:03:18.175672 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:03:18.175778 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airlines"
[0m21:03:18.175876 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:03:18.176003 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    SELECT
    flight_id,
    origin,
    destination AS dest,  -- or the correct column name
    airline,
    arr_time
FROM `flight_db`.`raw`.`flights`
  )

[0m21:03:18.176114 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:03:18.176270 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    -- models/bronze/bronze_airlines.sql

select
    airline,
    name,
    country
from `flight_db`.`raw`.`airlines`
  )

[0m21:03:18.176407 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:03:18.176530 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:03:18.176667 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    -- models/example/my_first_dbt_model.sql

select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m21:03:18.176791 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:03:18.176897 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:03:18.177087 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:03:19.080562 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c1-d1dc-1fab-beac-b8d04bc534c8) - Created
[0m21:03:19.120074 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c1-d1e3-18c9-8ced-291f79b9df23) - Created
[0m21:03:19.158904 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c1-d1e5-18b3-97a1-aa460022406e) - Created
[0m21:03:19.161236 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c1-d1e3-1b63-a42d-2a5f5f30c892) - Created
[0m21:03:19.542257 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    -- models/bronze/bronze_airlines.sql

select
    airline,
    name,
    country
from `flight_db`.`raw`.`airlines`
  )

: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c1-d1fb-1f0d-8df5-7d1642e86ec9
[0m21:03:19.543681 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: Close
[0m21:03:19.544087 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c1-d1dc-1fab-beac-b8d04bc534c8) - Closing
[0m21:03:19.754784 [debug] [Thread-4 (]: SQL status: OK in 1.580 seconds
[0m21:03:19.756318 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c1-d1e3-1b63-a42d-2a5f5f30c892, command-id=01f089c1-d208-128c-adb5-ce3434cda898) - Closing
[0m21:03:19.769566 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:03:19.772682 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:03:19.773069 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c1-d1e3-1b63-a42d-2a5f5f30c892) - Closing
[0m21:03:19.781248 [debug] [Thread-1 (]: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:03:19.820078 [debug] [Thread-2 (]: SQL status: OK in 1.640 seconds
[0m21:03:19.820827 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c1-d1e3-18c9-8ced-291f79b9df23, command-id=01f089c1-d207-183f-a6d1-947368c040e0) - Closing
[0m21:03:19.821335 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:03:19.859462 [debug] [Thread-3 (]: SQL status: OK in 1.680 seconds
[0m21:03:19.860774 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c1-d1e5-18b3-97a1-aa460022406e, command-id=01f089c1-d209-12ab-9325-75b4723cc92f) - Closing
[0m21:03:19.861658 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:03:19.975460 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: Close
[0m21:03:19.977218 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c1-d1e3-18c9-8ced-291f79b9df23) - Closing
[0m21:03:19.979313 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106711ed0>]}
[0m21:03:19.980259 [error] [Thread-1 (]: 1 of 14 ERROR creating sql view model raw.bronze_airlines ...................... [[31mERROR[0m in 1.85s]
[0m21:03:19.980907 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airlines
[0m21:03:19.981305 [debug] [Thread-1 (]: Began running node model.flights_dbt.silver_flights
[0m21:03:19.981780 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.bronze_airlines' to be skipped because of status 'error'.  Reason: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql.
[0m21:03:19.982260 [info ] [Thread-1 (]: 5 of 14 START sql view model raw.silver_flights ................................ [RUN]
[0m21:03:20.207791 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: Close
[0m21:03:20.208892 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c1-d1e5-18b3-97a1-aa460022406e) - Closing
[0m21:03:20.416450 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b294670>]}
[0m21:03:20.417645 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:03:20.418433 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e04ad60>]}
[0m21:03:20.419017 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11def0710>]}
[0m21:03:20.420174 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:03:20.419819 [info ] [Thread-4 (]: 4 of 14 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.29s]
[0m21:03:20.420886 [info ] [Thread-2 (]: 2 of 14 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.29s]
[0m21:03:20.421406 [info ] [Thread-3 (]: 3 of 14 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.30s]
[0m21:03:20.421785 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:03:20.422285 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:03:20.422690 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:03:20.423082 [debug] [Thread-3 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:03:20.425280 [debug] [Thread-4 (]: Began running node model.flights_dbt.stg_airlines
[0m21:03:20.427102 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_airlines
[0m21:03:20.434266 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m21:03:20.435899 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:03:20.436572 [info ] [Thread-4 (]: 6 of 14 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:03:20.437048 [info ] [Thread-2 (]: 7 of 14 SKIP relation raw.silver_airlines ...................................... [[33mSKIP[0m]
[0m21:03:20.437464 [info ] [Thread-3 (]: 8 of 14 START test not_null_my_first_dbt_model_id .............................. [RUN]
[0m21:03:20.438281 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:03:20.438685 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:03:20.439222 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_id.5fb22c2710) - Creating connection
[0m21:03:20.439519 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:03:20.439787 [debug] [Thread-2 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_id.16e066b321
[0m21:03:20.440026 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_id.5fb22c2710'
[0m21:03:20.440247 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.silver_airlines' to be skipped because of status 'skipped'. 
[0m21:03:20.440470 [debug] [Thread-1 (]: Began executing node model.flights_dbt.silver_flights
[0m21:03:20.440679 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:03:20.440898 [info ] [Thread-2 (]: 9 of 14 START test unique_my_first_dbt_model_id ................................ [RUN]
[0m21:03:20.441129 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m21:03:20.442790 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:03:20.446136 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_id.16e066b321) - Creating connection
[0m21:03:20.450052 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:03:20.457014 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m21:03:20.457611 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:03:20.457806 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_id.16e066b321'
[0m21:03:20.458363 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:03:20.458551 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_id.16e066b321
[0m21:03:20.462233 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m21:03:20.462450 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m21:03:20.468899 [debug] [Thread-4 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:03:20.471242 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m21:03:20.478943 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m21:03:20.479074 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:03:20.479262 [debug] [Thread-2 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_id.16e066b321
[0m21:03:20.492493 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:03:20.492660 [debug] [Thread-1 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    -- models/silver/silver_flights.sql

create or replace view `flight_db`.`raw`.`silver_flights` as
select
    airline,
    origin,
    dest,
    dep_time,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m21:03:20.493616 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m21:03:20.493732 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
[0m21:03:20.493875 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:03:20.494046 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from `flight_db`.`raw`.`my_first_dbt_model`
where id is null



  
  
      
    ) dbt_internal_test
[0m21:03:20.494154 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:03:20.494332 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:03:20.494518 [debug] [Thread-4 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:03:20.494640 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_id.16e066b321"
[0m21:03:20.494797 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:03:20.494929 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_id.16e066b321"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where id is not null
group by id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:03:20.495124 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:03:21.284320 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c1-d32d-1209-a974-fac68180acf9) - Created
[0m21:03:21.296585 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c1-d32f-1fdd-8479-5614ff185a7d) - Created
[0m21:03:21.321518 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c1-d332-1dfb-94f8-49e59acaaf33) - Created
[0m21:03:21.340492 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c1-d335-1cf1-b83f-81a4155827e9) - Created
[0m21:03:21.837860 [debug] [Thread-2 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_id.16e066b321"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where id is not null
group by id
having count(*) > 1



  
  
      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c1-d350-1b50-bbc9-f0631caa4829
[0m21:03:21.840112 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_first_dbt_model_id.16e066b321: Close
[0m21:03:21.840470 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c1-d332-1dfb-94f8-49e59acaaf33) - Closing
[0m21:03:21.879135 [debug] [Thread-3 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from `flight_db`.`raw`.`my_first_dbt_model`
where id is null



  
  
      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c1-d34a-1eb0-96e3-e2edfaf53f6f
[0m21:03:22.005225 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    -- models/silver/silver_flights.sql

create or replace view `flight_db`.`raw`.`silver_flights` as
select
    airline,
    origin,
    dest,
    dep_time,
    arr_time
from `flight_db`.`raw`.`flights`
  )

: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    -- models/silver/silver_flights.sql

create or replace view `flight_db`.`raw`.`silver_flights` as
^^^
select
    airline,
    origin,
    dest,
    dep_time,
    arr_time
from `flight_db`.`raw`.`flights`
  )

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    -- models/silver/silver_flights.sql

create or replace view `flight_db`.`raw`.`silver_flights` as
^^^
select
    airline,
    origin,
    dest,
    dep_time,
    arr_time
from `flight_db`.`raw`.`flights`
  )

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    -- models/silver/silver_flights.sql

create or replace view `flight_db`.`raw`.`silver_flights` as
^^^
select
    airline,
    origin,
    dest,
    dep_time,
    arr_time
from `flight_db`.`raw`.`flights`
  )

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:117)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:153)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:446)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:615)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:246)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:155)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)
	at com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:61)
	at com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:136)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:444)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:440)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:790)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:781)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:569)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:901)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:296)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:896)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f089c1-d353-11dc-9d4f-0a88436fa6e7
[0m21:03:22.045772 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m21:03:22.046530 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c1-d32d-1209-a974-fac68180acf9) - Closing
[0m21:03:22.053348 [debug] [Thread-2 (]: Database Error in test unique_my_first_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/unique_my_first_dbt_model_id.sql
[0m21:03:22.262323 [debug] [Thread-1 (]: On model.flights_dbt.silver_flights: Close
[0m21:03:22.263537 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c1-d335-1cf1-b83f-81a4155827e9) - Closing
[0m21:03:22.269368 [debug] [Thread-3 (]: Database Error in test not_null_my_first_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m21:03:22.473682 [error] [Thread-2 (]: 9 of 14 ERROR unique_my_first_dbt_model_id ..................................... [[31mERROR[0m in 2.03s]
[0m21:03:22.474487 [error] [Thread-3 (]: 8 of 14 ERROR not_null_my_first_dbt_model_id ................................... [[31mERROR[0m in 2.04s]
[0m21:03:22.475374 [debug] [Thread-2 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_id.16e066b321
[0m21:03:22.475918 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_id.5fb22c2710
[0m21:03:22.476814 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_airports
[0m21:03:22.477322 [debug] [Thread-7 (]: Marking all children of 'test.flights_dbt.unique_my_first_dbt_model_id.16e066b321' to be skipped because of status 'error'.  Reason: Database Error in test unique_my_first_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/unique_my_first_dbt_model_id.sql.
[0m21:03:22.481774 [debug] [Thread-1 (]: Database Error in model silver_flights (models/silver/silver_flights.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */
  
    
    
    create or replace view `flight_db`.`raw`.`silver_flights`
    
    as (
      -- models/silver/silver_flights.sql
  
  create or replace view `flight_db`.`raw`.`silver_flights` as
  ^^^
  select
      airline,
      origin,
      dest,
      dep_time,
      arr_time
  from `flight_db`.`raw`.`flights`
    )
  
  compiled code at target/run/flights_dbt/models/silver/silver_flights.sql
[0m21:03:22.480868 [info ] [Thread-2 (]: 10 of 14 START sql view model raw.silver_airports .............................. [RUN]
[0m21:03:22.482382 [debug] [Thread-7 (]: Marking all children of 'test.flights_dbt.not_null_my_first_dbt_model_id.5fb22c2710' to be skipped because of status 'error'.  Reason: Database Error in test not_null_my_first_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/not_null_my_first_dbt_model_id.sql.
[0m21:03:22.482838 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b194a70>]}
[0m21:03:22.483373 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:03:22.483972 [debug] [Thread-3 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:03:22.485095 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:03:22.484629 [error] [Thread-1 (]: 5 of 14 ERROR creating sql view model raw.silver_flights ....................... [[31mERROR[0m in 2.50s]
[0m21:03:22.485555 [info ] [Thread-3 (]: 11 of 14 SKIP relation raw.my_second_dbt_model ................................. [[33mSKIP[0m]
[0m21:03:22.485889 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:03:22.486317 [debug] [Thread-1 (]: Finished running node model.flights_dbt.silver_flights
[0m21:03:22.486603 [debug] [Thread-3 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:03:22.490302 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:03:22.490771 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.silver_flights' to be skipped because of status 'error'.  Reason: Database Error in model silver_flights (models/silver/silver_flights.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */
  
    
    
    create or replace view `flight_db`.`raw`.`silver_flights`
    
    as (
      -- models/silver/silver_flights.sql
  
  create or replace view `flight_db`.`raw`.`silver_flights` as
  ^^^
  select
      airline,
      origin,
      dest,
      dep_time,
      arr_time
  from `flight_db`.`raw`.`flights`
    )
  
  compiled code at target/run/flights_dbt/models/silver/silver_flights.sql.
[0m21:03:22.491206 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.my_second_dbt_model' to be skipped because of status 'skipped'. 
[0m21:03:22.491620 [debug] [Thread-1 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m21:03:22.491900 [debug] [Thread-3 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m21:03:22.492185 [info ] [Thread-1 (]: 12 of 14 SKIP test not_null_my_second_dbt_model_id ............................. [[33mSKIP[0m]
[0m21:03:22.492458 [info ] [Thread-3 (]: 13 of 14 SKIP test unique_my_second_dbt_model_id ............................... [[33mSKIP[0m]
[0m21:03:22.492697 [debug] [Thread-1 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m21:03:22.492974 [debug] [Thread-3 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m21:03:22.493218 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_airports
[0m21:03:22.493409 [debug] [Thread-7 (]: Marking all children of 'test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778' to be skipped because of status 'skipped'. 
[0m21:03:22.494880 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:03:22.495104 [debug] [Thread-7 (]: Marking all children of 'test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493' to be skipped because of status 'skipped'. 
[0m21:03:22.495908 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:03:22.496493 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:03:22.496877 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:03:22.497095 [debug] [Thread-2 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:03:22.497305 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:03:23.227583 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c1-d455-1191-8a7a-60245e56336b) - Created
[0m21:03:23.681823 [debug] [Thread-4 (]: SQL status: OK in 3.190 seconds
[0m21:03:23.683363 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c1-d32f-1fdd-8479-5614ff185a7d, command-id=01f089c1-d34c-1b74-bdf6-03dd511b1c2b) - Closing
[0m21:03:23.688112 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:03:23.704327 [debug] [Thread-4 (]: On model.flights_dbt.stg_airlines: Close
[0m21:03:23.704659 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c1-d32f-1fdd-8479-5614ff185a7d) - Closing
[0m21:03:23.906041 [debug] [Thread-2 (]: SQL status: OK in 1.410 seconds
[0m21:03:23.907394 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c1-d455-1191-8a7a-60245e56336b, command-id=01f089c1-d471-1770-a55a-2df4f3395bcd) - Closing
[0m21:03:23.908051 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:03:23.949190 [debug] [Thread-2 (]: On model.flights_dbt.silver_airports: Close
[0m21:03:23.949866 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c1-d455-1191-8a7a-60245e56336b) - Closing
[0m21:03:24.147559 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11def08f0>]}
[0m21:03:24.147763 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d7429e4-dbd2-4f00-b98e-382b376c2c05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11def22d0>]}
[0m21:03:24.148052 [info ] [Thread-4 (]: 6 of 14 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.71s]
[0m21:03:24.148442 [debug] [Thread-4 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:03:24.148254 [info ] [Thread-2 (]: 10 of 14 OK created sql view model raw.silver_airports ......................... [[32mOK[0m in 1.66s]
[0m21:03:24.148677 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_airports
[0m21:03:24.148940 [debug] [Thread-1 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:03:24.149058 [info ] [Thread-1 (]: 14 of 14 SKIP relation raw.gold_flight_metrics ................................. [[33mSKIP[0m]
[0m21:03:24.149198 [debug] [Thread-1 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:03:24.149293 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'skipped'. 
[0m21:03:24.149798 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:03:24.149910 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:03:24.150083 [info ] [MainThread]: 
[0m21:03:24.150191 [info ] [MainThread]: Finished running 2 table models, 4 data tests, 8 view models in 0 hours 0 minutes and 9.75 seconds (9.75s).
[0m21:03:24.150789 [debug] [MainThread]: Command end result
[0m21:03:24.162630 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:03:24.163341 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:03:24.165742 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:03:24.165850 [info ] [MainThread]: 
[0m21:03:24.165971 [info ] [MainThread]: [31mCompleted with 4 errors, 0 partial successes, and 0 warnings:[0m
[0m21:03:24.166062 [info ] [MainThread]: 
[0m21:03:24.166182 [error] [MainThread]: [31mFailure in model bronze_airlines (models/bronze/bronze_airlines.sql)[0m
[0m21:03:24.166295 [error] [MainThread]:   Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:03:24.166384 [info ] [MainThread]: 
[0m21:03:24.166479 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:03:24.166559 [info ] [MainThread]: 
[0m21:03:24.166661 [error] [MainThread]: [31mFailure in test unique_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m21:03:24.166762 [error] [MainThread]:   Database Error in test unique_my_first_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/unique_my_first_dbt_model_id.sql
[0m21:03:24.166846 [info ] [MainThread]: 
[0m21:03:24.166939 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/example/schema.yml/unique_my_first_dbt_model_id.sql
[0m21:03:24.167016 [info ] [MainThread]: 
[0m21:03:24.167112 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m21:03:24.167210 [error] [MainThread]:   Database Error in test not_null_my_first_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m21:03:24.167290 [info ] [MainThread]: 
[0m21:03:24.167380 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m21:03:24.167458 [info ] [MainThread]: 
[0m21:03:24.167556 [error] [MainThread]: [31mFailure in model silver_flights (models/silver/silver_flights.sql)[0m
[0m21:03:24.167664 [error] [MainThread]:   Database Error in model silver_flights (models/silver/silver_flights.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 10, pos 0)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */
  
    
    
    create or replace view `flight_db`.`raw`.`silver_flights`
    
    as (
      -- models/silver/silver_flights.sql
  
  create or replace view `flight_db`.`raw`.`silver_flights` as
  ^^^
  select
      airline,
      origin,
      dest,
      dep_time,
      arr_time
  from `flight_db`.`raw`.`flights`
    )
  
  compiled code at target/run/flights_dbt/models/silver/silver_flights.sql
[0m21:03:24.167752 [info ] [MainThread]: 
[0m21:03:24.167844 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/silver/silver_flights.sql
[0m21:03:24.167922 [info ] [MainThread]: 
[0m21:03:24.168023 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=4 SKIP=5 NO-OP=0 TOTAL=14
[0m21:03:24.170573 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 10.915942, "process_in_blocks": "0", "process_kernel_time": 0.284474, "process_mem_max_rss": "249036800", "process_out_blocks": "0", "process_user_time": 2.802593}
[0m21:03:24.170743 [debug] [MainThread]: Command `dbt build` failed at 21:03:24.170713 after 10.92 seconds
[0m21:03:24.170871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075f22d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e1b79b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e1b7950>]}
[0m21:03:24.170977 [debug] [MainThread]: Flushing usage events
[0m21:03:26.508526 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:05:02.166180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104137620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055ff890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055ffb10>]}


============================== 21:05:02.168436 | bf14534c-dd64-44f8-b380-a990860eef08 ==============================
[0m21:05:02.168436 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:05:02.168670 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'fail_fast': 'False', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt build', 'quiet': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'warn_error': 'None', 'profiles_dir': '/Users/artakerqeli/.dbt', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'no_print': 'None', 'log_cache_events': 'False', 'version_check': 'True', 'indirect_selection': 'eager', 'write_json': 'True', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'debug': 'False', 'partial_parse': 'True', 'printer_width': '80', 'static_parser': 'True', 'target_path': 'None'}
[0m21:05:02.469801 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:05:02.470021 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:05:02.470134 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:05:02.929752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10463f360>]}
[0m21:05:02.949045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107506ad0>]}
[0m21:05:02.949286 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:05:03.006656 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:05:03.065169 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m21:05:03.065471 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/example/schema.yml
[0m21:05:03.065613 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/silver/silver_flights.sql
[0m21:05:03.200870 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:05:03.205751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116344f50>]}
[0m21:05:03.241407 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:05:03.242507 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:05:03.253728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116305d60>]}
[0m21:05:03.253909 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:05:03.254893 [info ] [MainThread]: 
[0m21:05:03.255024 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:05:03.255111 [info ] [MainThread]: 
[0m21:05:03.255304 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:05:03.255402 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:05:03.257888 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:05:03.258008 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:05:03.261512 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:05:03.261623 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:05:03.261713 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:05:04.046188 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-106e-1254-862c-99904a134f5e) - Created
[0m21:05:04.654599 [debug] [ThreadPool]: SQL status: OK in 1.390 seconds
[0m21:05:04.664242 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c2-106e-1254-862c-99904a134f5e, command-id=01f089c2-108c-194d-9833-5d84e8f6d2c1) - Closing
[0m21:05:04.664705 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:05:04.664886 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-106e-1254-862c-99904a134f5e) - Closing
[0m21:05:04.867351 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:05:04.867957 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:05:04.877065 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:05:04.877557 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:05:04.877850 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:05:05.543480 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-1152-151e-be4b-9090f77cde2c) - Created
[0m21:05:06.080164 [debug] [ThreadPool]: SQL status: OK in 1.200 seconds
[0m21:05:06.084187 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c2-1152-151e-be4b-9090f77cde2c, command-id=01f089c2-116d-1f22-9725-9df6a64eb128) - Closing
[0m21:05:06.085273 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:05:06.085593 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-1152-151e-be4b-9090f77cde2c) - Closing
[0m21:05:06.304686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11641b070>]}
[0m21:05:06.309512 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airlines
[0m21:05:06.309912 [debug] [Thread-3 (]: Began running node model.flights_dbt.bronze_flights
[0m21:05:06.310195 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:05:06.310454 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_airports
[0m21:05:06.310964 [info ] [Thread-1 (]: 1 of 14 START sql view model raw.bronze_airlines ............................... [RUN]
[0m21:05:06.311343 [info ] [Thread-3 (]: 3 of 14 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:05:06.311734 [info ] [Thread-4 (]: 4 of 14 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:05:06.312081 [info ] [Thread-2 (]: 2 of 14 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:05:06.312684 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airlines) - Creating connection
[0m21:05:06.313255 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:05:06.313688 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:05:06.314093 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:05:06.314405 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airlines'
[0m21:05:06.314679 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:05:06.314938 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:05:06.315180 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:05:06.315452 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airlines
[0m21:05:06.315716 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:05:06.315968 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:05:06.316208 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:05:06.322745 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airlines"
[0m21:05:06.324996 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:05:06.326751 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:05:06.328593 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:05:06.329688 [debug] [Thread-3 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:05:06.335886 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airlines
[0m21:05:06.336077 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:05:06.339397 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:05:06.340646 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:05:06.341655 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:05:06.341822 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:05:06.342873 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:05:06.343134 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:05:06.343381 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:05:06.344584 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:05:06.344767 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120508050>]}
[0m21:05:06.344930 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116498050>]}
[0m21:05:06.345089 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x116499190>]}
[0m21:05:06.345323 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:05:06.353487 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airlines`
[0m21:05:06.354075 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:05:06.354508 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:05:06.354659 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120507390>]}
[0m21:05:06.359205 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airlines"
[0m21:05:06.359594 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:05:06.359912 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:05:06.360286 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:05:06.360765 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:05:06.361052 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:05:06.361174 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:05:06.361278 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airlines"
[0m21:05:06.361410 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:05:06.361557 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    SELECT
    flight_id,
    origin,
    destination AS dest,  -- or the correct column name
    airline,
    arr_time
FROM `flight_db`.`raw`.`flights`
  )

[0m21:05:06.361696 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    -- models/bronze/bronze_airlines.sql

select
    airline,
    name,
    country
from `flight_db`.`raw`.`airlines`
  )

[0m21:05:06.361802 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:05:06.361918 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:05:06.362031 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:05:06.362137 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:05:06.362272 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    -- models/example/my_first_dbt_model.sql

select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m21:05:06.362627 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:05:07.090351 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-123e-1635-a989-e2f4c0930d49) - Created
[0m21:05:07.130785 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-1245-1448-82d1-142b9334e963) - Created
[0m21:05:07.140317 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-1246-1074-9eaf-a7a11248cf35) - Created
[0m21:05:07.144680 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-1245-1ed9-9025-c96cba433d3f) - Created
[0m21:05:07.634405 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    -- models/bronze/bronze_airlines.sql

select
    airline,
    name,
    country
from `flight_db`.`raw`.`airlines`
  )

: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c2-1263-1524-8755-99a4324a1069
[0m21:05:07.636042 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: Close
[0m21:05:07.636579 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-1245-1ed9-9025-c96cba433d3f) - Closing
[0m21:05:07.700801 [debug] [Thread-3 (]: SQL status: OK in 1.340 seconds
[0m21:05:07.703261 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c2-123e-1635-a989-e2f4c0930d49, command-id=01f089c2-125a-172b-9185-4a385ebc5de8) - Closing
[0m21:05:07.713646 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:05:07.802253 [debug] [Thread-2 (]: SQL status: OK in 1.440 seconds
[0m21:05:07.803774 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c2-1245-1448-82d1-142b9334e963, command-id=01f089c2-1262-1441-9f07-9a4c1f3c1a84) - Closing
[0m21:05:07.804724 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:05:07.847677 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: Close
[0m21:05:07.850425 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-123e-1635-a989-e2f4c0930d49) - Closing
[0m21:05:07.850989 [debug] [Thread-4 (]: SQL status: OK in 1.490 seconds
[0m21:05:07.852682 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c2-1246-1074-9eaf-a7a11248cf35, command-id=01f089c2-1263-10da-af96-ecd5cca88f69) - Closing
[0m21:05:07.853437 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:05:07.864152 [debug] [Thread-1 (]: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:05:08.056229 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: Close
[0m21:05:08.057284 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-1245-1448-82d1-142b9334e963) - Closing
[0m21:05:08.272141 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:05:08.273197 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-1246-1074-9eaf-a7a11248cf35) - Closing
[0m21:05:08.485635 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12055da50>]}
[0m21:05:08.486153 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120585ed0>]}
[0m21:05:08.486482 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1164d91d0>]}
[0m21:05:08.486904 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1205432f0>]}
[0m21:05:08.487663 [info ] [Thread-3 (]: 3 of 14 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.17s]
[0m21:05:08.488249 [info ] [Thread-4 (]: 4 of 14 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.17s]
[0m21:05:08.488794 [error] [Thread-1 (]: 1 of 14 ERROR creating sql view model raw.bronze_airlines ...................... [[31mERROR[0m in 2.17s]
[0m21:05:08.489967 [debug] [Thread-3 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:05:08.489352 [info ] [Thread-2 (]: 2 of 14 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.17s]
[0m21:05:08.490578 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:05:08.491025 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airlines
[0m21:05:08.491389 [debug] [Thread-3 (]: Began running node model.flights_dbt.stg_airlines
[0m21:05:08.491886 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:05:08.492574 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.bronze_airlines' to be skipped because of status 'error'.  Reason: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql.
[0m21:05:08.493258 [debug] [Thread-1 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:05:08.492993 [info ] [Thread-3 (]: 5 of 14 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:05:08.493613 [debug] [Thread-4 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:05:08.494700 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_airlines
[0m21:05:08.494475 [info ] [Thread-1 (]: 7 of 14 START test unique_my_first_dbt_model_flight_id ......................... [RUN]
[0m21:05:08.495255 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:05:08.495525 [info ] [Thread-4 (]: 6 of 14 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:05:08.495829 [info ] [Thread-2 (]: 8 of 14 SKIP relation raw.silver_airlines ...................................... [[33mSKIP[0m]
[0m21:05:08.496221 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:05:08.496558 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:05:08.497100 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:05:08.497444 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:05:08.497728 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:05:08.498006 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:05:08.498264 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:05:08.498552 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_airports
[0m21:05:08.498801 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.silver_airlines' to be skipped because of status 'skipped'. 
[0m21:05:08.499103 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:05:08.501685 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:05:08.501961 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:05:08.502292 [info ] [Thread-2 (]: 9 of 14 START sql view model raw.silver_airports ............................... [RUN]
[0m21:05:08.509979 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:05:08.515711 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:05:08.516048 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:05:08.516330 [debug] [Thread-3 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:05:08.516560 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:05:08.526459 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m21:05:08.526636 [debug] [Thread-1 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:05:08.526806 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:05:08.533239 [debug] [Thread-4 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:05:08.547972 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:05:08.548664 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:05:08.549649 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:05:08.550707 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:05:08.551025 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:05:08.551167 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_airports
[0m21:05:08.551359 [debug] [Thread-3 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:05:08.552143 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:05:08.552244 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:05:08.552346 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:05:08.552463 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:05:08.552833 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:05:08.552969 [debug] [Thread-4 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:05:08.553110 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:05:08.553589 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:05:08.553744 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:05:08.553853 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:05:08.554079 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:05:08.554220 [debug] [Thread-2 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:05:08.554353 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:05:09.380717 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-1397-11c5-8e3f-7e559595c897) - Created
[0m21:05:09.382754 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-1397-1b5e-a091-c2caefb19430) - Created
[0m21:05:09.384390 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-1397-1bff-af81-8a1aff992ce0) - Created
[0m21:05:09.386447 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-1398-1fc4-868e-be173fe5138e) - Created
[0m21:05:10.136945 [debug] [Thread-2 (]: SQL status: OK in 1.580 seconds
[0m21:05:10.138510 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c2-1397-1bff-af81-8a1aff992ce0, command-id=01f089c2-13b7-1b95-869b-31c5c119d2c3) - Closing
[0m21:05:10.139479 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:05:10.140406 [debug] [Thread-2 (]: On model.flights_dbt.silver_airports: Close
[0m21:05:10.140719 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-1397-1bff-af81-8a1aff992ce0) - Closing
[0m21:05:10.346561 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1205f2750>]}
[0m21:05:10.348301 [info ] [Thread-2 (]: 9 of 14 OK created sql view model raw.silver_airports .......................... [[32mOK[0m in 1.83s]
[0m21:05:10.349376 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_airports
[0m21:05:11.026587 [debug] [Thread-1 (]: SQL status: OK in 2.470 seconds
[0m21:05:11.032400 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c2-1398-1fc4-868e-be173fe5138e, command-id=01f089c2-13bc-1a4c-857a-a40aebf41d7d) - Closing
[0m21:05:11.035260 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:05:11.035618 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-1398-1fc4-868e-be173fe5138e) - Closing
[0m21:05:11.144938 [debug] [Thread-4 (]: SQL status: OK in 2.590 seconds
[0m21:05:11.148366 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c2-1397-1b5e-a091-c2caefb19430, command-id=01f089c2-13b7-1f90-9ad3-1dd42232d367) - Closing
[0m21:05:11.235826 [debug] [Thread-4 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:05:11.236869 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-1397-1b5e-a091-c2caefb19430) - Closing
[0m21:05:11.420519 [info ] [Thread-1 (]: 7 of 14 PASS unique_my_first_dbt_model_flight_id ............................... [[32mPASS[0m in 2.92s]
[0m21:05:11.421510 [info ] [Thread-4 (]: 6 of 14 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 2.92s]
[0m21:05:11.422654 [debug] [Thread-1 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:05:11.423199 [debug] [Thread-4 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:05:11.424029 [debug] [Thread-1 (]: Began running node model.flights_dbt.silver_flights
[0m21:05:11.424382 [debug] [Thread-2 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:05:11.424964 [info ] [Thread-1 (]: 11 of 14 START sql view model raw.silver_flights ............................... [RUN]
[0m21:05:11.425405 [info ] [Thread-2 (]: 10 of 14 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:05:11.426069 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:05:11.426555 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:05:11.426901 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:05:11.427195 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:05:11.427491 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:05:11.427765 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:05:11.431877 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:05:11.442434 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:05:11.442883 [debug] [Thread-1 (]: Began executing node model.flights_dbt.silver_flights
[0m21:05:11.444743 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:05:11.445841 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:05:11.446454 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:05:11.446874 [debug] [Thread-2 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:05:11.448608 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:05:11.449255 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:05:11.449463 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:05:11.450006 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:05:11.450269 [debug] [Thread-1 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    -- models/silver/silver_flights.sql

select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:05:11.450545 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:05:11.450885 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:05:11.451108 [debug] [Thread-2 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    -- Use the `ref` function to select from other models

select *
from `flight_db`.`raw`.`my_first_dbt_model`
where id = 1
  )

[0m21:05:11.451367 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:05:12.018256 [debug] [Thread-3 (]: SQL status: OK in 3.470 seconds
[0m21:05:12.019832 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c2-1397-11c5-8e3f-7e559595c897, command-id=01f089c2-13b8-1c9a-a047-a9dc2da2d0a0) - Closing
[0m21:05:12.024178 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:05:12.037322 [debug] [Thread-3 (]: On model.flights_dbt.stg_airlines: Close
[0m21:05:12.037591 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-1397-11c5-8e3f-7e559595c897) - Closing
[0m21:05:12.111060 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-153c-14a0-99f9-b972ecd93716) - Created
[0m21:05:12.175930 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-1545-1d86-b0ab-ddfd2953c4f4) - Created
[0m21:05:12.232748 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12057fa70>]}
[0m21:05:12.234506 [info ] [Thread-3 (]: 5 of 14 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.74s]
[0m21:05:12.235361 [debug] [Thread-3 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:05:12.495598 [debug] [Thread-2 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    -- Use the `ref` function to select from other models

select *
from `flight_db`.`raw`.`my_first_dbt_model`
where id = 1
  )

: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 12 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 12 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 12 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c2-1562-15be-81b7-ae0ba412768f
[0m21:05:12.497161 [debug] [Thread-2 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:05:12.497593 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-1545-1d86-b0ab-ddfd2953c4f4) - Closing
[0m21:05:12.637227 [debug] [Thread-1 (]: SQL status: OK in 1.190 seconds
[0m21:05:12.639404 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c2-153c-14a0-99f9-b972ecd93716, command-id=01f089c2-1557-1490-a0ed-18fe0da9f842) - Closing
[0m21:05:12.640364 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:05:12.757623 [debug] [Thread-1 (]: On model.flights_dbt.silver_flights: Close
[0m21:05:12.758281 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-153c-14a0-99f9-b972ecd93716) - Closing
[0m21:05:12.763296 [debug] [Thread-2 (]: Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 12 pos 6
  compiled code at target/run/flights_dbt/models/example/my_second_dbt_model.sql
[0m21:05:12.937364 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1205f0f50>]}
[0m21:05:12.938361 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf14534c-dd64-44f8-b380-a990860eef08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1165528d0>]}
[0m21:05:12.939905 [error] [Thread-2 (]: 10 of 14 ERROR creating sql view model raw.my_second_dbt_model ................. [[31mERROR[0m in 1.51s]
[0m21:05:12.941334 [debug] [Thread-2 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:05:12.940788 [info ] [Thread-1 (]: 11 of 14 OK created sql view model raw.silver_flights .......................... [[32mOK[0m in 1.51s]
[0m21:05:12.941953 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.my_second_dbt_model' to be skipped because of status 'error'.  Reason: Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 12 pos 6
  compiled code at target/run/flights_dbt/models/example/my_second_dbt_model.sql.
[0m21:05:12.942468 [debug] [Thread-1 (]: Finished running node model.flights_dbt.silver_flights
[0m21:05:12.943192 [debug] [Thread-4 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m21:05:12.943511 [debug] [Thread-3 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m21:05:12.944248 [debug] [Thread-2 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:05:12.943940 [info ] [Thread-4 (]: 12 of 14 SKIP test not_null_my_second_dbt_model_id ............................. [[33mSKIP[0m]
[0m21:05:12.944595 [info ] [Thread-3 (]: 13 of 14 SKIP test unique_my_second_dbt_model_id ............................... [[33mSKIP[0m]
[0m21:05:12.944926 [info ] [Thread-2 (]: 14 of 14 SKIP relation raw.gold_flight_metrics ................................. [[33mSKIP[0m]
[0m21:05:12.945292 [debug] [Thread-4 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m21:05:12.945622 [debug] [Thread-3 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m21:05:12.945937 [debug] [Thread-2 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:05:12.946214 [debug] [Thread-7 (]: Marking all children of 'test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778' to be skipped because of status 'skipped'. 
[0m21:05:12.946577 [debug] [Thread-7 (]: Marking all children of 'test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493' to be skipped because of status 'skipped'. 
[0m21:05:12.946830 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'skipped'. 
[0m21:05:12.948569 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:05:12.948906 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:05:12.949445 [info ] [MainThread]: 
[0m21:05:12.949763 [info ] [MainThread]: Finished running 2 table models, 4 data tests, 8 view models in 0 hours 0 minutes and 9.69 seconds (9.69s).
[0m21:05:12.951577 [debug] [MainThread]: Command end result
[0m21:05:12.985082 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:05:12.986153 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:05:12.989672 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:05:12.989840 [info ] [MainThread]: 
[0m21:05:12.990002 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m21:05:12.990126 [info ] [MainThread]: 
[0m21:05:12.990288 [error] [MainThread]: [31mFailure in model bronze_airlines (models/bronze/bronze_airlines.sql)[0m
[0m21:05:12.990439 [error] [MainThread]:   Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 14 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:05:12.990553 [info ] [MainThread]: 
[0m21:05:12.990681 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:05:12.990782 [info ] [MainThread]: 
[0m21:05:12.990914 [error] [MainThread]: [31mFailure in model my_second_dbt_model (models/example/my_second_dbt_model.sql)[0m
[0m21:05:12.991051 [error] [MainThread]:   Database Error in model my_second_dbt_model (models/example/my_second_dbt_model.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 12 pos 6
  compiled code at target/run/flights_dbt/models/example/my_second_dbt_model.sql
[0m21:05:12.991154 [info ] [MainThread]: 
[0m21:05:12.991275 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/example/my_second_dbt_model.sql
[0m21:05:12.991378 [info ] [MainThread]: 
[0m21:05:12.991500 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=2 SKIP=4 NO-OP=0 TOTAL=14
[0m21:05:12.995019 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 10.859885, "process_in_blocks": "0", "process_kernel_time": 0.285675, "process_mem_max_rss": "254836736", "process_out_blocks": "0", "process_user_time": 2.867054}
[0m21:05:12.995231 [debug] [MainThread]: Command `dbt build` failed at 21:05:12.995191 after 10.86 seconds
[0m21:05:12.995423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1036bd6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1209b3a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1209b39b0>]}
[0m21:05:12.995566 [debug] [MainThread]: Flushing usage events
[0m21:05:13.815214 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:06:31.832975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067d3620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104ff890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104ffb10>]}


============================== 21:06:31.835276 | e425c595-dc48-48a7-ad13-238b082cc586 ==============================
[0m21:06:31.835276 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:06:31.835530 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/artakerqeli/flights_dbt/logs', 'use_colors': 'True', 'version_check': 'True', 'introspect': 'True', 'write_json': 'True', 'printer_width': '80', 'no_print': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'partial_parse': 'True', 'target_path': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/artakerqeli/.dbt', 'use_experimental_parser': 'False', 'quiet': 'False', 'debug': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt build', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'False', 'cache_selected_only': 'False'}
[0m21:06:32.142397 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:06:32.142595 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:06:32.142694 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:06:32.596739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10742b360>]}
[0m21:06:32.616181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11250aad0>]}
[0m21:06:32.616428 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:06:32.666770 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:06:32.725809 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m21:06:32.726075 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/example/my_second_dbt_model.sql
[0m21:06:32.726205 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/bronze/bronze_airlines.sql
[0m21:06:32.861433 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:06:32.866282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1213bd250>]}
[0m21:06:32.901835 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:06:32.902905 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:06:32.914216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12160df40>]}
[0m21:06:32.914396 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:06:32.915386 [info ] [MainThread]: 
[0m21:06:32.915512 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:06:32.915597 [info ] [MainThread]: 
[0m21:06:32.915788 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:06:32.915885 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:06:32.918449 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:06:32.918580 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:06:32.922321 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:06:32.922472 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:06:32.922571 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:06:33.756084 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-45e2-166c-98f4-4a6768543aed) - Created
[0m21:06:34.192716 [debug] [ThreadPool]: SQL status: OK in 1.270 seconds
[0m21:06:34.200404 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c2-45e2-166c-98f4-4a6768543aed, command-id=01f089c2-4603-1925-99b9-2dde9ccec3cb) - Closing
[0m21:06:34.200865 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:06:34.201064 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-45e2-166c-98f4-4a6768543aed) - Closing
[0m21:06:34.473086 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:06:34.473661 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:06:34.482723 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:06:34.483176 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:06:34.483461 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:06:35.187093 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-46c0-1ef2-b02c-189def478f6e) - Created
[0m21:06:35.752943 [debug] [ThreadPool]: SQL status: OK in 1.270 seconds
[0m21:06:35.755495 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c2-46c0-1ef2-b02c-189def478f6e, command-id=01f089c2-46e0-1e7c-a904-e1d64454ac0e) - Closing
[0m21:06:35.756290 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:06:35.756527 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-46c0-1ef2-b02c-189def478f6e) - Closing
[0m21:06:35.949495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121717690>]}
[0m21:06:35.953937 [debug] [Thread-3 (]: Began running node model.flights_dbt.bronze_flights
[0m21:06:35.954531 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airlines
[0m21:06:35.954956 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:06:35.955362 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_airports
[0m21:06:35.956014 [info ] [Thread-3 (]: 3 of 14 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:06:35.956584 [info ] [Thread-1 (]: 1 of 14 START sql view model raw.bronze_airlines ............................... [RUN]
[0m21:06:35.957072 [info ] [Thread-4 (]: 4 of 14 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:06:35.957559 [info ] [Thread-2 (]: 2 of 14 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:06:35.958319 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:06:35.959018 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airlines) - Creating connection
[0m21:06:35.959507 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:06:35.959891 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:06:35.960184 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:06:35.960441 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airlines'
[0m21:06:35.960686 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:06:35.960894 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:06:35.961167 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:06:35.961390 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airlines
[0m21:06:35.961601 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:06:35.961809 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:06:35.968354 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:06:35.970275 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airlines"
[0m21:06:35.972308 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:06:35.974637 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:06:35.975471 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:06:35.975636 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airlines
[0m21:06:35.975753 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:06:35.975858 [debug] [Thread-3 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:06:35.984946 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:06:35.986232 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:06:35.987270 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:06:35.988261 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:06:35.989598 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:06:35.989915 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:06:35.990171 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:06:35.990403 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:06:35.990608 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124f08050>]}
[0m21:06:35.990751 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1214c13d0>]}
[0m21:06:35.990884 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1214c1610>]}
[0m21:06:35.991007 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1214d3490>]}
[0m21:06:35.998993 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:06:35.999659 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airlines`
[0m21:06:36.000098 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:06:36.000451 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:06:36.005989 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:06:36.006313 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airlines"
[0m21:06:36.006607 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:06:36.006891 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:06:36.007526 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:06:36.007661 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:06:36.007767 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:06:36.007856 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airlines"
[0m21:06:36.007992 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    SELECT
    flight_id,
    origin,
    destination AS dest,  -- or the correct column name
    airline,
    arr_time
FROM `flight_db`.`raw`.`flights`
  )

[0m21:06:36.008139 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:06:36.008296 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    -- models/example/my_first_dbt_model.sql

select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m21:06:36.008441 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

[0m21:06:36.008561 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:06:36.008676 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:06:36.008786 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:06:36.008891 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:06:36.820187 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-47b8-126f-85df-b7e5960c35dc) - Created
[0m21:06:36.822171 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-47ba-12f4-bb66-31c8660351e9) - Created
[0m21:06:36.857447 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-47bf-1055-89e2-22af35286e9f) - Created
[0m21:06:36.862309 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-47be-1a9a-869a-c3ab907d2023) - Created
[0m21:06:37.386757 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c2-47db-1faa-bf7e-dcc627b273c4
[0m21:06:37.388869 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: Close
[0m21:06:37.389546 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-47be-1a9a-869a-c3ab907d2023) - Closing
[0m21:06:37.509997 [debug] [Thread-3 (]: SQL status: OK in 1.500 seconds
[0m21:06:37.511762 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c2-47ba-12f4-bb66-31c8660351e9, command-id=01f089c2-47d6-1a37-9b89-f2a4b99bdafa) - Closing
[0m21:06:37.525685 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:06:37.562827 [debug] [Thread-2 (]: SQL status: OK in 1.550 seconds
[0m21:06:37.564248 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c2-47b8-126f-85df-b7e5960c35dc, command-id=01f089c2-47d4-1cfc-8edf-23b7a2f7772e) - Closing
[0m21:06:37.565125 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:06:37.625172 [debug] [Thread-4 (]: SQL status: OK in 1.620 seconds
[0m21:06:37.628529 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c2-47bf-1055-89e2-22af35286e9f, command-id=01f089c2-47db-1d36-bfa1-ac0b18ebc796) - Closing
[0m21:06:37.628976 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: Close
[0m21:06:37.629765 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:06:37.630185 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-47ba-12f4-bb66-31c8660351e9) - Closing
[0m21:06:37.641406 [debug] [Thread-1 (]: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:06:37.944757 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: Close
[0m21:06:37.945987 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-47b8-126f-85df-b7e5960c35dc) - Closing
[0m21:06:38.144773 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:06:38.145520 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-47bf-1055-89e2-22af35286e9f) - Closing
[0m21:06:38.383204 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073e9ed0>]}
[0m21:06:38.383790 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124f8ddd0>]}
[0m21:06:38.384113 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12135a5f0>]}
[0m21:06:38.384523 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124f4b530>]}
[0m21:06:38.385290 [error] [Thread-1 (]: 1 of 14 ERROR creating sql view model raw.bronze_airlines ...................... [[31mERROR[0m in 2.42s]
[0m21:06:38.385840 [info ] [Thread-4 (]: 4 of 14 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.42s]
[0m21:06:38.386525 [info ] [Thread-3 (]: 3 of 14 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.42s]
[0m21:06:38.386980 [info ] [Thread-2 (]: 2 of 14 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.42s]
[0m21:06:38.387619 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airlines
[0m21:06:38.388076 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:06:38.388478 [debug] [Thread-3 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:06:38.388834 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:06:38.389180 [debug] [Thread-1 (]: Began running node model.flights_dbt.stg_airlines
[0m21:06:38.389589 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.bronze_airlines' to be skipped because of status 'error'.  Reason: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql.
[0m21:06:38.390082 [info ] [Thread-1 (]: 5 of 14 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:06:38.391466 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:06:38.391829 [debug] [Thread-3 (]: Began running node model.flights_dbt.silver_airports
[0m21:06:38.392135 [debug] [Thread-2 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:06:38.392407 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:06:38.392641 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_airlines
[0m21:06:38.392991 [info ] [Thread-3 (]: 7 of 14 START sql view model raw.silver_airports ............................... [RUN]
[0m21:06:38.393255 [info ] [Thread-2 (]: 8 of 14 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:06:38.393670 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:06:38.393974 [info ] [Thread-4 (]: 6 of 14 SKIP relation raw.silver_airlines ...................................... [[33mSKIP[0m]
[0m21:06:38.394534 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:06:38.395023 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:06:38.398363 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:06:38.398741 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:06:38.399004 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:06:38.399239 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:06:38.399588 [debug] [Thread-4 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:06:38.399874 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.silver_airlines' to be skipped because of status 'skipped'. 
[0m21:06:38.400181 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:06:38.400410 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:06:38.400654 [info ] [Thread-4 (]: 9 of 14 START test unique_my_first_dbt_model_flight_id ......................... [RUN]
[0m21:06:38.401123 [debug] [Thread-1 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:06:38.404266 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:06:38.412471 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:06:38.412785 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:06:38.423087 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m21:06:38.423383 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:06:38.429552 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:06:38.438633 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:06:38.442119 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:06:38.442404 [debug] [Thread-2 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:06:38.442560 [debug] [Thread-3 (]: Began executing node model.flights_dbt.silver_airports
[0m21:06:38.449180 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:06:38.450141 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:06:38.450319 [debug] [Thread-4 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:06:38.450428 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:06:38.450817 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:06:38.451767 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:06:38.451910 [debug] [Thread-1 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:06:38.452140 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:06:38.452419 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:06:38.452564 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:06:38.452708 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:06:38.452839 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:06:38.453027 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:06:38.453156 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:06:38.453260 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:06:38.453444 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:06:38.453566 [debug] [Thread-3 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:06:38.453760 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:06:39.195093 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-4925-13b0-8da2-b6a0e0b0a2c5) - Created
[0m21:06:39.216939 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-4929-113b-8046-c77cd2b8f641) - Created
[0m21:06:39.306744 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-4936-1983-a1f2-cb95bc13d9a2) - Created
[0m21:06:39.313370 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-4936-1ba0-9408-cb41dc7c96e8) - Created
[0m21:06:39.618108 [debug] [Thread-2 (]: SQL status: OK in 1.160 seconds
[0m21:06:39.623452 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c2-4925-13b0-8da2-b6a0e0b0a2c5, command-id=01f089c2-493e-1d78-82e6-04853a34566d) - Closing
[0m21:06:39.627161 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:06:39.627816 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-4925-13b0-8da2-b6a0e0b0a2c5) - Closing
[0m21:06:39.633472 [debug] [Thread-4 (]: SQL status: OK in 1.180 seconds
[0m21:06:39.636339 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c2-4929-113b-8046-c77cd2b8f641, command-id=01f089c2-4944-11a0-8458-8dabfd70f7ef) - Closing
[0m21:06:39.825907 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:06:39.827099 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-4929-113b-8046-c77cd2b8f641) - Closing
[0m21:06:40.029893 [info ] [Thread-2 (]: 8 of 14 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.63s]
[0m21:06:40.030546 [info ] [Thread-4 (]: 9 of 14 PASS unique_my_first_dbt_model_flight_id ............................... [[32mPASS[0m in 1.62s]
[0m21:06:40.033273 [debug] [Thread-3 (]: SQL status: OK in 1.580 seconds
[0m21:06:40.033810 [debug] [Thread-2 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:06:40.034286 [debug] [Thread-4 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:06:40.035411 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c2-4936-1ba0-9408-cb41dc7c96e8, command-id=01f089c2-4952-1a28-b9f6-77f2e883b65a) - Closing
[0m21:06:40.036730 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:06:40.037127 [debug] [Thread-2 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:06:40.037408 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_flights
[0m21:06:40.038289 [debug] [Thread-3 (]: On model.flights_dbt.silver_airports: Close
[0m21:06:40.038825 [info ] [Thread-2 (]: 10 of 14 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:06:40.039326 [info ] [Thread-4 (]: 11 of 14 START sql view model raw.silver_flights ............................... [RUN]
[0m21:06:40.039739 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-4936-1ba0-9408-cb41dc7c96e8) - Closing
[0m21:06:40.228620 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:06:40.229649 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:06:40.230371 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124ff4950>]}
[0m21:06:40.230788 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:06:40.231200 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:06:40.232487 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:06:40.232099 [info ] [Thread-3 (]: 7 of 14 OK created sql view model raw.silver_airports .......................... [[32mOK[0m in 1.84s]
[0m21:06:40.233055 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:06:40.239008 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:06:40.240510 [debug] [Thread-3 (]: Finished running node model.flights_dbt.silver_airports
[0m21:06:40.252499 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:06:40.252878 [debug] [Thread-2 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:06:40.254602 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:06:40.255492 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:06:40.256051 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:06:40.256405 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_flights
[0m21:06:40.258293 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:06:40.258964 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:06:40.259434 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:06:40.259660 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:06:40.259979 [debug] [Thread-2 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:06:40.260192 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:06:40.260798 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:06:40.261000 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    -- models/silver/silver_flights.sql

select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:06:40.261173 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:06:40.959999 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-4a33-119b-84c3-beda7c4aac21) - Created
[0m21:06:40.964380 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-4a32-126d-90ae-dbd364626cb9) - Created
[0m21:06:41.541888 [debug] [Thread-1 (]: SQL status: OK in 3.090 seconds
[0m21:06:41.544042 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c2-4936-1983-a1f2-cb95bc13d9a2, command-id=01f089c2-4951-1ee3-8181-82dcf66c7764) - Closing
[0m21:06:41.549123 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:06:41.566139 [debug] [Thread-1 (]: On model.flights_dbt.stg_airlines: Close
[0m21:06:41.566480 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-4936-1983-a1f2-cb95bc13d9a2) - Closing
[0m21:06:41.710326 [debug] [Thread-2 (]: SQL status: OK in 1.450 seconds
[0m21:06:41.712805 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c2-4a32-126d-90ae-dbd364626cb9, command-id=01f089c2-4a4d-15c0-a3ee-b9d3c7bad37f) - Closing
[0m21:06:41.714089 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:06:41.770022 [debug] [Thread-4 (]: SQL status: OK in 1.510 seconds
[0m21:06:41.772240 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c2-4a33-119b-84c3-beda7c4aac21, command-id=01f089c2-4a4e-1153-a842-da555f4fec92) - Closing
[0m21:06:41.773159 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:06:41.775444 [debug] [Thread-2 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:06:41.775873 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-4a32-126d-90ae-dbd364626cb9) - Closing
[0m21:06:41.982609 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: Close
[0m21:06:41.983686 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-4a33-119b-84c3-beda7c4aac21) - Closing
[0m21:06:42.192790 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124ff7350>]}
[0m21:06:42.193830 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124ff7d10>]}
[0m21:06:42.194511 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e425c595-dc48-48a7-ad13-238b082cc586', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124ff7770>]}
[0m21:06:42.195684 [info ] [Thread-1 (]: 5 of 14 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.80s]
[0m21:06:42.196367 [info ] [Thread-2 (]: 10 of 14 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 2.15s]
[0m21:06:42.197031 [info ] [Thread-4 (]: 11 of 14 OK created sql view model raw.silver_flights .......................... [[32mOK[0m in 2.15s]
[0m21:06:42.197590 [debug] [Thread-1 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:06:42.198011 [debug] [Thread-2 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:06:42.198396 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_flights
[0m21:06:42.199201 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m21:06:42.199614 [debug] [Thread-1 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m21:06:42.200203 [debug] [Thread-2 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:06:42.199906 [info ] [Thread-3 (]: 12 of 14 START test not_null_my_second_dbt_model_id ............................ [RUN]
[0m21:06:42.200648 [info ] [Thread-1 (]: 13 of 14 START test unique_my_second_dbt_model_id .............................. [RUN]
[0m21:06:42.201056 [info ] [Thread-2 (]: 14 of 14 SKIP relation raw.gold_flight_metrics ................................. [[33mSKIP[0m]
[0m21:06:42.201718 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778) - Creating connection
[0m21:06:42.202163 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493) - Creating connection
[0m21:06:42.202511 [debug] [Thread-2 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:06:42.202817 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778'
[0m21:06:42.203102 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493'
[0m21:06:42.203385 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'skipped'. 
[0m21:06:42.203691 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m21:06:42.203958 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m21:06:42.210631 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m21:06:42.217565 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m21:06:42.219149 [debug] [Thread-1 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m21:06:42.219423 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m21:06:42.221395 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m21:06:42.223724 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m21:06:42.224200 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m21:06:42.224495 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from `flight_db`.`raw`.`my_second_dbt_model`
where id is null



  
  
      
    ) dbt_internal_test
[0m21:06:42.224733 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:06:42.225051 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m21:06:42.225256 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where id is not null
group by id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:06:42.225493 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:06:42.955808 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-4b62-1b9a-ba4c-ec77f1c40901) - Created
[0m21:06:42.983638 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-4b66-1cc9-abee-74ed128ac1a5) - Created
[0m21:06:43.365340 [debug] [Thread-3 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from `flight_db`.`raw`.`my_second_dbt_model`
where id is null



  
  
      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c2-4b7d-1dce-90f4-8240c90de947
[0m21:06:43.366468 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
[0m21:06:43.366798 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-4b62-1b9a-ba4c-ec77f1c40901) - Closing
[0m21:06:43.392529 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where id is not null
group by id
having count(*) > 1



  
  
      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c2-4b82-1b17-b6d2-73777aabab1a
[0m21:06:43.599595 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m21:06:43.600304 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-4b66-1cc9-abee-74ed128ac1a5) - Closing
[0m21:06:43.607311 [debug] [Thread-3 (]: Database Error in test not_null_my_second_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
[0m21:06:43.804285 [error] [Thread-3 (]: 12 of 14 ERROR not_null_my_second_dbt_model_id ................................. [[31mERROR[0m in 1.60s]
[0m21:06:43.805224 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m21:06:43.805854 [debug] [Thread-7 (]: Marking all children of 'test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778' to be skipped because of status 'error'.  Reason: Database Error in test not_null_my_second_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql.
[0m21:06:43.810565 [debug] [Thread-1 (]: Database Error in test unique_my_second_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/unique_my_second_dbt_model_id.sql
[0m21:06:43.811248 [error] [Thread-1 (]: 13 of 14 ERROR unique_my_second_dbt_model_id ................................... [[31mERROR[0m in 1.61s]
[0m21:06:43.811813 [debug] [Thread-1 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m21:06:43.812458 [debug] [Thread-7 (]: Marking all children of 'test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493' to be skipped because of status 'error'.  Reason: Database Error in test unique_my_second_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/unique_my_second_dbt_model_id.sql.
[0m21:06:43.814414 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:06:43.814750 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:06:43.815292 [info ] [MainThread]: 
[0m21:06:43.815572 [info ] [MainThread]: Finished running 2 table models, 4 data tests, 8 view models in 0 hours 0 minutes and 10.90 seconds (10.90s).
[0m21:06:43.817459 [debug] [MainThread]: Command end result
[0m21:06:43.917275 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:06:43.917994 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:06:43.920265 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:06:43.920356 [info ] [MainThread]: 
[0m21:06:43.920458 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m21:06:43.920550 [info ] [MainThread]: 
[0m21:06:43.920667 [error] [MainThread]: [31mFailure in model bronze_airlines (models/bronze/bronze_airlines.sql)[0m
[0m21:06:43.920776 [error] [MainThread]:   Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:06:43.920866 [info ] [MainThread]: 
[0m21:06:43.920956 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:06:43.921033 [info ] [MainThread]: 
[0m21:06:43.921125 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
[0m21:06:43.921222 [error] [MainThread]:   Database Error in test not_null_my_second_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
[0m21:06:43.921301 [info ] [MainThread]: 
[0m21:06:43.921386 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
[0m21:06:43.921465 [info ] [MainThread]: 
[0m21:06:43.921556 [error] [MainThread]: [31mFailure in test unique_my_second_dbt_model_id (models/example/schema.yml)[0m
[0m21:06:43.921651 [error] [MainThread]:   Database Error in test unique_my_second_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/unique_my_second_dbt_model_id.sql
[0m21:06:43.921728 [info ] [MainThread]: 
[0m21:06:43.921813 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/example/schema.yml/unique_my_second_dbt_model_id.sql
[0m21:06:43.921888 [info ] [MainThread]: 
[0m21:06:43.921978 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=3 SKIP=2 NO-OP=0 TOTAL=14
[0m21:06:43.923760 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 12.123973, "process_in_blocks": "0", "process_kernel_time": 0.29601, "process_mem_max_rss": "258244608", "process_out_blocks": "0", "process_user_time": 3.238652}
[0m21:06:43.923890 [debug] [MainThread]: Command `dbt build` failed at 21:06:43.923864 after 12.12 seconds
[0m21:06:43.924000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107309f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125bb7a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125bb7650>]}
[0m21:06:43.924103 [debug] [MainThread]: Flushing usage events
[0m21:06:44.735819 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:09:57.152029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068d3620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107eff890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107effb10>]}


============================== 21:09:57.154308 | 86f915eb-0224-49b3-897f-ea4de9b18d7c ==============================
[0m21:09:57.154308 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:09:57.154536 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'empty': 'False', 'invocation_command': 'dbt build', 'version_check': 'True', 'static_parser': 'True', 'use_colors': 'True', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': '/Users/artakerqeli/.dbt', 'fail_fast': 'False', 'partial_parse': 'True', 'printer_width': '80', 'debug': 'False', 'log_cache_events': 'False', 'write_json': 'True', 'log_format': 'default', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'no_print': 'None', 'quiet': 'False', 'target_path': 'None', 'cache_selected_only': 'False'}
[0m21:09:57.455368 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:09:57.455557 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:09:57.455651 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:09:57.904820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d27360>]}
[0m21:09:57.924137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11160aad0>]}
[0m21:09:57.924376 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:09:57.974378 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:09:58.034525 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:09:58.034797 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/example/my_first_dbt_model.sql
[0m21:09:58.170489 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:09:58.175397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121845050>]}
[0m21:09:58.211388 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:09:58.212415 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:09:58.223983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121815e50>]}
[0m21:09:58.224159 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:09:58.225144 [info ] [MainThread]: 
[0m21:09:58.225266 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:09:58.225353 [info ] [MainThread]: 
[0m21:09:58.225546 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:09:58.225644 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:09:58.228223 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:09:58.228347 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:09:58.231817 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:09:58.231928 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:09:58.232016 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:09:59.033987 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-c03f-1f5f-b58a-7aabcf5a600b) - Created
[0m21:09:59.406587 [debug] [ThreadPool]: SQL status: OK in 1.170 seconds
[0m21:09:59.414324 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c2-c03f-1f5f-b58a-7aabcf5a600b, command-id=01f089c2-c05d-1518-9bf2-ca82b3368467) - Closing
[0m21:09:59.414797 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:09:59.414991 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-c03f-1f5f-b58a-7aabcf5a600b) - Closing
[0m21:09:59.617505 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:09:59.618057 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:09:59.626927 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:09:59.627433 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:09:59.627714 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:10:00.288556 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-c100-17e5-89fe-e70379b23eb2) - Created
[0m21:10:00.803271 [debug] [ThreadPool]: SQL status: OK in 1.180 seconds
[0m21:10:00.807951 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c2-c100-17e5-89fe-e70379b23eb2, command-id=01f089c2-c11b-1966-851a-9b76e628452b) - Closing
[0m21:10:00.808950 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:10:00.809220 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-c100-17e5-89fe-e70379b23eb2) - Closing
[0m21:10:00.995781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1219126d0>]}
[0m21:10:00.999873 [debug] [Thread-3 (]: Began running node model.flights_dbt.bronze_flights
[0m21:10:01.000347 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:10:01.000690 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airlines
[0m21:10:01.000988 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_airports
[0m21:10:01.001591 [info ] [Thread-3 (]: 3 of 14 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:10:01.002163 [info ] [Thread-4 (]: 4 of 14 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:10:01.002668 [info ] [Thread-1 (]: 1 of 14 START sql view model raw.bronze_airlines ............................... [RUN]
[0m21:10:01.003214 [info ] [Thread-2 (]: 2 of 14 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:10:01.004013 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:10:01.004606 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:10:01.005065 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airlines) - Creating connection
[0m21:10:01.005457 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:10:01.005791 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:10:01.006073 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:10:01.006327 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airlines'
[0m21:10:01.006584 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:10:01.006943 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:10:01.007232 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:10:01.007479 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airlines
[0m21:10:01.007708 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:10:01.015600 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:10:01.017657 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:10:01.018897 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airlines"
[0m21:10:01.021001 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:10:01.022142 [debug] [Thread-3 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:10:01.022444 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airlines
[0m21:10:01.022684 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:10:01.022892 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:10:01.032540 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:10:01.033780 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:10:01.034841 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:10:01.036024 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:10:01.037401 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:10:01.037694 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:10:01.037940 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:10:01.038210 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:10:01.038428 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123a04120>]}
[0m21:10:01.038572 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120ff9550>]}
[0m21:10:01.038703 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120ff9790>]}
[0m21:10:01.038833 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120fbb330>]}
[0m21:10:01.046094 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airlines`
[0m21:10:01.047275 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:10:01.047646 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:10:01.048002 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:10:01.051988 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airlines"
[0m21:10:01.052320 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:10:01.052619 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:10:01.052908 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:10:01.053351 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:10:01.053484 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:10:01.053677 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    SELECT
    flight_id,
    origin,
    destination AS dest,  -- or the correct column name
    airline,
    arr_time
FROM `flight_db`.`raw`.`flights`
  )

[0m21:10:01.053847 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airlines"
[0m21:10:01.053993 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:10:01.054137 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:10:01.054253 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:10:01.054402 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

[0m21:10:01.054531 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:10:01.054739 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:10:01.054862 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:10:01.055065 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:10:01.771890 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-c1e4-1765-af97-ad750c090e59) - Created
[0m21:10:01.790965 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-c1e8-15e1-ab53-8c492669e5ec) - Created
[0m21:10:01.806888 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-c1e7-1cd9-9da6-bf74bfd6465b) - Created
[0m21:10:01.808785 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-c1e9-10b6-b7cc-2cc55817839e) - Created
[0m21:10:02.278293 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c2-c203-126f-915b-cf5a5c5f11fb
[0m21:10:02.279819 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: Close
[0m21:10:02.280383 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-c1e7-1cd9-9da6-bf74bfd6465b) - Closing
[0m21:10:02.427595 [debug] [Thread-4 (]: SQL status: OK in 1.370 seconds
[0m21:10:02.429137 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c2-c1e8-15e1-ab53-8c492669e5ec, command-id=01f089c2-c202-1120-8c9a-0f72a6e71bd5) - Closing
[0m21:10:02.442562 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:10:02.452085 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:10:02.452451 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-c1e8-15e1-ab53-8c492669e5ec) - Closing
[0m21:10:02.461488 [debug] [Thread-1 (]: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:10:02.468758 [debug] [Thread-3 (]: SQL status: OK in 1.410 seconds
[0m21:10:02.469520 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c2-c1e4-1765-af97-ad750c090e59, command-id=01f089c2-c202-1b12-b701-83bf571cc100) - Closing
[0m21:10:02.470018 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:10:02.498873 [debug] [Thread-2 (]: SQL status: OK in 1.440 seconds
[0m21:10:02.499565 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c2-c1e9-10b6-b7cc-2cc55817839e, command-id=01f089c2-c205-1416-8ed1-9b91e7640882) - Closing
[0m21:10:02.500046 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:10:02.639605 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: Close
[0m21:10:02.641816 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-c1e4-1765-af97-ad750c090e59) - Closing
[0m21:10:02.644098 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ce9ed0>]}
[0m21:10:02.644971 [error] [Thread-1 (]: 1 of 14 ERROR creating sql view model raw.bronze_airlines ...................... [[31mERROR[0m in 1.63s]
[0m21:10:02.645592 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airlines
[0m21:10:02.646017 [debug] [Thread-1 (]: Began running node model.flights_dbt.stg_airlines
[0m21:10:02.646530 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.bronze_airlines' to be skipped because of status 'error'.  Reason: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql.
[0m21:10:02.647041 [info ] [Thread-1 (]: 5 of 14 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:10:02.832480 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: Close
[0m21:10:02.833571 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-c1e9-10b6-b7cc-2cc55817839e) - Closing
[0m21:10:03.021242 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121a70c90>]}
[0m21:10:03.022392 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:10:03.022913 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121ada580>]}
[0m21:10:03.023449 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121a382f0>]}
[0m21:10:03.024646 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:10:03.024289 [info ] [Thread-4 (]: 4 of 14 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.02s]
[0m21:10:03.025403 [info ] [Thread-3 (]: 3 of 14 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.02s]
[0m21:10:03.026376 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:10:03.026072 [info ] [Thread-2 (]: 2 of 14 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.02s]
[0m21:10:03.026979 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:10:03.027420 [debug] [Thread-3 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:10:03.031728 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:10:03.032683 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:10:03.033061 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_airlines
[0m21:10:03.033790 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:10:03.034136 [debug] [Thread-2 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:10:03.034574 [info ] [Thread-4 (]: 6 of 14 SKIP relation raw.silver_airlines ...................................... [[33mSKIP[0m]
[0m21:10:03.035000 [info ] [Thread-3 (]: 7 of 14 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:10:03.035450 [info ] [Thread-2 (]: 8 of 14 START test unique_my_first_dbt_model_flight_id ......................... [RUN]
[0m21:10:03.035877 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:10:03.036175 [debug] [Thread-1 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:10:03.036776 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:10:03.037118 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:10:03.037387 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_airports
[0m21:10:03.037598 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.silver_airlines' to be skipped because of status 'skipped'. 
[0m21:10:03.053222 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m21:10:03.053493 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:10:03.053673 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:10:03.053954 [info ] [Thread-4 (]: 9 of 14 START sql view model raw.silver_airports ............................... [RUN]
[0m21:10:03.065876 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:10:03.072704 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:10:03.072868 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:10:03.073088 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:10:03.078353 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:10:03.080896 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:10:03.081049 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:10:03.081269 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:10:03.081435 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:10:03.081633 [debug] [Thread-1 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:10:03.083046 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:10:03.083212 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:10:03.083348 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:10:03.083485 [debug] [Thread-2 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:10:03.090120 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_airports
[0m21:10:03.090931 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:10:03.092034 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:10:03.092763 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:10:03.093265 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:10:03.093682 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:10:03.093822 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:10:03.093961 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:10:03.094071 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:10:03.094189 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:10:03.094327 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:10:03.094518 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:10:03.094629 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:10:03.094782 [debug] [Thread-4 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:10:03.094949 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:10:03.752773 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-c312-16bd-84ba-8f5465555134) - Created
[0m21:10:03.772743 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-c313-1712-98fd-77aa0a424e1a) - Created
[0m21:10:03.779264 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-c315-1322-99fb-cdeef4cbda76) - Created
[0m21:10:03.807653 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-c31a-145e-a516-a08a5f8bfedb) - Created
[0m21:10:04.275158 [debug] [Thread-3 (]: SQL status: OK in 1.180 seconds
[0m21:10:04.275663 [debug] [Thread-2 (]: SQL status: OK in 1.180 seconds
[0m21:10:04.280140 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c2-c313-1712-98fd-77aa0a424e1a, command-id=01f089c2-c32e-1e9b-85c7-0d8fca5af91c) - Closing
[0m21:10:04.281329 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c2-c315-1322-99fb-cdeef4cbda76, command-id=01f089c2-c330-1237-9480-190ef720f4eb) - Closing
[0m21:10:04.283621 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:10:04.284153 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-c313-1712-98fd-77aa0a424e1a) - Closing
[0m21:10:04.470086 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:10:04.471089 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-c315-1322-99fb-cdeef4cbda76) - Closing
[0m21:10:04.661528 [info ] [Thread-3 (]: 7 of 14 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.62s]
[0m21:10:04.662521 [info ] [Thread-2 (]: 8 of 14 PASS unique_my_first_dbt_model_flight_id ............................... [[32mPASS[0m in 1.63s]
[0m21:10:04.663633 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:10:04.664225 [debug] [Thread-2 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:10:04.665237 [debug] [Thread-3 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:10:04.665634 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_flights
[0m21:10:04.666179 [info ] [Thread-3 (]: 10 of 14 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:10:04.666653 [info ] [Thread-2 (]: 11 of 14 START sql view model raw.silver_flights ............................... [RUN]
[0m21:10:04.667290 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:10:04.667770 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:10:04.668149 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:10:04.668527 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:10:04.668887 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:10:04.669345 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:10:04.673895 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:10:04.682374 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:10:04.682870 [debug] [Thread-3 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:10:04.684547 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:10:04.685412 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:10:04.686010 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:10:04.686366 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_flights
[0m21:10:04.687963 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:10:04.688696 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:10:04.689198 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:10:04.689607 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:10:04.689975 [debug] [Thread-3 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:10:04.690222 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:10:04.690389 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:10:04.690753 [debug] [Thread-2 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    -- models/silver/silver_flights.sql

select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:10:04.691005 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:10:04.728793 [debug] [Thread-4 (]: SQL status: OK in 1.630 seconds
[0m21:10:04.729262 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c2-c31a-145e-a516-a08a5f8bfedb, command-id=01f089c2-c335-144d-9b69-83c4afe460e7) - Closing
[0m21:10:04.729569 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:10:04.729921 [debug] [Thread-4 (]: On model.flights_dbt.silver_airports: Close
[0m21:10:04.730069 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-c31a-145e-a516-a08a5f8bfedb) - Closing
[0m21:10:04.920123 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123adda30>]}
[0m21:10:04.920542 [info ] [Thread-4 (]: 9 of 14 OK created sql view model raw.silver_airports .......................... [[32mOK[0m in 1.85s]
[0m21:10:04.920821 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_airports
[0m21:10:05.426347 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-c40b-1756-b794-27f6729cd050) - Created
[0m21:10:05.479275 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-c40e-1011-a8c1-95ace2a48482) - Created
[0m21:10:05.761836 [debug] [Thread-1 (]: SQL status: OK in 2.680 seconds
[0m21:10:05.763399 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c2-c312-16bd-84ba-8f5465555134, command-id=01f089c2-c32d-1f97-9075-941ed522fdab) - Closing
[0m21:10:05.767876 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:10:05.781355 [debug] [Thread-1 (]: On model.flights_dbt.stg_airlines: Close
[0m21:10:05.781651 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-c312-16bd-84ba-8f5465555134) - Closing
[0m21:10:05.974762 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123a53350>]}
[0m21:10:05.976258 [info ] [Thread-1 (]: 5 of 14 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.33s]
[0m21:10:05.976989 [debug] [Thread-1 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:10:06.179431 [debug] [Thread-3 (]: SQL status: OK in 1.490 seconds
[0m21:10:06.180941 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c2-c40b-1756-b794-27f6729cd050, command-id=01f089c2-c43d-1328-bb54-a360ec7a252f) - Closing
[0m21:10:06.181879 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:10:06.182895 [debug] [Thread-3 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:10:06.183238 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-c40b-1756-b794-27f6729cd050) - Closing
[0m21:10:06.305461 [debug] [Thread-2 (]: SQL status: OK in 1.610 seconds
[0m21:10:06.307808 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c2-c40e-1011-a8c1-95ace2a48482, command-id=01f089c2-c450-1b80-aca3-4e3c1fa2c11e) - Closing
[0m21:10:06.308707 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:10:06.405396 [debug] [Thread-2 (]: On model.flights_dbt.silver_flights: Close
[0m21:10:06.406428 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-c40e-1011-a8c1-95ace2a48482) - Closing
[0m21:10:06.640082 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123adc7d0>]}
[0m21:10:06.641091 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86f915eb-0224-49b3-897f-ea4de9b18d7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123adec30>]}
[0m21:10:06.642617 [info ] [Thread-3 (]: 10 of 14 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.97s]
[0m21:10:06.643915 [debug] [Thread-3 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:10:06.643429 [info ] [Thread-2 (]: 11 of 14 OK created sql view model raw.silver_flights .......................... [[32mOK[0m in 1.97s]
[0m21:10:06.644617 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_flights
[0m21:10:06.645139 [debug] [Thread-4 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m21:10:06.645518 [debug] [Thread-1 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m21:10:06.645807 [info ] [Thread-4 (]: 12 of 14 START test not_null_my_second_dbt_model_id ............................ [RUN]
[0m21:10:06.646194 [debug] [Thread-3 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:10:06.646494 [info ] [Thread-1 (]: 13 of 14 START test unique_my_second_dbt_model_id .............................. [RUN]
[0m21:10:06.647138 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778) - Creating connection
[0m21:10:06.647552 [info ] [Thread-3 (]: 14 of 14 SKIP relation raw.gold_flight_metrics ................................. [[33mSKIP[0m]
[0m21:10:06.648016 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493) - Creating connection
[0m21:10:06.648335 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778'
[0m21:10:06.648677 [debug] [Thread-3 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:10:06.648940 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493'
[0m21:10:06.649187 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m21:10:06.649468 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'skipped'. 
[0m21:10:06.649748 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m21:10:06.656111 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m21:10:06.661082 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m21:10:06.661783 [debug] [Thread-4 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m21:10:06.662026 [debug] [Thread-1 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m21:10:06.663738 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m21:10:06.665581 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m21:10:06.665944 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778"
[0m21:10:06.666171 [debug] [Thread-4 (]: On test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from `flight_db`.`raw`.`my_second_dbt_model`
where id is null



  
  
      
    ) dbt_internal_test
[0m21:10:06.666422 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:10:06.666834 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493"
[0m21:10:06.667041 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where id is not null
group by id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:10:06.667268 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:10:07.361999 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-c539-1c8a-8912-dd51eb93c228) - Created
[0m21:10:07.397731 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-c53d-1ac6-8ba5-4cb05172b5e9) - Created
[0m21:10:07.711947 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where id is not null
group by id
having count(*) > 1



  
  
      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c2-c554-18b1-8536-dca3fd5b7dbb
[0m21:10:07.713362 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m21:10:07.713738 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-c539-1c8a-8912-dd51eb93c228) - Closing
[0m21:10:07.772068 [debug] [Thread-4 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select id
from `flight_db`.`raw`.`my_second_dbt_model`
where id is null



  
  
      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c2-c558-1cd2-b128-08e48f564410
[0m21:10:07.916675 [debug] [Thread-4 (]: On test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
[0m21:10:07.917746 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-c53d-1ac6-8ba5-4cb05172b5e9) - Closing
[0m21:10:07.925471 [debug] [Thread-1 (]: Database Error in test unique_my_second_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/unique_my_second_dbt_model_id.sql
[0m21:10:08.114828 [error] [Thread-1 (]: 13 of 14 ERROR unique_my_second_dbt_model_id ................................... [[31mERROR[0m in 1.47s]
[0m21:10:08.115731 [debug] [Thread-1 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493
[0m21:10:08.116292 [debug] [Thread-7 (]: Marking all children of 'test.flights_dbt.unique_my_second_dbt_model_id.57a0f8c493' to be skipped because of status 'error'.  Reason: Database Error in test unique_my_second_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/unique_my_second_dbt_model_id.sql.
[0m21:10:08.120859 [debug] [Thread-4 (]: Database Error in test not_null_my_second_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
[0m21:10:08.121337 [error] [Thread-4 (]: 12 of 14 ERROR not_null_my_second_dbt_model_id ................................. [[31mERROR[0m in 1.47s]
[0m21:10:08.121783 [debug] [Thread-4 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778
[0m21:10:08.122166 [debug] [Thread-7 (]: Marking all children of 'test.flights_dbt.not_null_my_second_dbt_model_id.151b76d778' to be skipped because of status 'error'.  Reason: Database Error in test not_null_my_second_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql.
[0m21:10:08.123854 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:10:08.124242 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:10:08.124773 [info ] [MainThread]: 
[0m21:10:08.125069 [info ] [MainThread]: Finished running 2 table models, 4 data tests, 8 view models in 0 hours 0 minutes and 9.90 seconds (9.90s).
[0m21:10:08.126935 [debug] [MainThread]: Command end result
[0m21:10:08.217728 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:10:08.218426 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:10:08.220912 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:10:08.221002 [info ] [MainThread]: 
[0m21:10:08.221104 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m21:10:08.221199 [info ] [MainThread]: 
[0m21:10:08.221307 [error] [MainThread]: [31mFailure in model bronze_airlines (models/bronze/bronze_airlines.sql)[0m
[0m21:10:08.221421 [error] [MainThread]:   Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:10:08.221505 [info ] [MainThread]: 
[0m21:10:08.221599 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:10:08.221675 [info ] [MainThread]: 
[0m21:10:08.221770 [error] [MainThread]: [31mFailure in test unique_my_second_dbt_model_id (models/example/schema.yml)[0m
[0m21:10:08.221871 [error] [MainThread]:   Database Error in test unique_my_second_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/unique_my_second_dbt_model_id.sql
[0m21:10:08.221947 [info ] [MainThread]: 
[0m21:10:08.222038 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/example/schema.yml/unique_my_second_dbt_model_id.sql
[0m21:10:08.222112 [info ] [MainThread]: 
[0m21:10:08.222206 [error] [MainThread]: [31mFailure in test not_null_my_second_dbt_model_id (models/example/schema.yml)[0m
[0m21:10:08.222306 [error] [MainThread]:   Database Error in test not_null_my_second_dbt_model_id (models/example/schema.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `id` cannot be resolved. Did you mean one of the following? [`origin`, `airline`, `arr_time`, `flight_id`, `arr_delay`]. SQLSTATE: 42703; line 18 pos 6
  compiled code at target/run/flights_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
[0m21:10:08.222382 [info ] [MainThread]: 
[0m21:10:08.222472 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/example/schema.yml/not_null_my_second_dbt_model_id.sql
[0m21:10:08.222547 [info ] [MainThread]: 
[0m21:10:08.222637 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=3 SKIP=2 NO-OP=0 TOTAL=14
[0m21:10:08.224424 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 11.104758, "process_in_blocks": "0", "process_kernel_time": 0.29111, "process_mem_max_rss": "258064384", "process_out_blocks": "0", "process_user_time": 2.847431}
[0m21:10:08.224559 [debug] [MainThread]: Command `dbt build` failed at 21:10:08.224531 after 11.10 seconds
[0m21:10:08.224670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1249bb7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1249bbd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1249bb710>]}
[0m21:10:08.224767 [debug] [MainThread]: Flushing usage events
[0m21:10:09.005750 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:11:36.049408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045c3620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055df890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055dfb10>]}


============================== 21:11:36.051715 | 55eff430-b85a-4379-a846-651017aba097 ==============================
[0m21:11:36.051715 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:11:36.051959 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'quiet': 'False', 'invocation_command': 'dbt build', 'use_colors': 'True', 'empty': 'False', 'partial_parse': 'True', 'indirect_selection': 'eager', 'static_parser': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'introspect': 'True', 'write_json': 'True', 'profiles_dir': '/Users/artakerqeli/.dbt', 'log_format': 'default', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'no_print': 'None', 'printer_width': '80', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'warn_error': 'None'}
[0m21:11:36.353929 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:11:36.354117 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:11:36.354210 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:11:36.815308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104907360>]}
[0m21:11:36.834790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067eaad0>]}
[0m21:11:36.835034 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:11:36.896401 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:11:36.956554 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m21:11:36.956859 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/example/schema.yml
[0m21:11:36.957003 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/silver/silver_flights.sql
[0m21:11:37.095267 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:11:37.100184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c83d150>]}
[0m21:11:37.136096 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:11:37.137090 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:11:37.147910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7fdc70>]}
[0m21:11:37.148096 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:11:37.149081 [info ] [MainThread]: 
[0m21:11:37.149202 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:11:37.149288 [info ] [MainThread]: 
[0m21:11:37.149477 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:11:37.149567 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:11:37.152141 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:11:37.152258 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:11:37.155723 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:11:37.155836 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:11:37.155930 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:11:37.846702 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-fb27-1d92-9f83-7339be824a07) - Created
[0m21:11:38.285130 [debug] [ThreadPool]: SQL status: OK in 1.130 seconds
[0m21:11:38.293985 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c2-fb27-1d92-9f83-7339be824a07, command-id=01f089c2-fb45-181b-a193-ad31a4027fe3) - Closing
[0m21:11:38.294425 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:11:38.294617 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-fb27-1d92-9f83-7339be824a07) - Closing
[0m21:11:38.492722 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:11:38.493324 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:11:38.502428 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:11:38.502935 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:11:38.503291 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:11:39.198959 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-fbf4-1cdb-8e3f-fdc6953a3310) - Created
[0m21:11:39.651766 [debug] [ThreadPool]: SQL status: OK in 1.150 seconds
[0m21:11:39.655090 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c2-fbf4-1cdb-8e3f-fdc6953a3310, command-id=01f089c2-fc15-127d-8673-5e62f7b17376) - Closing
[0m21:11:39.655795 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:11:39.655998 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c2-fbf4-1cdb-8e3f-fdc6953a3310) - Closing
[0m21:11:39.874056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c90f5b0>]}
[0m21:11:39.878473 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_airports
[0m21:11:39.878902 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airlines
[0m21:11:39.879223 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:11:39.879486 [debug] [Thread-3 (]: Began running node model.flights_dbt.bronze_flights
[0m21:11:39.879902 [info ] [Thread-2 (]: 2 of 14 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:11:39.880255 [info ] [Thread-1 (]: 1 of 14 START sql view model raw.bronze_airlines ............................... [RUN]
[0m21:11:39.880559 [info ] [Thread-4 (]: 4 of 14 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:11:39.880966 [info ] [Thread-3 (]: 3 of 14 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:11:39.881535 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:11:39.881984 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airlines) - Creating connection
[0m21:11:39.882315 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:11:39.882617 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:11:39.882851 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:11:39.883061 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airlines'
[0m21:11:39.883256 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:11:39.883449 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:11:39.883668 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:11:39.883891 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airlines
[0m21:11:39.884064 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:11:39.884229 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:11:39.890161 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:11:39.891796 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airlines"
[0m21:11:39.892957 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:11:39.894835 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:11:39.895699 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:11:39.901542 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:11:39.901712 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airlines
[0m21:11:39.904343 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:11:39.904498 [debug] [Thread-3 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:11:39.905578 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:11:39.906453 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:11:39.907478 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:11:39.908541 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:11:39.908975 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:11:39.909234 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:11:39.909439 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc08120>]}
[0m21:11:39.909654 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:11:39.909819 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c99d490>]}
[0m21:11:39.909943 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c99d610>]}
[0m21:11:39.916389 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7d3a10>]}
[0m21:11:39.916500 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:11:39.916859 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:11:39.917178 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airlines`
[0m21:11:39.917497 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:11:39.921549 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:11:39.921855 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:11:39.922125 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airlines"
[0m21:11:39.922393 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:11:39.922731 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airlines"
[0m21:11:39.922861 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:11:39.922998 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

[0m21:11:39.923092 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:11:39.923232 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:11:39.923386 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:11:39.923494 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:11:39.923618 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    SELECT
    flight_id,
    origin,
    destination AS dest,  -- or the correct column name
    airline,
    arr_time
FROM `flight_db`.`raw`.`flights`
  )

[0m21:11:39.923738 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:11:39.923946 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:11:39.924072 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:11:39.924273 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:11:40.619822 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-fccd-1eae-bd39-56c160503fb7) - Created
[0m21:11:40.689957 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-fcd9-18f6-9e37-cd3554dee6e4) - Created
[0m21:11:40.694484 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-fcda-1035-acf9-a984e2a5ec2d) - Created
[0m21:11:40.696299 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-fcda-1062-aa62-389e8428cad6) - Created
[0m21:11:41.175453 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c2-fcf6-1b3b-b196-a0e99878928f
[0m21:11:41.176931 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: Close
[0m21:11:41.177306 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-fcda-1062-aa62-389e8428cad6) - Closing
[0m21:11:41.262369 [debug] [Thread-4 (]: SQL status: OK in 1.340 seconds
[0m21:11:41.264871 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c2-fccd-1eae-bd39-56c160503fb7, command-id=01f089c2-fce9-1c13-9d72-ba0b7e42d582) - Closing
[0m21:11:41.274817 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:11:41.374115 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:11:41.374733 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-fccd-1eae-bd39-56c160503fb7) - Closing
[0m21:11:41.377993 [debug] [Thread-2 (]: SQL status: OK in 1.450 seconds
[0m21:11:41.379171 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c2-fcd9-18f6-9e37-cd3554dee6e4, command-id=01f089c2-fcf4-19a1-8bde-d1ab19b3656e) - Closing
[0m21:11:41.379936 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:11:41.389902 [debug] [Thread-1 (]: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:11:41.401552 [debug] [Thread-3 (]: SQL status: OK in 1.480 seconds
[0m21:11:41.402527 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c2-fcda-1035-acf9-a984e2a5ec2d, command-id=01f089c2-fcf5-10ee-a8ef-e4e441cc9ad4) - Closing
[0m21:11:41.403190 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:11:41.547415 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: Close
[0m21:11:41.548435 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-fcd9-18f6-9e37-cd3554dee6e4) - Closing
[0m21:11:41.749393 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: Close
[0m21:11:41.751202 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-fcda-1035-acf9-a984e2a5ec2d) - Closing
[0m21:11:41.753471 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048c9ed0>]}
[0m21:11:41.754421 [error] [Thread-1 (]: 1 of 14 ERROR creating sql view model raw.bronze_airlines ...................... [[31mERROR[0m in 1.87s]
[0m21:11:41.755027 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airlines
[0m21:11:41.755461 [debug] [Thread-1 (]: Began running node model.flights_dbt.silver_flights
[0m21:11:41.756011 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.bronze_airlines' to be skipped because of status 'error'.  Reason: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql.
[0m21:11:41.756542 [info ] [Thread-1 (]: 5 of 14 START sql view model raw.silver_flights ................................ [RUN]
[0m21:11:41.967909 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca6b8c0>]}
[0m21:11:41.968932 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca9cec0>]}
[0m21:11:41.969701 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:11:41.970254 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca4ce30>]}
[0m21:11:41.971083 [info ] [Thread-4 (]: 4 of 14 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.09s]
[0m21:11:41.972181 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:11:41.971847 [info ] [Thread-2 (]: 2 of 14 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.09s]
[0m21:11:41.972805 [info ] [Thread-3 (]: 3 of 14 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.09s]
[0m21:11:41.973364 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:11:41.973706 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:11:41.974141 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:11:41.974553 [debug] [Thread-3 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:11:41.974916 [debug] [Thread-4 (]: Began running node model.flights_dbt.stg_airlines
[0m21:11:41.978061 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:11:41.978517 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_airlines
[0m21:11:41.978874 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:11:41.979343 [info ] [Thread-4 (]: 6 of 14 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:11:41.979789 [info ] [Thread-2 (]: 7 of 14 SKIP relation raw.silver_airlines ...................................... [[33mSKIP[0m]
[0m21:11:41.980155 [info ] [Thread-3 (]: 8 of 14 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:11:41.980723 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:11:41.981088 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:11:41.981470 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:11:41.981758 [debug] [Thread-1 (]: Began executing node model.flights_dbt.silver_flights
[0m21:11:41.981993 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:11:41.982270 [debug] [Thread-2 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:11:41.982499 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.silver_airlines' to be skipped because of status 'skipped'. 
[0m21:11:41.982747 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:11:41.986001 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:11:41.986350 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:11:41.986659 [info ] [Thread-2 (]: 9 of 14 START test unique_my_first_dbt_model_flight_id ......................... [RUN]
[0m21:11:41.987107 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:11:41.987975 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:11:41.990588 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:11:41.991215 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:11:41.998265 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:11:42.000563 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:11:42.000850 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:11:42.001244 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:11:42.005293 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:11:42.005640 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:11:42.005826 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:11:42.006030 [debug] [Thread-4 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:11:42.015231 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:11:42.015461 [debug] [Thread-1 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:11:42.015639 [debug] [Thread-2 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:11:42.024304 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m21:11:42.024544 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:11:42.025552 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:11:42.039317 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:11:42.039518 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:11:42.039773 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:11:42.039915 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:11:42.040089 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:11:42.040271 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:11:42.040378 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:11:42.040488 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:11:42.040617 [debug] [Thread-4 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:11:42.040779 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:11:42.768607 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-fe15-1c58-aca0-49cf37d359f3) - Created
[0m21:11:42.771623 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-fe17-1463-b37a-86628975b3c1) - Created
[0m21:11:42.794186 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-fe1a-148b-8ee1-5811258c058f) - Created
[0m21:11:42.801498 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-fe1a-17d7-b160-f2c685675909) - Created
[0m21:11:43.206493 [debug] [Thread-2 (]: SQL status: OK in 1.170 seconds
[0m21:11:43.211399 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c2-fe1a-148b-8ee1-5811258c058f, command-id=01f089c2-fe36-11df-a49f-59799263aea7) - Closing
[0m21:11:43.213678 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:11:43.213965 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-fe1a-148b-8ee1-5811258c058f) - Closing
[0m21:11:43.251339 [debug] [Thread-3 (]: SQL status: OK in 1.210 seconds
[0m21:11:43.252996 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c2-fe1a-17d7-b160-f2c685675909, command-id=01f089c2-fe37-1379-9dcb-8e4a5dad2e6e) - Closing
[0m21:11:43.413632 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:11:43.414245 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-fe1a-17d7-b160-f2c685675909) - Closing
[0m21:11:43.467332 [debug] [Thread-1 (]: SQL status: OK in 1.440 seconds
[0m21:11:43.469268 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c2-fe17-1463-b37a-86628975b3c1, command-id=01f089c2-fe32-1ecf-8ed8-751fe55e927c) - Closing
[0m21:11:43.470238 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:11:43.621234 [debug] [Thread-1 (]: On model.flights_dbt.silver_flights: Close
[0m21:11:43.620379 [info ] [Thread-2 (]: 9 of 14 PASS unique_my_first_dbt_model_flight_id ............................... [[32mPASS[0m in 1.63s]
[0m21:11:43.622307 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c2-fe17-1463-b37a-86628975b3c1) - Closing
[0m21:11:43.623334 [debug] [Thread-2 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:11:43.624580 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_airports
[0m21:11:43.625422 [info ] [Thread-2 (]: 10 of 14 START sql view model raw.silver_airports .............................. [RUN]
[0m21:11:43.829873 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:11:43.830604 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d02e390>]}
[0m21:11:43.828948 [info ] [Thread-3 (]: 8 of 14 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.85s]
[0m21:11:43.831160 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:11:43.832571 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:11:43.832104 [info ] [Thread-1 (]: 5 of 14 OK created sql view model raw.silver_flights ........................... [[32mOK[0m in 2.07s]
[0m21:11:43.832996 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:11:43.833717 [debug] [Thread-1 (]: Finished running node model.flights_dbt.silver_flights
[0m21:11:43.834029 [debug] [Thread-3 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:11:43.838357 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:11:43.839004 [info ] [Thread-3 (]: 11 of 14 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:11:43.839780 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:11:43.840113 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:11:43.840387 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:11:43.843351 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_airports
[0m21:11:43.846620 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:11:43.852487 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:11:43.853725 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:11:43.854471 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:11:43.855052 [debug] [Thread-3 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:11:43.855294 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:11:43.856817 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:11:43.857070 [debug] [Thread-2 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:11:43.857778 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:11:43.857997 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:11:43.858510 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:11:43.859203 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:11:43.859428 [debug] [Thread-3 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:11:43.859626 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:11:44.535082 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-ff23-1ddf-a0f3-9e66cbd3a0eb) - Created
[0m21:11:44.540575 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-ff25-1ca4-8e60-4bd3876d39f8) - Created
[0m21:11:44.679830 [debug] [Thread-4 (]: SQL status: OK in 2.640 seconds
[0m21:11:44.681174 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c2-fe15-1c58-aca0-49cf37d359f3, command-id=01f089c2-fe31-157f-90ac-583838893752) - Closing
[0m21:11:44.687224 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:11:44.704255 [debug] [Thread-4 (]: On model.flights_dbt.stg_airlines: Close
[0m21:11:44.704603 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c2-fe15-1c58-aca0-49cf37d359f3) - Closing
[0m21:11:44.894826 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d02fef0>]}
[0m21:11:44.896365 [info ] [Thread-4 (]: 6 of 14 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 2.91s]
[0m21:11:44.897341 [debug] [Thread-4 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:11:45.235066 [debug] [Thread-2 (]: SQL status: OK in 1.380 seconds
[0m21:11:45.238268 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c2-ff23-1ddf-a0f3-9e66cbd3a0eb, command-id=01f089c2-ff3f-169b-9798-e48a57ca3f24) - Closing
[0m21:11:45.238861 [debug] [Thread-3 (]: SQL status: OK in 1.380 seconds
[0m21:11:45.239817 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:11:45.240823 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c2-ff25-1ca4-8e60-4bd3876d39f8, command-id=01f089c2-ff40-1f58-bea8-1ef819a32fad) - Closing
[0m21:11:45.241715 [debug] [Thread-2 (]: On model.flights_dbt.silver_airports: Close
[0m21:11:45.242376 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:11:45.242715 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c2-ff23-1ddf-a0f3-9e66cbd3a0eb) - Closing
[0m21:11:45.455780 [debug] [Thread-3 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:11:45.456543 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c2-ff25-1ca4-8e60-4bd3876d39f8) - Closing
[0m21:11:45.652234 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d02d850>]}
[0m21:11:45.653255 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '55eff430-b85a-4379-a846-651017aba097', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d02e0f0>]}
[0m21:11:45.654440 [info ] [Thread-2 (]: 10 of 14 OK created sql view model raw.silver_airports ......................... [[32mOK[0m in 2.03s]
[0m21:11:45.655059 [info ] [Thread-3 (]: 11 of 14 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.81s]
[0m21:11:45.655787 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_airports
[0m21:11:45.656248 [debug] [Thread-3 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:11:45.657029 [debug] [Thread-1 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:11:45.657695 [debug] [Thread-2 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:11:45.657417 [info ] [Thread-1 (]: 12 of 14 SKIP relation raw.gold_flight_metrics ................................. [[33mSKIP[0m]
[0m21:11:45.658074 [debug] [Thread-4 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:11:45.658388 [info ] [Thread-2 (]: 14 of 14 START test unique_my_second_dbt_model_flight_id ....................... [RUN]
[0m21:11:45.658776 [debug] [Thread-1 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:11:45.659077 [info ] [Thread-4 (]: 13 of 14 START test not_null_my_second_dbt_model_flight_id ..................... [RUN]
[0m21:11:45.659693 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580) - Creating connection
[0m21:11:45.660036 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'skipped'. 
[0m21:11:45.660472 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d) - Creating connection
[0m21:11:45.660791 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580'
[0m21:11:45.661181 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d'
[0m21:11:45.661483 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:11:45.661771 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:11:45.667323 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:11:45.673038 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:11:45.673948 [debug] [Thread-4 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:11:45.674268 [debug] [Thread-2 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:11:45.676392 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:11:45.678548 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:11:45.679049 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:11:45.679374 [debug] [Thread-4 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:11:45.679607 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:11:45.679786 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:11:45.680264 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:11:45.680601 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:11:46.315720 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-0034-1c6a-9318-9d7c883af686) - Created
[0m21:11:46.361103 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-003a-133f-825f-8ec03c2ddd84) - Created
[0m21:11:46.616054 [debug] [Thread-4 (]: SQL status: OK in 0.940 seconds
[0m21:11:46.619429 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c3-0034-1c6a-9318-9d7c883af686, command-id=01f089c3-004d-19e8-9651-0e703fe2e702) - Closing
[0m21:11:46.620416 [debug] [Thread-4 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: Close
[0m21:11:46.620785 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-0034-1c6a-9318-9d7c883af686) - Closing
[0m21:11:46.747301 [debug] [Thread-2 (]: SQL status: OK in 1.070 seconds
[0m21:11:46.750266 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c3-003a-133f-825f-8ec03c2ddd84, command-id=01f089c3-0056-17f5-84d1-301993711d5c) - Closing
[0m21:11:46.822147 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: Close
[0m21:11:46.823199 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-003a-133f-825f-8ec03c2ddd84) - Closing
[0m21:11:47.023343 [info ] [Thread-4 (]: 13 of 14 PASS not_null_my_second_dbt_model_flight_id ........................... [[32mPASS[0m in 1.36s]
[0m21:11:47.024330 [info ] [Thread-2 (]: 14 of 14 PASS unique_my_second_dbt_model_flight_id ............................. [[32mPASS[0m in 1.36s]
[0m21:11:47.025267 [debug] [Thread-4 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:11:47.025826 [debug] [Thread-2 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:11:47.027898 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:11:47.028287 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:11:47.028878 [info ] [MainThread]: 
[0m21:11:47.029218 [info ] [MainThread]: Finished running 2 table models, 4 data tests, 8 view models in 0 hours 0 minutes and 9.88 seconds (9.88s).
[0m21:11:47.031473 [debug] [MainThread]: Command end result
[0m21:11:47.142883 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:11:47.143808 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:11:47.146000 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:11:47.146107 [info ] [MainThread]: 
[0m21:11:47.146214 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:11:47.146315 [info ] [MainThread]: 
[0m21:11:47.146433 [error] [MainThread]: [31mFailure in model bronze_airlines (models/bronze/bronze_airlines.sql)[0m
[0m21:11:47.146557 [error] [MainThread]:   Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:11:47.146645 [info ] [MainThread]: 
[0m21:11:47.146747 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:11:47.146833 [info ] [MainThread]: 
[0m21:11:47.146926 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=1 SKIP=2 NO-OP=0 TOTAL=14
[0m21:11:47.149151 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 11.13047, "process_in_blocks": "0", "process_kernel_time": 0.2964, "process_mem_max_rss": "256933888", "process_out_blocks": "0", "process_user_time": 3.08142}
[0m21:11:47.149290 [debug] [MainThread]: Command `dbt build` failed at 21:11:47.149260 after 11.13 seconds
[0m21:11:47.149408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f07050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c80b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7b5d90>]}
[0m21:11:47.149513 [debug] [MainThread]: Flushing usage events
[0m21:11:47.989840 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:13:07.203565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10626f620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10728b890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10728bb10>]}


============================== 21:13:07.205700 | 67e8da1c-3fc0-49f1-a220-db50d5410b11 ==============================
[0m21:13:07.205700 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:13:07.205940 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'empty': 'False', 'quiet': 'False', 'invocation_command': 'dbt build', 'version_check': 'True', 'write_json': 'True', 'debug': 'False', 'static_parser': 'True', 'fail_fast': 'False', 'profiles_dir': '/Users/artakerqeli/.dbt', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'log_format': 'default', 'target_path': 'None', 'warn_error': 'None', 'log_cache_events': 'False', 'introspect': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'printer_width': '80'}
[0m21:13:07.515805 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:13:07.515995 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:13:07.516088 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:13:07.947838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065b7360>]}
[0m21:13:07.967342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108496ad0>]}
[0m21:13:07.967574 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:13:08.017131 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:13:08.074201 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m21:13:08.074458 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/bronze/bronze_airlines.sql
[0m21:13:08.074586 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/bronze/bronze_airports.sql
[0m21:13:08.164579 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:13:08.169532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e15fa50>]}
[0m21:13:08.203704 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:13:08.204709 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:13:08.214786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e47fd40>]}
[0m21:13:08.214985 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:13:08.215972 [info ] [MainThread]: 
[0m21:13:08.216097 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:13:08.216184 [info ] [MainThread]: 
[0m21:13:08.216367 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:13:08.216462 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:13:08.219050 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:13:08.219180 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:13:08.223432 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:13:08.223546 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:13:08.223629 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:13:09.145734 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-318a-1867-b749-800293031a94) - Created
[0m21:13:09.539621 [debug] [ThreadPool]: SQL status: OK in 1.320 seconds
[0m21:13:09.547120 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c3-318a-1867-b749-800293031a94, command-id=01f089c3-31b4-102c-ac53-d5bf148e4beb) - Closing
[0m21:13:09.547586 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:13:09.547780 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-318a-1867-b749-800293031a94) - Closing
[0m21:13:09.788010 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:13:09.788600 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:13:09.797535 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:13:09.797990 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:13:09.798257 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:13:10.433250 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-3256-1436-adca-ec8b6d044bb5) - Created
[0m21:13:10.941494 [debug] [ThreadPool]: SQL status: OK in 1.140 seconds
[0m21:13:10.943463 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c3-3256-1436-adca-ec8b6d044bb5, command-id=01f089c3-3275-1725-8346-270bd61c41d6) - Closing
[0m21:13:10.944101 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:13:10.944324 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-3256-1436-adca-ec8b6d044bb5) - Closing
[0m21:13:11.281388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e63f690>]}
[0m21:13:11.286308 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_airports
[0m21:13:11.286702 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airlines
[0m21:13:11.286986 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:13:11.287227 [debug] [Thread-3 (]: Began running node model.flights_dbt.bronze_flights
[0m21:13:11.287758 [info ] [Thread-2 (]: 2 of 14 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:13:11.288161 [info ] [Thread-1 (]: 1 of 14 START sql view model raw.bronze_airlines ............................... [RUN]
[0m21:13:11.288548 [info ] [Thread-4 (]: 4 of 14 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:13:11.288967 [info ] [Thread-3 (]: 3 of 14 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:13:11.289598 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:13:11.289993 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airlines) - Creating connection
[0m21:13:11.290365 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:13:11.290672 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:13:11.290924 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:13:11.291148 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airlines'
[0m21:13:11.291350 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:13:11.291554 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:13:11.291796 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:13:11.292008 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airlines
[0m21:13:11.292204 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:13:11.292567 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:13:11.298826 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:13:11.301020 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:13:11.304140 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airlines"
[0m21:13:11.306259 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:13:11.306952 [debug] [Thread-3 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:13:11.307208 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:13:11.307407 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:13:11.307581 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airlines
[0m21:13:11.316801 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:13:11.317816 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:13:11.318997 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:13:11.319954 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:13:11.321055 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:13:11.321337 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:13:11.321571 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:13:11.321795 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:13:11.321999 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6e6820>]}
[0m21:13:11.322145 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5df4d0>]}
[0m21:13:11.322274 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5541d0>]}
[0m21:13:11.322397 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e62c680>]}
[0m21:13:11.330796 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:13:11.331398 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:13:11.331793 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:13:11.332129 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airlines`
[0m21:13:11.336041 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:13:11.336366 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:13:11.336668 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:13:11.336954 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airlines"
[0m21:13:11.337360 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:13:11.337515 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:13:11.337639 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airlines"
[0m21:13:11.337793 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    create or replace view flight_db.raw.bronze_airports as
select
    airport_id,
    iata_code,
    city,
    state,
    country
from flight_db.raw.airports
  )

[0m21:13:11.337904 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:13:11.338048 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    SELECT
    flight_id,
    origin,
    destination AS dest,  -- or the correct column name
    airline,
    arr_time
FROM `flight_db`.`raw`.`flights`
  )

[0m21:13:11.338200 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view flight_db.raw.bronze_airlines as
select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

[0m21:13:11.338334 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:13:11.338464 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:13:11.338591 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:13:11.338697 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:13:11.338880 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:13:12.060960 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-334f-1d24-b751-545ee2ec59e0) - Created
[0m21:13:12.134762 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-335a-147c-9db5-2551be636ad1) - Created
[0m21:13:12.137485 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-335a-1a8a-acaa-321b3f0dbe1a) - Created
[0m21:13:12.178243 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-335f-1a7f-b09d-75bde2fd97ba) - Created
[0m21:13:12.402091 [debug] [Thread-2 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    create or replace view flight_db.raw.bronze_airports as
select
    airport_id,
    iata_code,
    city,
    state,
    country
from flight_db.raw.airports
  )

: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    create or replace view flight_db.raw.bronze_airports as
----^^^
select
    airport_id,
    iata_code,
    city,
    state,
    country
from flight_db.raw.airports
  )

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    create or replace view flight_db.raw.bronze_airports as
----^^^
select
    airport_id,
    iata_code,
    city,
    state,
    country
from flight_db.raw.airports
  )

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    create or replace view flight_db.raw.bronze_airports as
----^^^
select
    airport_id,
    iata_code,
    city,
    state,
    country
from flight_db.raw.airports
  )

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:117)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:153)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:446)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:615)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:246)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:155)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)
	at com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:61)
	at com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:136)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:444)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:440)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:790)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:781)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:569)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:901)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:296)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:896)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f089c3-3369-17a7-84f5-dacd34258543
[0m21:13:12.403186 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: Close
[0m21:13:12.403467 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-334f-1d24-b751-545ee2ec59e0) - Closing
[0m21:13:12.558423 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view flight_db.raw.bronze_airlines as
select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view flight_db.raw.bronze_airlines as
----^^^
select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view flight_db.raw.bronze_airlines as
----^^^
select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view flight_db.raw.bronze_airlines as
----^^^
select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:117)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:153)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:446)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:615)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:246)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:155)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)
	at com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:61)
	at com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:136)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:444)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:440)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:790)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:781)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:569)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:901)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:296)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:896)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f089c3-3376-1eab-a886-9cf90c3e1e83
[0m21:13:12.583261 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: Close
[0m21:13:12.584028 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-335a-1a8a-acaa-321b3f0dbe1a) - Closing
[0m21:13:12.595658 [debug] [Thread-2 (]: Database Error in model bronze_airports (models/bronze/bronze_airports.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airports`
    
    as (
      create or replace view flight_db.raw.bronze_airports as
  ----^^^
  select
      airport_id,
      iata_code,
      city,
      state,
      country
  from flight_db.raw.airports
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airports.sql
[0m21:13:12.743470 [debug] [Thread-3 (]: SQL status: OK in 1.400 seconds
[0m21:13:12.745133 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c3-335a-147c-9db5-2551be636ad1, command-id=01f089c3-3377-16e9-8dbb-aa0c27b95c98) - Closing
[0m21:13:12.758454 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:13:12.790141 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: Close
[0m21:13:12.790865 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-335a-147c-9db5-2551be636ad1) - Closing
[0m21:13:12.792977 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106575ed0>]}
[0m21:13:12.797089 [debug] [Thread-1 (]: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airlines`
    
    as (
      create or replace view flight_db.raw.bronze_airlines as
  ----^^^
  select
      airline,
      name,
      country
  from flight_db.raw.airlines
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:13:12.796342 [error] [Thread-2 (]: 2 of 14 ERROR creating sql view model raw.bronze_airports ...................... [[31mERROR[0m in 1.50s]
[0m21:13:12.797729 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:13:12.798033 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_flights
[0m21:13:12.798436 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.bronze_airports' to be skipped because of status 'error'.  Reason: Database Error in model bronze_airports (models/bronze/bronze_airports.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airports`
    
    as (
      create or replace view flight_db.raw.bronze_airports as
  ----^^^
  select
      airport_id,
      iata_code,
      city,
      state,
      country
  from flight_db.raw.airports
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airports.sql.
[0m21:13:12.798825 [info ] [Thread-2 (]: 5 of 14 START sql view model raw.silver_flights ................................ [RUN]
[0m21:13:12.801197 [debug] [Thread-4 (]: SQL status: OK in 1.460 seconds
[0m21:13:12.801918 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c3-335f-1a7f-b09d-75bde2fd97ba, command-id=01f089c3-337d-1ef5-9bf9-f19d7effd095) - Closing
[0m21:13:12.802388 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:13:13.007636 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6eef20>]}
[0m21:13:13.008791 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:13:13.009467 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:13:13.010826 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:13:13.010358 [error] [Thread-1 (]: 1 of 14 ERROR creating sql view model raw.bronze_airlines ...................... [[31mERROR[0m in 1.72s]
[0m21:13:13.011437 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-335f-1a7f-b09d-75bde2fd97ba) - Closing
[0m21:13:13.011865 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:13:13.012407 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airlines
[0m21:13:13.015177 [debug] [Thread-1 (]: Began running node model.flights_dbt.stg_airlines
[0m21:13:13.020446 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:13:13.020944 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.bronze_airlines' to be skipped because of status 'error'.  Reason: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airlines`
    
    as (
      create or replace view flight_db.raw.bronze_airlines as
  ----^^^
  select
      airline,
      name,
      country
  from flight_db.raw.airlines
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql.
[0m21:13:13.021393 [info ] [Thread-1 (]: 6 of 14 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:13:13.022789 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_flights
[0m21:13:13.024907 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:13:13.025974 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:13:13.026668 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:13:13.229118 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eae4290>]}
[0m21:13:13.230143 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:13:13.230462 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:13:13.231004 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7103b0>]}
[0m21:13:13.232074 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:13:13.231759 [info ] [Thread-3 (]: 3 of 14 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 1.94s]
[0m21:13:13.232597 [debug] [Thread-2 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:13:13.233543 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:13:13.233251 [info ] [Thread-4 (]: 4 of 14 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 1.94s]
[0m21:13:13.234152 [debug] [Thread-3 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:13:13.234482 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:13:13.239090 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:13:13.239608 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:13:13.239948 [debug] [Thread-3 (]: Began running node model.flights_dbt.silver_airports
[0m21:13:13.240650 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_airlines
[0m21:13:13.241045 [info ] [Thread-3 (]: 7 of 14 SKIP relation raw.silver_airports ...................................... [[33mSKIP[0m]
[0m21:13:13.241849 [info ] [Thread-4 (]: 8 of 14 SKIP relation raw.silver_airlines ...................................... [[33mSKIP[0m]
[0m21:13:13.242837 [debug] [Thread-3 (]: Finished running node model.flights_dbt.silver_airports
[0m21:13:13.243180 [debug] [Thread-1 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:13:13.243457 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:13:13.243922 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:13:13.244260 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.silver_airports' to be skipped because of status 'skipped'. 
[0m21:13:13.258675 [debug] [Thread-4 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:13:13.258934 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m21:13:13.259135 [info ] [Thread-3 (]: 9 of 14 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:13:13.259430 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.silver_airlines' to be skipped because of status 'skipped'. 
[0m21:13:13.259698 [info ] [Thread-4 (]: 10 of 14 START test unique_my_first_dbt_model_flight_id ........................ [RUN]
[0m21:13:13.272192 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:13:13.278725 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:13:13.279056 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:13:13.279233 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:13:13.279425 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:13:13.279596 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:13:13.279757 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:13:13.285235 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:13:13.285386 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:13:13.288006 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:13:13.288211 [debug] [Thread-1 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:13:13.288398 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:13:13.288615 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:13:13.294460 [debug] [Thread-4 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:13:13.295810 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:13:13.296727 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:13:13.296960 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:13:13.297065 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:13:13.297198 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:13:13.297342 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:13:13.297463 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:13:13.297569 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:13:13.904288 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-3469-1617-aab8-e186c0865cce) - Created
[0m21:13:14.006839 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-3478-164f-ad62-957b05ac5ddc) - Created
[0m21:13:14.026130 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-3478-1113-94a2-e568137e1089) - Created
[0m21:13:14.028082 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-3478-1284-99c7-99ed80e98f99) - Created
[0m21:13:14.294602 [debug] [Thread-3 (]: SQL status: OK in 1.000 seconds
[0m21:13:14.299666 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c3-3469-1617-aab8-e186c0865cce, command-id=01f089c3-3482-1593-8271-97f90651326b) - Closing
[0m21:13:14.302692 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:13:14.303113 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-3469-1617-aab8-e186c0865cce) - Closing
[0m21:13:14.456736 [debug] [Thread-4 (]: SQL status: OK in 1.160 seconds
[0m21:13:14.459754 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c3-3478-1113-94a2-e568137e1089, command-id=01f089c3-3496-1d39-8ab2-b8adedd4af84) - Closing
[0m21:13:14.507235 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:13:14.508247 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-3478-1113-94a2-e568137e1089) - Closing
[0m21:13:14.700574 [info ] [Thread-3 (]: 9 of 14 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.43s]
[0m21:13:14.701215 [info ] [Thread-4 (]: 10 of 14 PASS unique_my_first_dbt_model_flight_id .............................. [[32mPASS[0m in 1.42s]
[0m21:13:14.702108 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:13:14.702623 [debug] [Thread-4 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:13:14.703366 [debug] [Thread-3 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:13:14.703940 [info ] [Thread-3 (]: 11 of 14 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:13:14.704545 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:13:14.704881 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:13:14.705178 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:13:14.709568 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:13:14.710560 [debug] [Thread-3 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:13:14.712650 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:13:14.728239 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:13:14.729044 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:13:14.729642 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:13:14.729887 [debug] [Thread-3 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:13:14.730086 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:13:14.760409 [debug] [Thread-2 (]: SQL status: OK in 1.530 seconds
[0m21:13:14.760931 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c3-3478-1284-99c7-99ed80e98f99, command-id=01f089c3-3496-1ad4-a87d-3c88cf0df309) - Closing
[0m21:13:14.761272 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:13:14.761654 [debug] [Thread-2 (]: On model.flights_dbt.silver_flights: Close
[0m21:13:14.761816 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-3478-1284-99c7-99ed80e98f99) - Closing
[0m21:13:14.981072 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df7edb0>]}
[0m21:13:14.982149 [info ] [Thread-2 (]: 5 of 14 OK created sql view model raw.silver_flights ........................... [[32mOK[0m in 2.18s]
[0m21:13:14.982765 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_flights
[0m21:13:14.983432 [debug] [Thread-4 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:13:14.983864 [info ] [Thread-4 (]: 12 of 14 SKIP relation raw.gold_flight_metrics ................................. [[33mSKIP[0m]
[0m21:13:14.984248 [debug] [Thread-4 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:13:14.984578 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'skipped'. 
[0m21:13:15.404886 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-354d-1353-9ab6-e5125ef7c3db) - Created
[0m21:13:16.039849 [debug] [Thread-1 (]: SQL status: OK in 2.750 seconds
[0m21:13:16.041364 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c3-3478-164f-ad62-957b05ac5ddc, command-id=01f089c3-3493-1e5e-b128-75f064cf60c4) - Closing
[0m21:13:16.046056 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:13:16.061790 [debug] [Thread-1 (]: On model.flights_dbt.stg_airlines: Close
[0m21:13:16.062106 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-3478-164f-ad62-957b05ac5ddc) - Closing
[0m21:13:16.194051 [debug] [Thread-3 (]: SQL status: OK in 1.460 seconds
[0m21:13:16.195393 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c3-354d-1353-9ab6-e5125ef7c3db, command-id=01f089c3-3569-18cc-9d46-e0cc989ead72) - Closing
[0m21:13:16.196124 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:13:16.265999 [debug] [Thread-3 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:13:16.267113 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-354d-1353-9ab6-e5125ef7c3db) - Closing
[0m21:13:16.488379 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e712810>]}
[0m21:13:16.489408 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67e8da1c-3fc0-49f1-a220-db50d5410b11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e711f10>]}
[0m21:13:16.490674 [info ] [Thread-1 (]: 6 of 14 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.47s]
[0m21:13:16.492021 [debug] [Thread-1 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:13:16.491472 [info ] [Thread-3 (]: 11 of 14 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.78s]
[0m21:13:16.492709 [debug] [Thread-3 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:13:16.493610 [debug] [Thread-2 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:13:16.493945 [debug] [Thread-4 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:13:16.494354 [info ] [Thread-2 (]: 13 of 14 START test not_null_my_second_dbt_model_flight_id ..................... [RUN]
[0m21:13:16.494734 [info ] [Thread-4 (]: 14 of 14 START test unique_my_second_dbt_model_flight_id ....................... [RUN]
[0m21:13:16.495403 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d) - Creating connection
[0m21:13:16.495851 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580) - Creating connection
[0m21:13:16.496186 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d'
[0m21:13:16.496481 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580'
[0m21:13:16.496804 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:13:16.497112 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:13:16.503045 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:13:16.509715 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:13:16.510439 [debug] [Thread-2 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:13:16.510725 [debug] [Thread-4 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:13:16.512795 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:13:16.514738 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:13:16.515178 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:13:16.515367 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:13:16.515617 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:13:16.515872 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:13:16.516089 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:13:16.516285 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:13:17.216692 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-3662-1ebb-bf9b-1054975762b1) - Created
[0m21:13:17.241294 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-3663-1fa0-b96f-2ea403cb15a5) - Created
[0m21:13:17.557794 [debug] [Thread-4 (]: SQL status: OK in 1.040 seconds
[0m21:13:17.561014 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c3-3662-1ebb-bf9b-1054975762b1, command-id=01f089c3-367d-173c-bd9b-df4119532e21) - Closing
[0m21:13:17.562001 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: Close
[0m21:13:17.562362 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-3662-1ebb-bf9b-1054975762b1) - Closing
[0m21:13:17.575146 [debug] [Thread-2 (]: SQL status: OK in 1.060 seconds
[0m21:13:17.577297 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c3-3663-1fa0-b96f-2ea403cb15a5, command-id=01f089c3-3680-1ec0-8f39-f6c65d14bc8e) - Closing
[0m21:13:17.760006 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: Close
[0m21:13:17.761111 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-3663-1fa0-b96f-2ea403cb15a5) - Closing
[0m21:13:17.950421 [info ] [Thread-4 (]: 14 of 14 PASS unique_my_second_dbt_model_flight_id ............................. [[32mPASS[0m in 1.45s]
[0m21:13:17.951359 [info ] [Thread-2 (]: 13 of 14 PASS not_null_my_second_dbt_model_flight_id ........................... [[32mPASS[0m in 1.46s]
[0m21:13:17.952387 [debug] [Thread-4 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:13:17.952942 [debug] [Thread-2 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:13:17.954934 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:13:17.955272 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:13:17.955799 [info ] [MainThread]: 
[0m21:13:17.956093 [info ] [MainThread]: Finished running 2 table models, 4 data tests, 8 view models in 0 hours 0 minutes and 9.74 seconds (9.74s).
[0m21:13:17.958321 [debug] [MainThread]: Command end result
[0m21:13:17.990882 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:13:17.992224 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:13:17.995966 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:13:17.996107 [info ] [MainThread]: 
[0m21:13:17.996269 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m21:13:17.996388 [info ] [MainThread]: 
[0m21:13:17.996548 [error] [MainThread]: [31mFailure in model bronze_airports (models/bronze/bronze_airports.sql)[0m
[0m21:13:17.996703 [error] [MainThread]:   Database Error in model bronze_airports (models/bronze/bronze_airports.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airports`
    
    as (
      create or replace view flight_db.raw.bronze_airports as
  ----^^^
  select
      airport_id,
      iata_code,
      city,
      state,
      country
  from flight_db.raw.airports
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airports.sql
[0m21:13:17.996831 [info ] [MainThread]: 
[0m21:13:17.996956 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/bronze/bronze_airports.sql
[0m21:13:17.997058 [info ] [MainThread]: 
[0m21:13:17.997189 [error] [MainThread]: [31mFailure in model bronze_airlines (models/bronze/bronze_airlines.sql)[0m
[0m21:13:17.997333 [error] [MainThread]:   Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airlines`
    
    as (
      create or replace view flight_db.raw.bronze_airlines as
  ----^^^
  select
      airline,
      name,
      country
  from flight_db.raw.airlines
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:13:17.997453 [info ] [MainThread]: 
[0m21:13:17.997574 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:13:17.997679 [info ] [MainThread]: 
[0m21:13:17.997801 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=2 SKIP=3 NO-OP=0 TOTAL=14
[0m21:13:18.000919 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 10.826539, "process_in_blocks": "0", "process_kernel_time": 0.277593, "process_mem_max_rss": "253771776", "process_out_blocks": "0", "process_user_time": 2.496162}
[0m21:13:18.001182 [debug] [MainThread]: Command `dbt build` failed at 21:13:18.001131 after 10.83 seconds
[0m21:13:18.001380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10514db50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed47b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed47ad0>]}
[0m21:13:18.001542 [debug] [MainThread]: Flushing usage events
[0m21:13:18.708419 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:14:34.219553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106643620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10765f890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10765fb10>]}


============================== 21:14:34.221819 | 18539827-78f9-455f-8267-78326e1b7a6a ==============================
[0m21:14:34.221819 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:14:34.222045 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'indirect_selection': 'eager', 'profiles_dir': '/Users/artakerqeli/.dbt', 'log_cache_events': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'partial_parse': 'True', 'invocation_command': 'dbt build', 'version_check': 'True', 'quiet': 'False', 'write_json': 'True', 'use_experimental_parser': 'False', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'static_parser': 'True', 'no_print': 'None', 'log_format': 'default', 'cache_selected_only': 'False', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'use_colors': 'True', 'introspect': 'True'}
[0m21:14:34.527090 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:14:34.527283 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:14:34.527387 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:14:34.990469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106983360>]}
[0m21:14:35.009938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108866ad0>]}
[0m21:14:35.010177 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:14:35.063795 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:14:35.122452 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:14:35.122603 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:14:35.125619 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:14:35.140602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e462e50>]}
[0m21:14:35.177391 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:14:35.178366 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:14:35.189351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7094f0>]}
[0m21:14:35.189515 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:14:35.190490 [info ] [MainThread]: 
[0m21:14:35.190610 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:14:35.190695 [info ] [MainThread]: 
[0m21:14:35.190892 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:14:35.190985 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:14:35.193449 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:14:35.193567 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:14:35.197586 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:14:35.197707 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:14:35.197800 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:14:35.935129 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-654c-1d33-ac60-3b5c744b0927) - Created
[0m21:14:36.454924 [debug] [ThreadPool]: SQL status: OK in 1.260 seconds
[0m21:14:36.465450 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c3-654c-1d33-ac60-3b5c744b0927, command-id=01f089c3-656a-141d-b8a6-eb1174e103a9) - Closing
[0m21:14:36.466125 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:14:36.466385 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-654c-1d33-ac60-3b5c744b0927) - Closing
[0m21:14:36.663928 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:14:36.664624 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:14:36.678921 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:14:36.679326 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:14:36.679557 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:14:37.377862 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-6629-1df2-ac00-a7361854990f) - Created
[0m21:14:37.887292 [debug] [ThreadPool]: SQL status: OK in 1.210 seconds
[0m21:14:37.890625 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c3-6629-1df2-ac00-a7361854990f, command-id=01f089c3-6645-12ba-a802-96a335fbe76e) - Closing
[0m21:14:37.891599 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:14:37.891851 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-6629-1df2-ac00-a7361854990f) - Closing
[0m21:14:38.100491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7bbe70>]}
[0m21:14:38.105129 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_airports
[0m21:14:38.105492 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airlines
[0m21:14:38.105750 [debug] [Thread-3 (]: Began running node model.flights_dbt.bronze_flights
[0m21:14:38.105991 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:14:38.106732 [info ] [Thread-2 (]: 2 of 14 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:14:38.107259 [info ] [Thread-1 (]: 1 of 14 START sql view model raw.bronze_airlines ............................... [RUN]
[0m21:14:38.107792 [info ] [Thread-3 (]: 3 of 14 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:14:38.108305 [info ] [Thread-4 (]: 4 of 14 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:14:38.108862 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:14:38.109264 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airlines) - Creating connection
[0m21:14:38.109646 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:14:38.109994 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:14:38.110224 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:14:38.110436 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airlines'
[0m21:14:38.110636 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:14:38.110842 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:14:38.111061 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:14:38.111269 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airlines
[0m21:14:38.111481 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:14:38.111684 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:14:38.116942 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:14:38.119847 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:14:38.122523 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airlines"
[0m21:14:38.123693 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:14:38.125147 [debug] [Thread-3 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:14:38.131384 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:14:38.131564 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airlines
[0m21:14:38.134351 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:14:38.135359 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:14:38.136448 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:14:38.136617 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:14:38.137734 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:14:38.138031 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:14:38.138303 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:14:38.139334 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:14:38.139545 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e867040>]}
[0m21:14:38.139697 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e76a2d0>]}
[0m21:14:38.139840 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e76b350>]}
[0m21:14:38.140069 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:14:38.148004 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:14:38.148201 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:14:38.148556 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airlines`
[0m21:14:38.148690 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e951130>]}
[0m21:14:38.152756 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:14:38.153082 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:14:38.153371 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airlines"
[0m21:14:38.153705 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:14:38.154155 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:14:38.154380 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:14:38.154540 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    SELECT
    flight_id,
    origin,
    destination AS dest,  -- or the correct column name
    airline,
    arr_time
FROM `flight_db`.`raw`.`flights`
  )

[0m21:14:38.154655 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:14:38.154786 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:14:38.154898 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airlines"
[0m21:14:38.155055 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    create or replace view flight_db.raw.bronze_airports as
select
    airport_id,
    iata_code,
    city,
    state,
    country
from flight_db.raw.airports
  )

[0m21:14:38.155258 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:14:38.155387 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view flight_db.raw.bronze_airlines as
select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

[0m21:14:38.155545 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:14:38.155684 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:14:38.155821 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:14:38.155981 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:14:38.908682 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-6715-1419-8ed7-6cf5d6a0476d) - Created
[0m21:14:38.913791 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-6714-1938-9eb9-f57aa8ea5c8f) - Created
[0m21:14:38.929010 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-6717-1bb5-be73-a402fc4bacb9) - Created
[0m21:14:38.934651 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-6717-1a02-a7bc-7ea574adae76) - Created
[0m21:14:39.334104 [debug] [Thread-2 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    create or replace view flight_db.raw.bronze_airports as
select
    airport_id,
    iata_code,
    city,
    state,
    country
from flight_db.raw.airports
  )

: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    create or replace view flight_db.raw.bronze_airports as
----^^^
select
    airport_id,
    iata_code,
    city,
    state,
    country
from flight_db.raw.airports
  )

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    create or replace view flight_db.raw.bronze_airports as
----^^^
select
    airport_id,
    iata_code,
    city,
    state,
    country
from flight_db.raw.airports
  )

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    create or replace view flight_db.raw.bronze_airports as
----^^^
select
    airport_id,
    iata_code,
    city,
    state,
    country
from flight_db.raw.airports
  )

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:117)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:153)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:446)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:615)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:246)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:155)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)
	at com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:61)
	at com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:136)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:444)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:440)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:790)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:781)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:569)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:901)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:296)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:896)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f089c3-672f-182e-a46b-517b22c902ae
[0m21:14:39.335768 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: Close
[0m21:14:39.336155 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-6715-1419-8ed7-6cf5d6a0476d) - Closing
[0m21:14:39.378838 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view flight_db.raw.bronze_airlines as
select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view flight_db.raw.bronze_airlines as
----^^^
select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view flight_db.raw.bronze_airlines as
----^^^
select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    create or replace view flight_db.raw.bronze_airlines as
----^^^
select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:117)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:153)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:446)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:615)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:246)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:445)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:155)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)
	at com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:61)
	at com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:136)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:444)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:440)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:790)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:781)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:569)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:901)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:296)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:896)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f089c3-6733-11d5-9d8d-3422968f8259
[0m21:14:39.532786 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: Close
[0m21:14:39.533529 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-6717-1a02-a7bc-7ea574adae76) - Closing
[0m21:14:39.545494 [debug] [Thread-2 (]: Database Error in model bronze_airports (models/bronze/bronze_airports.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airports`
    
    as (
      create or replace view flight_db.raw.bronze_airports as
  ----^^^
  select
      airport_id,
      iata_code,
      city,
      state,
      country
  from flight_db.raw.airports
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airports.sql
[0m21:14:39.614844 [debug] [Thread-3 (]: SQL status: OK in 1.460 seconds
[0m21:14:39.616436 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c3-6717-1bb5-be73-a402fc4bacb9, command-id=01f089c3-6732-13b7-96c5-0d347bca20e4) - Closing
[0m21:14:39.629812 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:14:39.651255 [debug] [Thread-4 (]: SQL status: OK in 1.500 seconds
[0m21:14:39.652518 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c3-6714-1938-9eb9-f57aa8ea5c8f, command-id=01f089c3-672f-1b67-ace4-a891ac31491a) - Closing
[0m21:14:39.653277 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:14:39.737011 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: Close
[0m21:14:39.738487 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-6717-1bb5-be73-a402fc4bacb9) - Closing
[0m21:14:39.744063 [debug] [Thread-1 (]: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airlines`
    
    as (
      create or replace view flight_db.raw.bronze_airlines as
  ----^^^
  select
      airline,
      name,
      country
  from flight_db.raw.airlines
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:14:39.744564 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106949ed0>]}
[0m21:14:39.745425 [error] [Thread-2 (]: 2 of 14 ERROR creating sql view model raw.bronze_airports ...................... [[31mERROR[0m in 1.63s]
[0m21:14:39.746013 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:14:39.746349 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_flights
[0m21:14:39.746769 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.bronze_airports' to be skipped because of status 'error'.  Reason: Database Error in model bronze_airports (models/bronze/bronze_airports.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airports`
    
    as (
      create or replace view flight_db.raw.bronze_airports as
  ----^^^
  select
      airport_id,
      iata_code,
      city,
      state,
      country
  from flight_db.raw.airports
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airports.sql.
[0m21:14:39.747183 [info ] [Thread-2 (]: 5 of 14 START sql view model raw.silver_flights ................................ [RUN]
[0m21:14:39.941082 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:14:39.941866 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-6714-1938-9eb9-f57aa8ea5c8f) - Closing
[0m21:14:40.159127 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e892270>]}
[0m21:14:40.160316 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:14:40.161012 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e853b60>]}
[0m21:14:40.161535 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7abb30>]}
[0m21:14:40.162701 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:14:40.162342 [error] [Thread-1 (]: 1 of 14 ERROR creating sql view model raw.bronze_airlines ...................... [[31mERROR[0m in 2.05s]
[0m21:14:40.163388 [info ] [Thread-3 (]: 3 of 14 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.05s]
[0m21:14:40.164253 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:14:40.163871 [info ] [Thread-4 (]: 4 of 14 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.05s]
[0m21:14:40.164932 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airlines
[0m21:14:40.165436 [debug] [Thread-3 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:14:40.167501 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:14:40.169133 [debug] [Thread-1 (]: Began running node model.flights_dbt.stg_airlines
[0m21:14:40.174855 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.bronze_airlines' to be skipped because of status 'error'.  Reason: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airlines`
    
    as (
      create or replace view flight_db.raw.bronze_airlines as
  ----^^^
  select
      airline,
      name,
      country
  from flight_db.raw.airlines
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql.
[0m21:14:40.175176 [debug] [Thread-3 (]: Began running node model.flights_dbt.silver_airports
[0m21:14:40.175982 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:14:40.176435 [info ] [Thread-1 (]: 6 of 14 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:14:40.177212 [info ] [Thread-3 (]: 7 of 14 SKIP relation raw.silver_airports ...................................... [[33mSKIP[0m]
[0m21:14:40.177755 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_airlines
[0m21:14:40.178243 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:14:40.178646 [debug] [Thread-3 (]: Finished running node model.flights_dbt.silver_airports
[0m21:14:40.179044 [info ] [Thread-4 (]: 8 of 14 SKIP relation raw.silver_airlines ...................................... [[33mSKIP[0m]
[0m21:14:40.179367 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_flights
[0m21:14:40.179657 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:14:40.179973 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:14:40.180222 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.silver_airports' to be skipped because of status 'skipped'. 
[0m21:14:40.180525 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:14:40.182244 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:14:40.182506 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:14:40.182764 [info ] [Thread-3 (]: 9 of 14 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:14:40.183127 [debug] [Thread-4 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:14:40.183330 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.silver_airlines' to be skipped because of status 'skipped'. 
[0m21:14:40.184172 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:14:40.187469 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:14:40.188504 [info ] [Thread-4 (]: 10 of 14 START test unique_my_first_dbt_model_flight_id ........................ [RUN]
[0m21:14:40.193564 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:14:40.194145 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:14:40.194344 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:14:40.194620 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:14:40.194924 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:14:40.195147 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:14:40.200885 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:14:40.202059 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:14:40.205202 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:14:40.205441 [debug] [Thread-1 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:14:40.205591 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:14:40.214483 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m21:14:40.214730 [debug] [Thread-2 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:14:40.214890 [debug] [Thread-4 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:14:40.215029 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:14:40.227693 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:14:40.229615 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:14:40.236317 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:14:40.237340 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:14:40.237784 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:14:40.237896 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:14:40.238029 [debug] [Thread-1 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:14:40.238124 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:14:40.238249 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:14:40.238364 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:14:40.238481 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:14:40.238589 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:14:40.238745 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:14:40.944200 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-6849-12c9-9cb6-9d159817c6a6) - Created
[0m21:14:41.008140 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-6854-1048-8b8a-02129a8851d7) - Created
[0m21:14:41.011068 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-6853-1f08-af6f-c96204b03342) - Created
[0m21:14:41.012244 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-6853-1d6b-ae22-69c747d3bb8f) - Created
[0m21:14:41.245643 [debug] [Thread-3 (]: SQL status: OK in 1.010 seconds
[0m21:14:41.250659 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c3-6849-12c9-9cb6-9d159817c6a6, command-id=01f089c3-6864-1b58-a6e9-996541d32b42) - Closing
[0m21:14:41.253890 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:14:41.254378 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-6849-12c9-9cb6-9d159817c6a6) - Closing
[0m21:14:41.401300 [debug] [Thread-4 (]: SQL status: OK in 1.160 seconds
[0m21:14:41.404242 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c3-6853-1d6b-ae22-69c747d3bb8f, command-id=01f089c3-686f-1ea5-880e-6af57e81900b) - Closing
[0m21:14:41.444857 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:14:41.445546 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-6853-1d6b-ae22-69c747d3bb8f) - Closing
[0m21:14:41.601384 [debug] [Thread-2 (]: SQL status: OK in 1.370 seconds
[0m21:14:41.603108 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c3-6853-1f08-af6f-c96204b03342, command-id=01f089c3-6870-1626-a033-b4ed50e44829) - Closing
[0m21:14:41.604099 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:14:41.641456 [debug] [Thread-2 (]: On model.flights_dbt.silver_flights: Close
[0m21:14:41.640605 [info ] [Thread-3 (]: 9 of 14 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.45s]
[0m21:14:41.642288 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-6853-1f08-af6f-c96204b03342) - Closing
[0m21:14:41.642947 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:14:41.842924 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e956630>]}
[0m21:14:41.842215 [info ] [Thread-4 (]: 10 of 14 PASS unique_my_first_dbt_model_flight_id .............................. [[32mPASS[0m in 1.65s]
[0m21:14:41.844433 [debug] [Thread-4 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:14:41.843956 [info ] [Thread-2 (]: 5 of 14 OK created sql view model raw.silver_flights ........................... [[32mOK[0m in 2.09s]
[0m21:14:41.845272 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_flights
[0m21:14:41.845684 [debug] [Thread-3 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:14:41.846213 [info ] [Thread-3 (]: 11 of 14 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:14:41.846613 [debug] [Thread-4 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:14:41.847144 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:14:41.847506 [info ] [Thread-4 (]: 12 of 14 SKIP relation raw.gold_flight_metrics ................................. [[33mSKIP[0m]
[0m21:14:41.847831 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:14:41.848122 [debug] [Thread-4 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:14:41.848379 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:14:41.848648 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'skipped'. 
[0m21:14:41.858911 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:14:41.859705 [debug] [Thread-3 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:14:41.861400 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:14:41.862382 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:14:41.862964 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:14:41.863688 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:14:41.864016 [debug] [Thread-3 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:14:41.864262 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:14:42.519553 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-6939-1f51-8485-9b57effc2c52) - Created
[0m21:14:43.005699 [debug] [Thread-1 (]: SQL status: OK in 2.770 seconds
[0m21:14:43.008212 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c3-6854-1048-8b8a-02129a8851d7, command-id=01f089c3-686f-1c5c-987f-a2a634c078ff) - Closing
[0m21:14:43.014384 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:14:43.029348 [debug] [Thread-1 (]: On model.flights_dbt.stg_airlines: Close
[0m21:14:43.029657 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-6854-1048-8b8a-02129a8851d7) - Closing
[0m21:14:43.230459 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb72ed0>]}
[0m21:14:43.232188 [info ] [Thread-1 (]: 6 of 14 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.05s]
[0m21:14:43.233284 [debug] [Thread-1 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:14:43.244398 [debug] [Thread-3 (]: SQL status: OK in 1.380 seconds
[0m21:14:43.245914 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c3-6939-1f51-8485-9b57effc2c52, command-id=01f089c3-6954-19cb-af45-db22961b8b0f) - Closing
[0m21:14:43.246681 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:14:43.247506 [debug] [Thread-3 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:14:43.247750 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-6939-1f51-8485-9b57effc2c52) - Closing
[0m21:14:43.441556 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18539827-78f9-455f-8267-78326e1b7a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb72ff0>]}
[0m21:14:43.443400 [info ] [Thread-3 (]: 11 of 14 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.59s]
[0m21:14:43.444213 [debug] [Thread-3 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:14:43.445157 [debug] [Thread-2 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:14:43.445533 [debug] [Thread-4 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:14:43.445993 [info ] [Thread-2 (]: 13 of 14 START test not_null_my_second_dbt_model_flight_id ..................... [RUN]
[0m21:14:43.446520 [info ] [Thread-4 (]: 14 of 14 START test unique_my_second_dbt_model_flight_id ....................... [RUN]
[0m21:14:43.447218 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d) - Creating connection
[0m21:14:43.447699 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580) - Creating connection
[0m21:14:43.448019 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d'
[0m21:14:43.448276 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580'
[0m21:14:43.448538 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:14:43.448792 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:14:43.454104 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:14:43.458546 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:14:43.460170 [debug] [Thread-2 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:14:43.460441 [debug] [Thread-4 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:14:43.462539 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:14:43.464554 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:14:43.464974 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:14:43.465150 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:14:43.465397 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:14:43.465652 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:14:43.465867 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:14:43.466057 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:14:44.171916 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-6a37-196d-9d23-7af18882aab3) - Created
[0m21:14:44.173971 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-6a37-1810-8fcc-523d0d7371a6) - Created
[0m21:14:44.496329 [debug] [Thread-2 (]: SQL status: OK in 1.030 seconds
[0m21:14:44.499521 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c3-6a37-196d-9d23-7af18882aab3, command-id=01f089c3-6a52-1ee7-8da0-b710cc61c23b) - Closing
[0m21:14:44.500443 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: Close
[0m21:14:44.500796 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-6a37-196d-9d23-7af18882aab3) - Closing
[0m21:14:44.515769 [debug] [Thread-4 (]: SQL status: OK in 1.050 seconds
[0m21:14:44.518725 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c3-6a37-1810-8fcc-523d0d7371a6, command-id=01f089c3-6a53-1a12-8299-c512f6f99d86) - Closing
[0m21:14:44.707032 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: Close
[0m21:14:44.708134 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-6a37-1810-8fcc-523d0d7371a6) - Closing
[0m21:14:44.911682 [info ] [Thread-2 (]: 13 of 14 PASS not_null_my_second_dbt_model_flight_id ........................... [[32mPASS[0m in 1.46s]
[0m21:14:44.912710 [info ] [Thread-4 (]: 14 of 14 PASS unique_my_second_dbt_model_flight_id ............................. [[32mPASS[0m in 1.46s]
[0m21:14:44.913721 [debug] [Thread-2 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:14:44.914271 [debug] [Thread-4 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:14:44.916156 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:14:44.916496 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:14:44.917055 [info ] [MainThread]: 
[0m21:14:44.917369 [info ] [MainThread]: Finished running 2 table models, 4 data tests, 8 view models in 0 hours 0 minutes and 9.73 seconds (9.73s).
[0m21:14:44.919511 [debug] [MainThread]: Command end result
[0m21:14:44.952889 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:14:44.954302 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:14:44.958660 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:14:44.958829 [info ] [MainThread]: 
[0m21:14:44.959011 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m21:14:44.959141 [info ] [MainThread]: 
[0m21:14:44.959302 [error] [MainThread]: [31mFailure in model bronze_airports (models/bronze/bronze_airports.sql)[0m
[0m21:14:44.959469 [error] [MainThread]:   Database Error in model bronze_airports (models/bronze/bronze_airports.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airports`
    
    as (
      create or replace view flight_db.raw.bronze_airports as
  ----^^^
  select
      airport_id,
      iata_code,
      city,
      state,
      country
  from flight_db.raw.airports
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airports.sql
[0m21:14:44.959592 [info ] [MainThread]: 
[0m21:14:44.959721 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/bronze/bronze_airports.sql
[0m21:14:44.959828 [info ] [MainThread]: 
[0m21:14:44.959954 [error] [MainThread]: [31mFailure in model bronze_airlines (models/bronze/bronze_airlines.sql)[0m
[0m21:14:44.960104 [error] [MainThread]:   Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near 'create'. SQLSTATE: 42601 (line 8, pos 4)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */
  
    
    
    create or replace view `flight_db`.`raw`.`bronze_airlines`
    
    as (
      create or replace view flight_db.raw.bronze_airlines as
  ----^^^
  select
      airline,
      name,
      country
  from flight_db.raw.airlines
    )
  
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:14:44.960220 [info ] [MainThread]: 
[0m21:14:44.960341 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:14:44.960448 [info ] [MainThread]: 
[0m21:14:44.960577 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=2 SKIP=3 NO-OP=0 TOTAL=14
[0m21:14:44.963141 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 10.774396, "process_in_blocks": "0", "process_kernel_time": 0.280619, "process_mem_max_rss": "247365632", "process_out_blocks": "0", "process_user_time": 2.836646}
[0m21:14:44.963357 [debug] [MainThread]: Command `dbt build` failed at 21:14:44.963313 after 10.77 seconds
[0m21:14:44.963539 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107552810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8c9130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8c8ef0>]}
[0m21:14:44.963686 [debug] [MainThread]: Flushing usage events
[0m21:14:45.702379 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:15:57.309203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103c37620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c53890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c53b10>]}


============================== 21:15:57.311535 | 552e8281-0b61-4695-8fea-c20767c7b951 ==============================
[0m21:15:57.311535 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:15:57.311767 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'log_format': 'default', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'printer_width': '80', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'static_parser': 'True', 'empty': 'False', 'fail_fast': 'False', 'debug': 'False', 'indirect_selection': 'eager', 'invocation_command': 'dbt build', 'warn_error': 'None', 'profiles_dir': '/Users/artakerqeli/.dbt', 'cache_selected_only': 'False', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'use_colors': 'True', 'no_print': 'None', 'log_cache_events': 'False', 'target_path': 'None', 'introspect': 'True'}
[0m21:15:57.618717 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:15:57.618918 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:15:57.619014 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:15:58.061933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103f7f360>]}
[0m21:15:58.081458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e5aad0>]}
[0m21:15:58.081706 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:15:58.131193 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:15:58.192022 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m21:15:58.192291 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/bronze/bronze_airports.sql
[0m21:15:58.192426 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/bronze/bronze_airlines.sql
[0m21:15:58.281658 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:15:58.286496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10badfa50>]}
[0m21:15:58.320312 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:15:58.321283 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:15:58.334240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be03d40>]}
[0m21:15:58.334420 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:15:58.335426 [info ] [MainThread]: 
[0m21:15:58.335553 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:15:58.335639 [info ] [MainThread]: 
[0m21:15:58.335835 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:15:58.335933 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:15:58.338528 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:15:58.338644 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:15:58.343099 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:15:58.343222 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:15:58.343310 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:15:59.112858 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-96e2-10a7-be42-3d7e4e9c9719) - Created
[0m21:15:59.733252 [debug] [ThreadPool]: SQL status: OK in 1.390 seconds
[0m21:15:59.742629 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c3-96e2-10a7-be42-3d7e4e9c9719, command-id=01f089c3-96fd-11f0-9d3d-505058bea78e) - Closing
[0m21:15:59.743240 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:15:59.743530 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-96e2-10a7-be42-3d7e4e9c9719) - Closing
[0m21:15:59.999737 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:16:00.000303 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:16:00.009687 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:16:00.010411 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:16:00.010808 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:16:00.681666 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-97d1-11a5-b53a-1e984c3bf582) - Created
[0m21:16:01.239978 [debug] [ThreadPool]: SQL status: OK in 1.230 seconds
[0m21:16:01.243090 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c3-97d1-11a5-b53a-1e984c3bf582, command-id=01f089c3-97f0-135c-8b25-e131dbf4713e) - Closing
[0m21:16:01.244012 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:16:01.244322 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-97d1-11a5-b53a-1e984c3bf582) - Closing
[0m21:16:01.440335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfbf5b0>]}
[0m21:16:01.444892 [debug] [Thread-3 (]: Began running node model.flights_dbt.bronze_flights
[0m21:16:01.445373 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airlines
[0m21:16:01.445654 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_airports
[0m21:16:01.445885 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:16:01.446471 [info ] [Thread-3 (]: 3 of 14 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:16:01.447029 [info ] [Thread-1 (]: 1 of 14 START sql view model raw.bronze_airlines ............................... [RUN]
[0m21:16:01.447614 [info ] [Thread-2 (]: 2 of 14 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:16:01.448195 [info ] [Thread-4 (]: 4 of 14 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:16:01.448815 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:16:01.449279 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airlines) - Creating connection
[0m21:16:01.449675 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:16:01.450020 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:16:01.450267 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:16:01.450523 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airlines'
[0m21:16:01.450771 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:16:01.450984 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:16:01.451216 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:16:01.451437 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airlines
[0m21:16:01.451641 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:16:01.451845 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:16:01.458070 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:16:01.459924 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:16:01.462208 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airlines"
[0m21:16:01.463449 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:16:01.464540 [debug] [Thread-3 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:16:01.464740 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airlines
[0m21:16:01.464930 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:16:01.465090 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:16:01.473842 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:16:01.474810 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:16:01.475833 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:16:01.476686 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:16:01.477712 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:16:01.478016 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:16:01.478265 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:16:01.478544 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:16:01.478773 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c06a750>]}
[0m21:16:01.478925 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf67290>]}
[0m21:16:01.479057 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bed81d0>]}
[0m21:16:01.479184 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfb2830>]}
[0m21:16:01.485718 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airlines`
[0m21:16:01.486237 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:16:01.486610 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:16:01.486951 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:16:01.491107 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airlines"
[0m21:16:01.491460 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:16:01.491745 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:16:01.492016 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:16:01.492668 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:16:01.492788 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airlines"
[0m21:16:01.492934 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    SELECT
    flight_id,
    origin,
    destination AS dest,  -- or the correct column name
    airline,
    arr_time
FROM `flight_db`.`raw`.`flights`
  )

[0m21:16:01.493057 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:16:01.493228 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

[0m21:16:01.493344 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:16:01.493459 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:16:01.493590 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from flight_db.raw.airports
  )

[0m21:16:01.493713 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:16:01.493838 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:16:01.494036 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:16:01.494247 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:16:02.197562 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-98b9-146c-873f-2aea8689e855) - Created
[0m21:16:02.269756 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-98c3-14e6-a8a1-c426410adff1) - Created
[0m21:16:02.274492 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-98c3-15d0-80cd-32e7aee474b5) - Created
[0m21:16:02.275878 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-98c3-1daf-a364-98119098f78b) - Created
[0m21:16:02.716743 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airlines`
  
  as (
    select
    airline,
    name,
    country
from flight_db.raw.airlines
  )

: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c3-98df-19e0-a215-16d352fb20fb
[0m21:16:02.718339 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airlines: Close
[0m21:16:02.718873 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-98c3-15d0-80cd-32e7aee474b5) - Closing
[0m21:16:02.786028 [debug] [Thread-4 (]: SQL status: OK in 1.290 seconds
[0m21:16:02.788030 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c3-98b9-146c-873f-2aea8689e855, command-id=01f089c3-98d6-163e-82f4-8430bcabc208) - Closing
[0m21:16:02.800803 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:16:02.872257 [debug] [Thread-2 (]: SQL status: OK in 1.380 seconds
[0m21:16:02.874179 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c3-98c3-1daf-a364-98119098f78b, command-id=01f089c3-98df-1a15-a6ad-cff550d6ec35) - Closing
[0m21:16:02.875205 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:16:02.892869 [debug] [Thread-3 (]: SQL status: OK in 1.400 seconds
[0m21:16:02.894068 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c3-98c3-14e6-a8a1-c426410adff1, command-id=01f089c3-98df-13a3-be2c-9981b01a678e) - Closing
[0m21:16:02.894785 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:16:02.928299 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:16:02.929123 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-98b9-146c-873f-2aea8689e855) - Closing
[0m21:16:02.941669 [debug] [Thread-1 (]: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:16:03.124298 [debug] [Thread-2 (]: On model.flights_dbt.bronze_airports: Close
[0m21:16:03.125208 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-98c3-1daf-a364-98119098f78b) - Closing
[0m21:16:03.329521 [debug] [Thread-3 (]: On model.flights_dbt.bronze_flights: Close
[0m21:16:03.330511 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-98c3-14e6-a8a1-c426410adff1) - Closing
[0m21:16:03.537213 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103f3ded0>]}
[0m21:16:03.537848 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3363d0>]}
[0m21:16:03.538206 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b77aeb0>]}
[0m21:16:03.538636 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1c0650>]}
[0m21:16:03.539373 [info ] [Thread-2 (]: 2 of 14 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.08s]
[0m21:16:03.540227 [info ] [Thread-3 (]: 3 of 14 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.09s]
[0m21:16:03.540868 [error] [Thread-1 (]: 1 of 14 ERROR creating sql view model raw.bronze_airlines ...................... [[31mERROR[0m in 2.08s]
[0m21:16:03.541981 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:16:03.541473 [info ] [Thread-4 (]: 4 of 14 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.08s]
[0m21:16:03.542498 [debug] [Thread-3 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:16:03.542921 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airlines
[0m21:16:03.543298 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_flights
[0m21:16:03.543880 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:16:03.544385 [debug] [Thread-3 (]: Began running node model.flights_dbt.stg_airlines
[0m21:16:03.544735 [debug] [Thread-1 (]: Began running node model.flights_dbt.silver_airports
[0m21:16:03.545148 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.bronze_airlines' to be skipped because of status 'error'.  Reason: Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql.
[0m21:16:03.545653 [info ] [Thread-2 (]: 5 of 14 START sql view model raw.silver_flights ................................ [RUN]
[0m21:16:03.546096 [info ] [Thread-3 (]: 6 of 14 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:16:03.546524 [info ] [Thread-1 (]: 7 of 14 START sql view model raw.silver_airports ............................... [RUN]
[0m21:16:03.547921 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:16:03.548336 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_airlines
[0m21:16:03.548851 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:16:03.549254 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:16:03.549548 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:16:03.549893 [info ] [Thread-4 (]: 8 of 14 SKIP relation raw.silver_airlines ...................................... [[33mSKIP[0m]
[0m21:16:03.550211 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:16:03.550462 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:16:03.550719 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:16:03.551006 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:16:03.551242 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:16:03.551479 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:16:03.552696 [debug] [Thread-4 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:16:03.553725 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.silver_airlines' to be skipped because of status 'skipped'. 
[0m21:16:03.556400 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:16:03.559324 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:16:03.563981 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:16:03.559674 [info ] [Thread-4 (]: 9 of 14 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:16:03.564712 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:16:03.564939 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:16:03.565125 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:16:03.572857 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:16:03.573153 [debug] [Thread-1 (]: Began executing node model.flights_dbt.silver_airports
[0m21:16:03.573351 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_flights
[0m21:16:03.574397 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:16:03.574564 [debug] [Thread-3 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:16:03.575728 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:16:03.576250 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:16:03.576410 [debug] [Thread-4 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:16:03.585024 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m21:16:03.585484 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:16:03.585820 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:16:03.599758 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:16:03.606345 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:16:03.607185 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:16:03.607558 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:16:03.607678 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:16:03.607768 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:16:03.607887 [debug] [Thread-1 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:16:03.607976 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:16:03.608104 [debug] [Thread-4 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:16:03.608229 [debug] [Thread-2 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:16:03.608341 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:16:03.608456 [debug] [Thread-3 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:16:03.608561 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:16:03.608655 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:16:03.608823 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:16:04.305477 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-99fa-1a59-aca9-77c34b833076) - Created
[0m21:16:04.334050 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-99fe-1cfd-ba3f-1092417532ae) - Created
[0m21:16:04.352586 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-9a01-18b9-999d-1e34097ae412) - Created
[0m21:16:04.364722 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-9a02-1101-94ab-26b75b152960) - Created
[0m21:16:04.831877 [debug] [Thread-4 (]: SQL status: OK in 1.220 seconds
[0m21:16:04.837113 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c3-9a02-1101-94ab-26b75b152960, command-id=01f089c3-9a1e-1204-82c6-8dd9a7a5dc87) - Closing
[0m21:16:04.840342 [debug] [Thread-4 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:16:04.840825 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-9a02-1101-94ab-26b75b152960) - Closing
[0m21:16:04.951471 [debug] [Thread-2 (]: SQL status: OK in 1.340 seconds
[0m21:16:04.953087 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c3-99fe-1cfd-ba3f-1092417532ae, command-id=01f089c3-9a19-1288-821a-167cfbc3e357) - Closing
[0m21:16:04.954314 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:16:04.961931 [debug] [Thread-1 (]: SQL status: OK in 1.350 seconds
[0m21:16:04.963621 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c3-99fa-1a59-aca9-77c34b833076, command-id=01f089c3-9a14-132f-a972-ffecb313af8f) - Closing
[0m21:16:04.964587 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:16:05.040404 [debug] [Thread-2 (]: On model.flights_dbt.silver_flights: Close
[0m21:16:05.041277 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-99fe-1cfd-ba3f-1092417532ae) - Closing
[0m21:16:05.225060 [debug] [Thread-1 (]: On model.flights_dbt.silver_airports: Close
[0m21:16:05.225995 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-99fa-1a59-aca9-77c34b833076) - Closing
[0m21:16:05.413849 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c093110>]}
[0m21:16:05.414592 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c093bf0>]}
[0m21:16:05.412680 [info ] [Thread-4 (]: 9 of 14 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.85s]
[0m21:16:05.415699 [info ] [Thread-2 (]: 5 of 14 OK created sql view model raw.silver_flights ........................... [[32mOK[0m in 1.87s]
[0m21:16:05.417301 [debug] [Thread-4 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:16:05.416638 [info ] [Thread-1 (]: 7 of 14 OK created sql view model raw.silver_airports .......................... [[32mOK[0m in 1.87s]
[0m21:16:05.417981 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_flights
[0m21:16:05.419017 [debug] [Thread-4 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:16:05.419783 [debug] [Thread-1 (]: Finished running node model.flights_dbt.silver_airports
[0m21:16:05.420512 [info ] [Thread-4 (]: 10 of 14 START test unique_my_first_dbt_model_flight_id ........................ [RUN]
[0m21:16:05.421529 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:16:05.422122 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:16:05.422527 [debug] [Thread-2 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:16:05.422894 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:16:05.423369 [info ] [Thread-2 (]: 11 of 14 SKIP relation raw.gold_flight_metrics ................................. [[33mSKIP[0m]
[0m21:16:05.430544 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:16:05.430913 [debug] [Thread-2 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:16:05.431270 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'skipped'. 
[0m21:16:05.431724 [debug] [Thread-4 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:16:05.434521 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:16:05.434978 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:16:05.435255 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:16:05.435486 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:16:06.048513 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-9b04-117e-8b2e-e7e6f2cc8df5) - Created
[0m21:16:06.211379 [debug] [Thread-3 (]: SQL status: OK in 2.600 seconds
[0m21:16:06.213100 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c3-9a01-18b9-999d-1e34097ae412, command-id=01f089c3-9a1c-12b4-a4f9-ecac82277e2c) - Closing
[0m21:16:06.218231 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:16:06.234934 [debug] [Thread-3 (]: On model.flights_dbt.stg_airlines: Close
[0m21:16:06.235311 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-9a01-18b9-999d-1e34097ae412) - Closing
[0m21:16:06.342888 [debug] [Thread-4 (]: SQL status: OK in 0.910 seconds
[0m21:16:06.346186 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c3-9b04-117e-8b2e-e7e6f2cc8df5, command-id=01f089c3-9b1e-1dbc-a003-0c19c783c435) - Closing
[0m21:16:06.436565 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:16:06.437382 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-9b04-117e-8b2e-e7e6f2cc8df5) - Closing
[0m21:16:06.634059 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c092c30>]}
[0m21:16:06.635307 [info ] [Thread-4 (]: 10 of 14 PASS unique_my_first_dbt_model_flight_id .............................. [[32mPASS[0m in 1.21s]
[0m21:16:06.637376 [debug] [Thread-4 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:16:06.636674 [info ] [Thread-3 (]: 6 of 14 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.08s]
[0m21:16:06.638372 [debug] [Thread-3 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:16:06.638799 [debug] [Thread-1 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:16:06.639501 [info ] [Thread-1 (]: 12 of 14 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:16:06.640276 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:16:06.640664 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:16:06.641008 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:16:06.646201 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:16:06.647613 [debug] [Thread-1 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:16:06.670658 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:16:06.672030 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:16:06.672574 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:16:06.673356 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:16:06.673576 [debug] [Thread-1 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:16:06.673762 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:16:07.324225 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-9bc6-13e3-9380-ac3327ec900a) - Created
[0m21:16:07.994613 [debug] [Thread-1 (]: SQL status: OK in 1.320 seconds
[0m21:16:07.996249 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c3-9bc6-13e3-9380-ac3327ec900a, command-id=01f089c3-9be5-188d-97b2-eec7dbccb769) - Closing
[0m21:16:07.997188 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:16:07.998189 [debug] [Thread-1 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:16:07.998486 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-9bc6-13e3-9380-ac3327ec900a) - Closing
[0m21:16:08.195646 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '552e8281-0b61-4695-8fea-c20767c7b951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bee6ff0>]}
[0m21:16:08.197427 [info ] [Thread-1 (]: 12 of 14 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.56s]
[0m21:16:08.198241 [debug] [Thread-1 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:16:08.199275 [debug] [Thread-2 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:16:08.199646 [debug] [Thread-4 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:16:08.200051 [info ] [Thread-2 (]: 13 of 14 START test not_null_my_second_dbt_model_flight_id ..................... [RUN]
[0m21:16:08.200508 [info ] [Thread-4 (]: 14 of 14 START test unique_my_second_dbt_model_flight_id ....................... [RUN]
[0m21:16:08.201164 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d) - Creating connection
[0m21:16:08.201629 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580) - Creating connection
[0m21:16:08.201999 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d'
[0m21:16:08.202258 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580'
[0m21:16:08.202526 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:16:08.202766 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:16:08.211156 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:16:08.214716 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:16:08.215485 [debug] [Thread-4 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:16:08.215806 [debug] [Thread-2 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:16:08.217896 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:16:08.219673 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:16:08.220097 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:16:08.220287 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:16:08.220573 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:16:08.220839 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:16:08.221064 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:16:08.221255 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:16:08.872066 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-9cb4-12d0-a196-f522f1bff97e) - Created
[0m21:16:08.917191 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-9cb9-1316-90e1-971a41882d93) - Created
[0m21:16:09.210697 [debug] [Thread-4 (]: SQL status: OK in 0.990 seconds
[0m21:16:09.214329 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c3-9cb4-12d0-a196-f522f1bff97e, command-id=01f089c3-9ccc-1aad-b6c8-4c44e980564e) - Closing
[0m21:16:09.215550 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: Close
[0m21:16:09.216104 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-9cb4-12d0-a196-f522f1bff97e) - Closing
[0m21:16:09.282444 [debug] [Thread-2 (]: SQL status: OK in 1.060 seconds
[0m21:16:09.290725 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c3-9cb9-1316-90e1-971a41882d93, command-id=01f089c3-9cd5-195c-bf18-7508db3e6322) - Closing
[0m21:16:09.397223 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: Close
[0m21:16:09.397979 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-9cb9-1316-90e1-971a41882d93) - Closing
[0m21:16:09.595601 [info ] [Thread-4 (]: 14 of 14 PASS unique_my_second_dbt_model_flight_id ............................. [[32mPASS[0m in 1.39s]
[0m21:16:09.596472 [info ] [Thread-2 (]: 13 of 14 PASS not_null_my_second_dbt_model_flight_id ........................... [[32mPASS[0m in 1.40s]
[0m21:16:09.597315 [debug] [Thread-4 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:16:09.597841 [debug] [Thread-2 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:16:09.599756 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:16:09.600105 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:16:09.600648 [info ] [MainThread]: 
[0m21:16:09.600974 [info ] [MainThread]: Finished running 2 table models, 4 data tests, 8 view models in 0 hours 0 minutes and 11.26 seconds (11.26s).
[0m21:16:09.603118 [debug] [MainThread]: Command end result
[0m21:16:09.633248 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:16:09.634714 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:16:09.638317 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:16:09.638470 [info ] [MainThread]: 
[0m21:16:09.638628 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:16:09.638749 [info ] [MainThread]: 
[0m21:16:09.638913 [error] [MainThread]: [31mFailure in model bronze_airlines (models/bronze/bronze_airlines.sql)[0m
[0m21:16:09.639072 [error] [MainThread]:   Database Error in model bronze_airlines (models/bronze/bronze_airlines.sql)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `flight_db`.`raw`.`airlines` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 12 pos 5
  compiled code at target/run/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:16:09.639193 [info ] [MainThread]: 
[0m21:16:09.639325 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/bronze/bronze_airlines.sql
[0m21:16:09.639434 [info ] [MainThread]: 
[0m21:16:09.639560 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=1 SKIP=2 NO-OP=0 TOTAL=14
[0m21:16:09.642212 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 12.363496, "process_in_blocks": "0", "process_kernel_time": 0.288093, "process_mem_max_rss": "249217024", "process_out_blocks": "0", "process_user_time": 2.999509}
[0m21:16:09.642422 [debug] [MainThread]: Command `dbt build` failed at 21:16:09.642378 after 12.36 seconds
[0m21:16:09.642602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103e0eab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bda97f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063f8dd0>]}
[0m21:16:09.642757 [debug] [MainThread]: Flushing usage events
[0m21:16:10.443693 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:18:45.992778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104013620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10502f890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10502fb10>]}


============================== 21:18:45.995046 | 9f1909ca-3594-4a90-b546-381bf88a58e1 ==============================
[0m21:18:45.995046 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:18:45.995266 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'printer_width': '80', 'no_print': 'None', 'invocation_command': 'dbt build', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'debug': 'False', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'quiet': 'False', 'version_check': 'True', 'use_colors': 'True', 'log_format': 'default', 'cache_selected_only': 'False', 'write_json': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'profiles_dir': '/Users/artakerqeli/.dbt', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'empty': 'False', 'introspect': 'True', 'warn_error': 'None'}
[0m21:18:46.300082 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:18:46.300284 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:18:46.300377 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:18:46.752005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10435b360>]}
[0m21:18:46.771290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106236ad0>]}
[0m21:18:46.771526 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:18:46.821620 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:18:46.881032 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m21:18:46.881286 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/bronze/bronze_flights.sql
[0m21:18:46.881416 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/bronze/bronze_airports.sql
[0m21:18:46.881534 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/bronze/bronze_airlines.sql
[0m21:18:46.971347 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:18:46.976283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf2fa50>]}
[0m21:18:47.010304 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:18:47.011329 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:18:47.022411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c247c50>]}
[0m21:18:47.022583 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:18:47.023556 [info ] [MainThread]: 
[0m21:18:47.023686 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:18:47.023773 [info ] [MainThread]: 
[0m21:18:47.023976 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:18:47.024068 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:18:47.026620 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:18:47.026733 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:18:47.030898 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:18:47.031018 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:18:47.031110 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:18:47.813057 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-fb6e-17a3-9f37-3da212f73671) - Created
[0m21:18:48.265533 [debug] [ThreadPool]: SQL status: OK in 1.230 seconds
[0m21:18:48.274523 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c3-fb6e-17a3-9f37-3da212f73671, command-id=01f089c3-fb8b-15f1-8b35-815a5c8803fd) - Closing
[0m21:18:48.275038 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:18:48.275258 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-fb6e-17a3-9f37-3da212f73671) - Closing
[0m21:18:48.488231 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:18:48.488786 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:18:48.497728 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:18:48.498214 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:18:48.498487 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:18:49.154869 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-fc3b-1aa2-a6c3-43f9ed5ebdb9) - Created
[0m21:18:49.689689 [debug] [ThreadPool]: SQL status: OK in 1.190 seconds
[0m21:18:49.693213 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c3-fc3b-1aa2-a6c3-43f9ed5ebdb9, command-id=01f089c3-fc57-1941-8d0b-8a0787f4faf6) - Closing
[0m21:18:49.693904 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:18:49.694131 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c3-fc3b-1aa2-a6c3-43f9ed5ebdb9) - Closing
[0m21:18:49.902790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4042f0>]}
[0m21:18:49.908225 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_flights
[0m21:18:49.908691 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airports
[0m21:18:49.909015 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_airlines
[0m21:18:49.909325 [debug] [Thread-3 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:18:49.909882 [info ] [Thread-2 (]: 2 of 13 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:18:49.910350 [info ] [Thread-1 (]: 1 of 13 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:18:49.910850 [info ] [Thread-4 (]: 4 of 13 START sql view model raw.silver_airlines ............................... [RUN]
[0m21:18:49.911292 [info ] [Thread-3 (]: 3 of 13 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:18:49.911895 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:18:49.912452 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:18:49.912882 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airlines) - Creating connection
[0m21:18:49.913295 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:18:49.913618 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:18:49.913910 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:18:49.914192 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airlines'
[0m21:18:49.914470 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:18:49.914877 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:18:49.915296 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:18:49.915557 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_airlines
[0m21:18:49.915822 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:18:49.923416 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:18:49.926479 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_airlines"
[0m21:18:49.930125 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:18:49.931367 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:18:49.932432 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:18:49.938698 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:18:49.944929 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_airlines
[0m21:18:49.948919 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:18:49.951218 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:18:49.951402 [debug] [Thread-3 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:18:49.952345 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:18:49.953379 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:18:49.953683 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:18:49.954648 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:18:49.954867 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:18:49.955136 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4b29c0>]}
[0m21:18:49.955283 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c043950>]}
[0m21:18:49.955481 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:18:49.955637 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3250d0>]}
[0m21:18:49.963438 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:18:49.963646 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:18:49.963789 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c740af0>]}
[0m21:18:49.964162 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_airlines`
[0m21:18:49.968128 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:18:49.968446 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:18:49.968803 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_airlines"
[0m21:18:49.969097 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:18:49.969520 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:18:49.969742 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_airlines"
[0m21:18:49.969896 [debug] [Thread-4 (]: On model.flights_dbt.silver_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airlines`
  
  as (
    select
    airline
from `flight_db`.`raw`.`bronze_airlines`
  )

[0m21:18:49.970012 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:18:49.970111 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:18:49.970219 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:18:49.970377 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    -- models/bronze/bronze_airports.sql
select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:18:49.970493 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:18:49.970619 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    -- models/bronze/bronze_flights.sql
select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m21:18:49.970829 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:18:49.970961 [debug] [Thread-3 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:18:49.971118 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:18:49.971360 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:18:50.702060 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-fd29-132d-a9c8-a5bb48e902aa) - Created
[0m21:18:50.706257 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-fd27-1ade-80a7-8954ab77113a) - Created
[0m21:18:50.725358 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-fd2b-1891-b583-23566d2aedc7) - Created
[0m21:18:50.749577 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-fd2f-17bd-a60f-c86a19e96a50) - Created
[0m21:18:51.281975 [debug] [Thread-4 (]: SQL status: OK in 1.310 seconds
[0m21:18:51.284429 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c3-fd29-132d-a9c8-a5bb48e902aa, command-id=01f089c3-fd43-1cbe-8b9f-b439f3aa2f1d) - Closing
[0m21:18:51.299553 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:18:51.303197 [debug] [Thread-4 (]: On model.flights_dbt.silver_airlines: Close
[0m21:18:51.303502 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-fd29-132d-a9c8-a5bb48e902aa) - Closing
[0m21:18:51.306524 [debug] [Thread-1 (]: SQL status: OK in 1.340 seconds
[0m21:18:51.307306 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c3-fd2b-1891-b583-23566d2aedc7, command-id=01f089c3-fd47-12c7-ad6f-71cceb5ce709) - Closing
[0m21:18:51.307832 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:18:51.312490 [debug] [Thread-3 (]: SQL status: OK in 1.340 seconds
[0m21:18:51.313122 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c3-fd27-1ade-80a7-8954ab77113a, command-id=01f089c3-fd43-1623-908a-92c3a717257b) - Closing
[0m21:18:51.313575 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:18:51.360937 [debug] [Thread-2 (]: SQL status: OK in 1.390 seconds
[0m21:18:51.362258 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c3-fd2f-17bd-a60f-c86a19e96a50, command-id=01f089c3-fd4b-1015-ba87-e235fd05e8c4) - Closing
[0m21:18:51.363119 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:18:51.506524 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: Close
[0m21:18:51.507825 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-fd2b-1891-b583-23566d2aedc7) - Closing
[0m21:18:51.706718 [debug] [Thread-3 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:18:51.707795 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-fd27-1ade-80a7-8954ab77113a) - Closing
[0m21:18:51.904858 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: Close
[0m21:18:51.905878 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-fd2f-17bd-a60f-c86a19e96a50) - Closing
[0m21:18:52.110548 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104319ed0>]}
[0m21:18:52.111068 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7769d0>]}
[0m21:18:52.111366 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4bf700>]}
[0m21:18:52.111739 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4db650>]}
[0m21:18:52.112393 [info ] [Thread-4 (]: 4 of 13 OK created sql view model raw.silver_airlines .......................... [[32mOK[0m in 2.19s]
[0m21:18:52.112901 [info ] [Thread-2 (]: 2 of 13 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.20s]
[0m21:18:52.113557 [info ] [Thread-1 (]: 1 of 13 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.19s]
[0m21:18:52.114046 [info ] [Thread-3 (]: 3 of 13 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.20s]
[0m21:18:52.114589 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:18:52.114998 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:18:52.115384 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:18:52.115771 [debug] [Thread-3 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:18:52.116129 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_flights
[0m21:18:52.116566 [debug] [Thread-2 (]: Began running node model.flights_dbt.stg_airlines
[0m21:18:52.117119 [debug] [Thread-1 (]: Began running node model.flights_dbt.silver_airports
[0m21:18:52.117895 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:18:52.117615 [info ] [Thread-4 (]: 5 of 13 START sql view model raw.silver_flights ................................ [RUN]
[0m21:18:52.118255 [info ] [Thread-2 (]: 6 of 13 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:18:52.118607 [info ] [Thread-1 (]: 7 of 13 START sql view model raw.silver_airports ............................... [RUN]
[0m21:18:52.118968 [info ] [Thread-3 (]: 8 of 13 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:18:52.119579 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:18:52.119950 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:18:52.120297 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:18:52.120641 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:18:52.120916 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:18:52.121167 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:18:52.121383 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:18:52.121587 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:18:52.121813 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:18:52.122021 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:18:52.122225 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:18:52.122475 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:18:52.124758 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:18:52.127831 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:18:52.129802 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:18:52.138833 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:18:52.139466 [debug] [Thread-1 (]: Began executing node model.flights_dbt.silver_airports
[0m21:18:52.140746 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:18:52.140960 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_flights
[0m21:18:52.141642 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:18:52.143117 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:18:52.143661 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:18:52.143854 [debug] [Thread-2 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:18:52.144031 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:18:52.144630 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:18:52.154225 [debug] [Thread-2 (]: MATERIALIZING TABLE
[0m21:18:52.162141 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:18:52.162515 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:18:52.162649 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:18:52.176480 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:18:52.176648 [debug] [Thread-1 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:18:52.176851 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:18:52.177083 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:18:52.177217 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:18:52.177334 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:18:52.177518 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:18:52.177668 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:18:52.177814 [debug] [Thread-2 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:18:52.177957 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:18:52.178073 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:18:52.178189 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:18:52.848853 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-fe6f-1cab-88a7-1cba4b5d783e) - Created
[0m21:18:52.891284 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-fe76-1bab-8623-82fad188ce45) - Created
[0m21:18:52.900796 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-fe77-17f3-ac04-f8e71dfd9779) - Created
[0m21:18:52.917518 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-fe78-1a08-b692-8425f20daf86) - Created
[0m21:18:53.372277 [debug] [Thread-3 (]: SQL status: OK in 1.190 seconds
[0m21:18:53.378417 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c3-fe76-1bab-8623-82fad188ce45, command-id=01f089c3-fe92-1525-a7f3-834adc405927) - Closing
[0m21:18:53.381541 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:18:53.381927 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-fe76-1bab-8623-82fad188ce45) - Closing
[0m21:18:53.563211 [debug] [Thread-4 (]: SQL status: OK in 1.390 seconds
[0m21:18:53.564819 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c3-fe77-17f3-ac04-f8e71dfd9779, command-id=01f089c3-fe94-1146-b2ba-080a4c74c63e) - Closing
[0m21:18:53.565855 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:18:53.608822 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: Close
[0m21:18:53.611919 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-fe77-17f3-ac04-f8e71dfd9779) - Closing
[0m21:18:53.612497 [debug] [Thread-1 (]: SQL status: OK in 1.440 seconds
[0m21:18:53.614201 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c3-fe78-1a08-b692-8425f20daf86, command-id=01f089c3-fe95-16bc-8b45-0a60dd1cc05d) - Closing
[0m21:18:53.615119 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:18:53.811295 [debug] [Thread-1 (]: On model.flights_dbt.silver_airports: Close
[0m21:18:53.810358 [info ] [Thread-3 (]: 8 of 13 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.69s]
[0m21:18:53.812030 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c3-fe78-1a08-b692-8425f20daf86) - Closing
[0m21:18:53.812689 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:18:53.813773 [debug] [Thread-3 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:18:53.814321 [info ] [Thread-3 (]: 9 of 13 START test unique_my_first_dbt_model_flight_id ......................... [RUN]
[0m21:18:54.010039 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4da1b0>]}
[0m21:18:54.010953 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:18:54.011480 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4dabd0>]}
[0m21:18:54.012792 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:18:54.012425 [info ] [Thread-4 (]: 5 of 13 OK created sql view model raw.silver_flights ........................... [[32mOK[0m in 1.89s]
[0m21:18:54.013969 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:18:54.013636 [info ] [Thread-1 (]: 7 of 13 OK created sql view model raw.silver_airports .......................... [[32mOK[0m in 1.89s]
[0m21:18:54.014594 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_flights
[0m21:18:54.023631 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:18:54.024363 [debug] [Thread-1 (]: Finished running node model.flights_dbt.silver_airports
[0m21:18:54.025200 [debug] [Thread-4 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:18:54.025685 [info ] [Thread-4 (]: 10 of 13 START sql table model raw.gold_flight_metrics ......................... [RUN]
[0m21:18:54.026399 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.gold_flight_metrics) - Creating connection
[0m21:18:54.026914 [debug] [Thread-3 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:18:54.027307 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.gold_flight_metrics'
[0m21:18:54.032315 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.gold_flight_metrics
[0m21:18:54.036360 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.gold_flight_metrics"
[0m21:18:54.040182 [debug] [Thread-4 (]: Began executing node model.flights_dbt.gold_flight_metrics
[0m21:18:54.047795 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m21:18:54.048318 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:18:54.049349 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.gold_flight_metrics"
[0m21:18:54.049886 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:18:54.050110 [debug] [Thread-3 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:18:54.050276 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.gold_flight_metrics"
[0m21:18:54.050475 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:18:54.050698 [debug] [Thread-4 (]: On model.flights_dbt.gold_flight_metrics: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
    
        create or replace table `flight_db`.`raw`.`gold_flight_metrics`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with f as (select * from `flight_db`.`raw`.`silver_flights`),
al as (select * from `flight_db`.`raw`.`silver_airlines`),
ap as (select * from `flight_db`.`raw`.`silver_airports`)

select
  f.flight_date,
  f.airline,
  al.airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.dest,
  d.airport_name as dest_airport_name,
  count(*)                          as flights,
  avg(coalesce(f.dep_delay, 0))      as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0))      as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from f
left join al on f.airline = al.airline_code
left join ap o on f.origin = o.iata
left join ap d on f.dest   = d.iata
group by 1,2,3,4,5,6,7
  
[0m21:18:54.051034 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:18:54.713212 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-ff88-11ca-b285-066f7fb13600) - Created
[0m21:18:54.730383 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-ff8d-1aba-b68c-edd62f9671a1) - Created
[0m21:18:54.851284 [debug] [Thread-2 (]: SQL status: OK in 2.670 seconds
[0m21:18:54.852696 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c3-fe6f-1cab-88a7-1cba4b5d783e, command-id=01f089c3-fe89-19a4-b664-dbde9b1ee66f) - Closing
[0m21:18:54.857303 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:18:54.874216 [debug] [Thread-2 (]: On model.flights_dbt.stg_airlines: Close
[0m21:18:54.874553 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c3-fe6f-1cab-88a7-1cba4b5d783e) - Closing
[0m21:18:55.060244 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3d2990>]}
[0m21:18:55.061585 [info ] [Thread-2 (]: 6 of 13 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 2.94s]
[0m21:18:55.062315 [debug] [Thread-2 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:18:55.149121 [debug] [Thread-3 (]: SQL status: OK in 1.100 seconds
[0m21:18:55.152204 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c3-ff88-11ca-b285-066f7fb13600, command-id=01f089c3-ffa7-1cb2-af77-e75106f2dd88) - Closing
[0m21:18:55.153180 [debug] [Thread-3 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:18:55.153612 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c3-ff88-11ca-b285-066f7fb13600) - Closing
[0m21:18:55.333915 [info ] [Thread-3 (]: 9 of 13 PASS unique_my_first_dbt_model_flight_id ............................... [[32mPASS[0m in 1.52s]
[0m21:18:55.335012 [debug] [Thread-3 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:18:55.335858 [debug] [Thread-1 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:18:55.336446 [info ] [Thread-1 (]: 11 of 13 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:18:55.337158 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:18:55.337500 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:18:55.337807 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:18:55.342038 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:18:55.343248 [debug] [Thread-1 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:18:55.345647 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:18:55.347498 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:18:55.348315 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:18:55.349366 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:18:55.349812 [debug] [Thread-1 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:18:55.350244 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:18:55.515235 [debug] [Thread-4 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
    
        create or replace table `flight_db`.`raw`.`gold_flight_metrics`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with f as (select * from `flight_db`.`raw`.`silver_flights`),
al as (select * from `flight_db`.`raw`.`silver_airlines`),
ap as (select * from `flight_db`.`raw`.`silver_airports`)

select
  f.flight_date,
  f.airline,
  al.airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.dest,
  d.airport_name as dest_airport_name,
  count(*)                          as flights,
  avg(coalesce(f.dep_delay, 0))      as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0))      as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from f
left join al on f.airline = al.airline_code
left join ap o on f.origin = o.iata
left join ap d on f.dest   = d.iata
group by 1,2,3,4,5,6,7
  
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`airline_code` cannot be resolved. Did you mean one of the following? [`al`.`airline`, `f`.`airline`, `f`.`flight_id`, `f`.`arr_delay`, `f`.`arr_time`]. SQLSTATE: 42703; line 34 pos 28
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`airline_code` cannot be resolved. Did you mean one of the following? [`al`.`airline`, `f`.`airline`, `f`.`flight_id`, `f`.`arr_delay`, `f`.`arr_time`]. SQLSTATE: 42703; line 34 pos 28
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`airline_code` cannot be resolved. Did you mean one of the following? [`al`.`airline`, `f`.`airline`, `f`.`flight_id`, `f`.`arr_delay`, `f`.`arr_time`]. SQLSTATE: 42703; line 34 pos 28
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c3-ffab-1bb2-9e64-439df2d80149
[0m21:18:55.516640 [debug] [Thread-4 (]: On model.flights_dbt.gold_flight_metrics: Close
[0m21:18:55.517059 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c3-ff8d-1aba-b68c-edd62f9671a1) - Closing
[0m21:18:55.738114 [debug] [Thread-4 (]: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`airline_code` cannot be resolved. Did you mean one of the following? [`al`.`airline`, `f`.`airline`, `f`.`flight_id`, `f`.`arr_delay`, `f`.`arr_time`]. SQLSTATE: 42703; line 34 pos 28
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:18:55.739024 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f413950>]}
[0m21:18:55.739768 [error] [Thread-4 (]: 10 of 13 ERROR creating sql table model raw.gold_flight_metrics ................ [[31mERROR[0m in 1.71s]
[0m21:18:55.740434 [debug] [Thread-4 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:18:55.741044 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'error'.  Reason: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`airline_code` cannot be resolved. Did you mean one of the following? [`al`.`airline`, `f`.`airline`, `f`.`flight_id`, `f`.`arr_delay`, `f`.`arr_time`]. SQLSTATE: 42703; line 34 pos 28
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql.
[0m21:18:56.031898 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-0055-1586-898f-8f8220d5b5fd) - Created
[0m21:18:56.599623 [debug] [Thread-1 (]: SQL status: OK in 1.250 seconds
[0m21:18:56.601147 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c4-0055-1586-898f-8f8220d5b5fd, command-id=01f089c4-0072-1305-b65a-90e9ef1d3e7e) - Closing
[0m21:18:56.602070 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:18:56.603032 [debug] [Thread-1 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:18:56.603298 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-0055-1586-898f-8f8220d5b5fd) - Closing
[0m21:18:56.801424 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f1909ca-3594-4a90-b546-381bf88a58e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4d88f0>]}
[0m21:18:56.803128 [info ] [Thread-1 (]: 11 of 13 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.46s]
[0m21:18:56.803877 [debug] [Thread-1 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:18:56.805023 [debug] [Thread-2 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:18:56.805373 [debug] [Thread-3 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:18:56.805736 [info ] [Thread-2 (]: 12 of 13 START test not_null_my_second_dbt_model_flight_id ..................... [RUN]
[0m21:18:56.806169 [info ] [Thread-3 (]: 13 of 13 START test unique_my_second_dbt_model_flight_id ....................... [RUN]
[0m21:18:56.806886 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d) - Creating connection
[0m21:18:56.807408 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580) - Creating connection
[0m21:18:56.807753 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d'
[0m21:18:56.808041 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580'
[0m21:18:56.808339 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:18:56.808613 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:18:56.814331 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:18:56.823577 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:18:56.824200 [debug] [Thread-2 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:18:56.826349 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:18:56.826631 [debug] [Thread-3 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:18:56.828569 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:18:56.828987 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:18:56.829296 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:18:56.829536 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:18:56.829721 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:18:56.830079 [debug] [Thread-3 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:18:56.830368 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:18:57.522237 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-0138-11cc-99c6-2f7eac727c1a) - Created
[0m21:18:57.524712 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-0139-1031-ae98-b783147245a5) - Created
[0m21:18:57.877537 [debug] [Thread-2 (]: SQL status: OK in 1.050 seconds
[0m21:18:57.880515 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c4-0138-11cc-99c6-2f7eac727c1a, command-id=01f089c4-0154-18b6-b4a2-0ca52730aa8f) - Closing
[0m21:18:57.881227 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: Close
[0m21:18:57.881529 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-0138-11cc-99c6-2f7eac727c1a) - Closing
[0m21:18:57.888524 [debug] [Thread-3 (]: SQL status: OK in 1.060 seconds
[0m21:18:57.890136 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c4-0139-1031-ae98-b783147245a5, command-id=01f089c4-0154-1a0e-9f81-63da26cbdc33) - Closing
[0m21:18:58.085478 [debug] [Thread-3 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: Close
[0m21:18:58.086485 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-0139-1031-ae98-b783147245a5) - Closing
[0m21:18:58.282966 [info ] [Thread-2 (]: 12 of 13 PASS not_null_my_second_dbt_model_flight_id ........................... [[32mPASS[0m in 1.48s]
[0m21:18:58.283928 [info ] [Thread-3 (]: 13 of 13 PASS unique_my_second_dbt_model_flight_id ............................. [[32mPASS[0m in 1.48s]
[0m21:18:58.284820 [debug] [Thread-2 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:18:58.285376 [debug] [Thread-3 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:18:58.287393 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:18:58.287748 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:18:58.288301 [info ] [MainThread]: 
[0m21:18:58.288638 [info ] [MainThread]: Finished running 2 table models, 4 data tests, 7 view models in 0 hours 0 minutes and 11.26 seconds (11.26s).
[0m21:18:58.290856 [debug] [MainThread]: Command end result
[0m21:18:58.322342 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:18:58.323659 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:18:58.328017 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:18:58.328162 [info ] [MainThread]: 
[0m21:18:58.328328 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:18:58.328460 [info ] [MainThread]: 
[0m21:18:58.328628 [error] [MainThread]: [31mFailure in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)[0m
[0m21:18:58.328789 [error] [MainThread]:   Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`airline_code` cannot be resolved. Did you mean one of the following? [`al`.`airline`, `f`.`airline`, `f`.`flight_id`, `f`.`arr_delay`, `f`.`arr_time`]. SQLSTATE: 42703; line 34 pos 28
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:18:58.328904 [info ] [MainThread]: 
[0m21:18:58.329039 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:18:58.329153 [info ] [MainThread]: 
[0m21:18:58.329287 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=13
[0m21:18:58.332414 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 12.369942, "process_in_blocks": "0", "process_kernel_time": 0.296395, "process_mem_max_rss": "252641280", "process_out_blocks": "0", "process_user_time": 2.857243}
[0m21:18:58.332646 [debug] [MainThread]: Command `dbt build` failed at 21:18:58.332600 after 12.37 seconds
[0m21:18:58.332837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fda7b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c767f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c767dd0>]}
[0m21:18:58.333002 [debug] [MainThread]: Flushing usage events
[0m21:18:59.264221 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:20:17.990699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e87620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073ff890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073ffb10>]}


============================== 21:20:17.992946 | 28510e67-d9d5-4888-8552-02ce4a45730c ==============================
[0m21:20:17.992946 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:20:17.993176 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'profiles_dir': '/Users/artakerqeli/.dbt', 'version_check': 'True', 'quiet': 'False', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_format': 'default', 'cache_selected_only': 'False', 'empty': 'False', 'write_json': 'True', 'no_print': 'None', 'target_path': 'None', 'invocation_command': 'dbt build', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'printer_width': '80', 'warn_error': 'None'}
[0m21:20:18.292740 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:20:18.292975 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:20:18.293074 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:20:18.739154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10632b360>]}
[0m21:20:18.758299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109506ad0>]}
[0m21:20:18.758538 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:20:18.811009 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:20:18.869331 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:20:18.869575 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/gold/gold_flight_metrics.sql
[0m21:20:18.958238 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:20:18.963040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118e0ba50>]}
[0m21:20:18.996634 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:20:18.997751 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:20:19.009410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119127e30>]}
[0m21:20:19.009591 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:20:19.010559 [info ] [MainThread]: 
[0m21:20:19.010683 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:20:19.010766 [info ] [MainThread]: 
[0m21:20:19.010956 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:20:19.011044 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:20:19.013591 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:20:19.013723 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:20:19.018474 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:20:19.018592 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:20:19.018676 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:20:19.677948 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c4-3232-11cb-a7e7-65f3611fe1c4) - Created
[0m21:20:20.011051 [debug] [ThreadPool]: SQL status: OK in 0.990 seconds
[0m21:20:20.018545 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c4-3232-11cb-a7e7-65f3611fe1c4, command-id=01f089c4-324a-1d64-a9d8-64c848f37f15) - Closing
[0m21:20:20.018982 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:20:20.019166 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c4-3232-11cb-a7e7-65f3611fe1c4) - Closing
[0m21:20:20.207663 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:20:20.208245 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:20:20.217112 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:20:20.217570 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:20:20.217828 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:20:20.876053 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c4-32e7-1778-811b-de6221d32ffc) - Created
[0m21:20:21.472427 [debug] [ThreadPool]: SQL status: OK in 1.250 seconds
[0m21:20:21.476688 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c4-32e7-1778-811b-de6221d32ffc, command-id=01f089c4-3303-11e8-bf59-4d66d5892a40) - Closing
[0m21:20:21.477497 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:20:21.477756 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c4-32e7-1778-811b-de6221d32ffc) - Closing
[0m21:20:21.683622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1192fa970>]}
[0m21:20:21.687541 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airports
[0m21:20:21.687919 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_airlines
[0m21:20:21.688164 [debug] [Thread-3 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:20:21.688413 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_flights
[0m21:20:21.688974 [info ] [Thread-1 (]: 1 of 13 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:20:21.689426 [info ] [Thread-4 (]: 4 of 13 START sql view model raw.silver_airlines ............................... [RUN]
[0m21:20:21.689797 [info ] [Thread-3 (]: 3 of 13 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:20:21.690156 [info ] [Thread-2 (]: 2 of 13 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:20:21.690627 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:20:21.690999 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airlines) - Creating connection
[0m21:20:21.691363 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:20:21.691701 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:20:21.691965 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:20:21.692203 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airlines'
[0m21:20:21.692436 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:20:21.692652 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:20:21.692856 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:20:21.693059 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_airlines
[0m21:20:21.693254 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:20:21.693452 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:20:21.699485 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:20:21.701347 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:20:21.704114 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_airlines"
[0m21:20:21.705595 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:20:21.706600 [debug] [Thread-3 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:20:21.712369 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:20:21.712596 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:20:21.716066 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:20:21.716214 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_airlines
[0m21:20:21.717118 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:20:21.718131 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:20:21.719142 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:20:21.720188 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:20:21.720463 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:20:21.720760 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:20:21.721003 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119396000>]}
[0m21:20:21.721246 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:20:21.721450 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119287d10>]}
[0m21:20:21.721612 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119204650>]}
[0m21:20:21.727659 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1192daa40>]}
[0m21:20:21.728495 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:20:21.728990 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:20:21.729308 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:20:21.729611 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_airlines`
[0m21:20:21.734125 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:20:21.734473 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:20:21.734769 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:20:21.735049 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_airlines"
[0m21:20:21.735702 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:20:21.735821 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_airlines"
[0m21:20:21.735994 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    -- models/bronze/bronze_airports.sql
select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:20:21.736104 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:20:21.736207 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:20:21.736343 [debug] [Thread-4 (]: On model.flights_dbt.silver_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airlines`
  
  as (
    select
    airline
from `flight_db`.`raw`.`bronze_airlines`
  )

[0m21:20:21.736466 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:20:21.736597 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    -- models/bronze/bronze_flights.sql
select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m21:20:21.736737 [debug] [Thread-3 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:20:21.736852 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:20:21.737065 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:20:21.737257 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:20:22.463822 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-33da-13a4-b429-ff8765f99282) - Created
[0m21:20:22.476935 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-33dd-10a8-9796-83e1b363c665) - Created
[0m21:20:22.479973 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-33dd-1f29-a7a6-9be413160d8f) - Created
[0m21:20:22.493747 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-33df-166c-8bb8-903ab899a0d5) - Created
[0m21:20:23.177366 [debug] [Thread-2 (]: SQL status: OK in 1.440 seconds
[0m21:20:23.182093 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c4-33da-13a4-b429-ff8765f99282, command-id=01f089c4-33f4-1ff5-b150-1cca92fa742b) - Closing
[0m21:20:23.182567 [debug] [Thread-4 (]: SQL status: OK in 1.450 seconds
[0m21:20:23.195513 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:20:23.196407 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c4-33df-166c-8bb8-903ab899a0d5, command-id=01f089c4-33f9-1b95-b121-280f25fcf7b3) - Closing
[0m21:20:23.196734 [debug] [Thread-1 (]: SQL status: OK in 1.460 seconds
[0m21:20:23.200212 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: Close
[0m21:20:23.201727 [debug] [Thread-3 (]: SQL status: OK in 1.460 seconds
[0m21:20:23.202245 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:20:23.202911 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c4-33dd-10a8-9796-83e1b363c665, command-id=01f089c4-33f6-109a-99a2-69cca48ea350) - Closing
[0m21:20:23.203146 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-33da-13a4-b429-ff8765f99282) - Closing
[0m21:20:23.203683 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c4-33dd-1f29-a7a6-9be413160d8f, command-id=01f089c4-33f8-1410-8292-cc582cdcd3e1) - Closing
[0m21:20:23.204412 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:20:23.205157 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:20:23.407047 [debug] [Thread-4 (]: On model.flights_dbt.silver_airlines: Close
[0m21:20:23.408084 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-33df-166c-8bb8-903ab899a0d5) - Closing
[0m21:20:23.616245 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: Close
[0m21:20:23.617287 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-33dd-10a8-9796-83e1b363c665) - Closing
[0m21:20:23.808732 [debug] [Thread-3 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:20:23.809520 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-33dd-1f29-a7a6-9be413160d8f) - Closing
[0m21:20:24.018280 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062e9ed0>]}
[0m21:20:24.018839 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a386ed0>]}
[0m21:20:24.019138 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11939d080>]}
[0m21:20:24.019547 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1193b8b30>]}
[0m21:20:24.020224 [info ] [Thread-4 (]: 4 of 13 OK created sql view model raw.silver_airlines .......................... [[32mOK[0m in 2.32s]
[0m21:20:24.020722 [info ] [Thread-3 (]: 3 of 13 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.33s]
[0m21:20:24.021382 [info ] [Thread-2 (]: 2 of 13 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.32s]
[0m21:20:24.022492 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:20:24.022000 [info ] [Thread-1 (]: 1 of 13 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.33s]
[0m21:20:24.022996 [debug] [Thread-3 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:20:24.023407 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:20:24.023783 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_flights
[0m21:20:24.024354 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:20:24.024719 [debug] [Thread-3 (]: Began running node model.flights_dbt.stg_airlines
[0m21:20:24.025727 [debug] [Thread-2 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:20:24.025364 [info ] [Thread-4 (]: 5 of 13 START sql view model raw.silver_flights ................................ [RUN]
[0m21:20:24.026176 [debug] [Thread-1 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:20:24.026562 [info ] [Thread-3 (]: 6 of 13 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:20:24.026957 [info ] [Thread-2 (]: 7 of 13 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:20:24.027595 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:20:24.027927 [info ] [Thread-1 (]: 8 of 13 START test unique_my_first_dbt_model_flight_id ......................... [RUN]
[0m21:20:24.028410 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:20:24.028801 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:20:24.029111 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:20:24.029662 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:20:24.029930 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:20:24.030175 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:20:24.030457 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:20:24.030678 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:20:24.030986 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:20:24.031314 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:20:24.032502 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:20:24.035698 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:20:24.047669 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:20:24.049837 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:20:24.054100 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:20:24.054630 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_flights
[0m21:20:24.055710 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:20:24.056246 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:20:24.056656 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:20:24.056904 [debug] [Thread-3 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:20:24.063177 [debug] [Thread-1 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:20:24.065952 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m21:20:24.072387 [debug] [Thread-2 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:20:24.072541 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:20:24.073911 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:20:24.087366 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:20:24.088296 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:20:24.088442 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:20:24.088679 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:20:24.088929 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:20:24.089031 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:20:24.089167 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:20:24.089297 [debug] [Thread-3 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:20:24.089432 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:20:24.089571 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:20:24.089687 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:20:24.089781 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:20:24.089877 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:20:24.849536 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-3546-1990-a7ea-ffcd426c85d1) - Created
[0m21:20:24.852920 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-3547-12f6-b2e5-9b6d8a5d5050) - Created
[0m21:20:24.854668 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-3546-1904-bb9d-f239aae8998f) - Created
[0m21:20:24.855697 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-3545-15a7-bebb-5943e5bb0439) - Created
[0m21:20:25.192424 [debug] [Thread-1 (]: SQL status: OK in 1.100 seconds
[0m21:20:25.197224 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c4-3547-12f6-b2e5-9b6d8a5d5050, command-id=01f089c4-3562-168f-befe-01a347cb1cfb) - Closing
[0m21:20:25.200089 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:20:25.200511 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-3547-12f6-b2e5-9b6d8a5d5050) - Closing
[0m21:20:25.256463 [debug] [Thread-2 (]: SQL status: OK in 1.170 seconds
[0m21:20:25.259645 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c4-3546-1990-a7ea-ffcd426c85d1, command-id=01f089c4-3561-1be0-889a-7a7ef7aeecda) - Closing
[0m21:20:25.391810 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:20:25.392658 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-3546-1990-a7ea-ffcd426c85d1) - Closing
[0m21:20:25.484920 [debug] [Thread-4 (]: SQL status: OK in 1.400 seconds
[0m21:20:25.486472 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c4-3546-1904-bb9d-f239aae8998f, command-id=01f089c4-3562-1409-ad2c-514befb897be) - Closing
[0m21:20:25.487454 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:20:25.589913 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: Close
[0m21:20:25.589381 [info ] [Thread-1 (]: 8 of 13 PASS unique_my_first_dbt_model_flight_id ............................... [[32mPASS[0m in 1.56s]
[0m21:20:25.590472 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-3546-1904-bb9d-f239aae8998f) - Closing
[0m21:20:25.591001 [debug] [Thread-1 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:20:25.591751 [debug] [Thread-1 (]: Began running node model.flights_dbt.silver_airports
[0m21:20:25.592533 [info ] [Thread-1 (]: 9 of 13 START sql view model raw.silver_airports ............................... [RUN]
[0m21:20:25.789059 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:20:25.787168 [info ] [Thread-2 (]: 7 of 13 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.76s]
[0m21:20:25.790239 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a3b4f50>]}
[0m21:20:25.790764 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:20:25.791299 [debug] [Thread-2 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:20:25.792528 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:20:25.792178 [info ] [Thread-4 (]: 5 of 13 OK created sql view model raw.silver_flights ........................... [[32mOK[0m in 1.76s]
[0m21:20:25.797438 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:20:25.798087 [debug] [Thread-2 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:20:25.798750 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_flights
[0m21:20:25.799295 [info ] [Thread-2 (]: 10 of 13 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:20:25.800146 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:20:25.800461 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:20:25.800784 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:20:25.804016 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:20:25.804432 [debug] [Thread-1 (]: Began executing node model.flights_dbt.silver_airports
[0m21:20:25.807376 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:20:25.808382 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:20:25.808984 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:20:25.809308 [debug] [Thread-2 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:20:25.810940 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:20:25.814545 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:20:25.815535 [debug] [Thread-1 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:20:25.816393 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:20:25.821438 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:20:25.822170 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:20:25.823050 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:20:25.823259 [debug] [Thread-2 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:20:25.823436 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:20:26.478396 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-363e-1d03-9bce-b3d229731da0) - Created
[0m21:20:26.480804 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-363e-15e2-8a9e-221274642ba0) - Created
[0m21:20:26.634273 [debug] [Thread-3 (]: SQL status: OK in 2.540 seconds
[0m21:20:26.636876 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c4-3545-15a7-bebb-5943e5bb0439, command-id=01f089c4-3562-1646-a192-ff921ff13488) - Closing
[0m21:20:26.640909 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:20:26.650939 [debug] [Thread-3 (]: On model.flights_dbt.stg_airlines: Close
[0m21:20:26.651156 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-3545-15a7-bebb-5943e5bb0439) - Closing
[0m21:20:26.845816 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1193b8950>]}
[0m21:20:26.847459 [info ] [Thread-3 (]: 6 of 13 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 2.82s]
[0m21:20:26.848148 [debug] [Thread-3 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:20:27.043184 [debug] [Thread-1 (]: SQL status: OK in 1.230 seconds
[0m21:20:27.044866 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c4-363e-15e2-8a9e-221274642ba0, command-id=01f089c4-3659-1631-a96e-a00bb6c39dea) - Closing
[0m21:20:27.045783 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:20:27.046717 [debug] [Thread-1 (]: On model.flights_dbt.silver_airports: Close
[0m21:20:27.047046 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-363e-15e2-8a9e-221274642ba0) - Closing
[0m21:20:27.099293 [debug] [Thread-2 (]: SQL status: OK in 1.280 seconds
[0m21:20:27.100875 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c4-363e-1d03-9bce-b3d229731da0, command-id=01f089c4-3659-12c5-9c16-2317c98d2e62) - Closing
[0m21:20:27.101783 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:20:27.233308 [debug] [Thread-2 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:20:27.234437 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-363e-1d03-9bce-b3d229731da0) - Closing
[0m21:20:27.429283 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1193b8950>]}
[0m21:20:27.430211 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1193bbf50>]}
[0m21:20:27.431390 [info ] [Thread-1 (]: 9 of 13 OK created sql view model raw.silver_airports .......................... [[32mOK[0m in 1.84s]
[0m21:20:27.432746 [debug] [Thread-1 (]: Finished running node model.flights_dbt.silver_airports
[0m21:20:27.432209 [info ] [Thread-2 (]: 10 of 13 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.63s]
[0m21:20:27.433536 [debug] [Thread-2 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:20:27.433937 [debug] [Thread-4 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:20:27.434726 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:20:27.434425 [info ] [Thread-4 (]: 11 of 13 START sql table model raw.gold_flight_metrics ......................... [RUN]
[0m21:20:27.435097 [debug] [Thread-1 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:20:27.435385 [info ] [Thread-3 (]: 12 of 13 START test not_null_my_second_dbt_model_flight_id ..................... [RUN]
[0m21:20:27.435996 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.gold_flight_metrics) - Creating connection
[0m21:20:27.436388 [info ] [Thread-1 (]: 13 of 13 START test unique_my_second_dbt_model_flight_id ....................... [RUN]
[0m21:20:27.436913 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d) - Creating connection
[0m21:20:27.437262 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.gold_flight_metrics'
[0m21:20:27.437658 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580) - Creating connection
[0m21:20:27.437951 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d'
[0m21:20:27.438235 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.gold_flight_metrics
[0m21:20:27.438506 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580'
[0m21:20:27.438769 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:20:27.443236 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.gold_flight_metrics"
[0m21:20:27.443595 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:20:27.448796 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:20:27.455262 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:20:27.455709 [debug] [Thread-4 (]: Began executing node model.flights_dbt.gold_flight_metrics
[0m21:20:27.455978 [debug] [Thread-1 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:20:27.457400 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m21:20:27.459457 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:20:27.459679 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:20:27.460852 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.gold_flight_metrics"
[0m21:20:27.462523 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:20:27.462848 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:20:27.463081 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:20:27.463268 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:20:27.463596 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.gold_flight_metrics"
[0m21:20:27.463762 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:20:27.464002 [debug] [Thread-4 (]: On model.flights_dbt.gold_flight_metrics: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
    
        create or replace table `flight_db`.`raw`.`gold_flight_metrics`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with f as (select * from `flight_db`.`raw`.`silver_flights`),
al as (select * from `flight_db`.`raw`.`silver_airlines`),
ap as (select * from `flight_db`.`raw`.`silver_airports`)

select
  f.flight_date,
  f.airline,
  al.airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.dest,
  d.airport_name as dest_airport_name,
  count(*)                          as flights,
  avg(coalesce(f.dep_delay, 0))      as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0))      as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from f
left join al on f.airline = al.airline
left join ap o on f.origin = o.iata
left join ap d on f.dest   = d.iata
group by 1,2,3,4,5,6,7
  
[0m21:20:27.464315 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:20:27.464518 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:20:27.464901 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:20:28.160686 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-3740-112b-ab63-ae83f8bd571e) - Created
[0m21:20:28.172630 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-3741-1e8f-a0f2-0b61c3994fc4) - Created
[0m21:20:28.184249 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-3742-153a-99dd-3941ab1fbc38) - Created
[0m21:20:28.459239 [debug] [Thread-1 (]: SQL status: OK in 1.000 seconds
[0m21:20:28.462962 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c4-3740-112b-ab63-ae83f8bd571e, command-id=01f089c4-375a-1820-bf1e-5692039da46c) - Closing
[0m21:20:28.464203 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: Close
[0m21:20:28.464657 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-3740-112b-ab63-ae83f8bd571e) - Closing
[0m21:20:28.475068 [debug] [Thread-3 (]: SQL status: OK in 1.010 seconds
[0m21:20:28.478107 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c4-3741-1e8f-a0f2-0b61c3994fc4, command-id=01f089c4-375c-136f-bf35-cd70016d7419) - Closing
[0m21:20:28.650063 [debug] [Thread-4 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
    
        create or replace table `flight_db`.`raw`.`gold_flight_metrics`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with f as (select * from `flight_db`.`raw`.`silver_flights`),
al as (select * from `flight_db`.`raw`.`silver_airlines`),
ap as (select * from `flight_db`.`raw`.`silver_airports`)

select
  f.flight_date,
  f.airline,
  al.airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.dest,
  d.airport_name as dest_airport_name,
  count(*)                          as flights,
  avg(coalesce(f.dep_delay, 0))      as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0))      as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from f
left join al on f.airline = al.airline
left join ap o on f.origin = o.iata
left join ap d on f.dest   = d.iata
group by 1,2,3,4,5,6,7
  
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `o`.`iata` cannot be resolved. Did you mean one of the following? [`o`.`city`, `o`.`state`, `o`.`iata_code`, `o`.`country`, `f`.`origin`]. SQLSTATE: 42703; line 35 pos 29
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `o`.`iata` cannot be resolved. Did you mean one of the following? [`o`.`city`, `o`.`state`, `o`.`iata_code`, `o`.`country`, `f`.`origin`]. SQLSTATE: 42703; line 35 pos 29
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `o`.`iata` cannot be resolved. Did you mean one of the following? [`o`.`city`, `o`.`state`, `o`.`iata_code`, `o`.`country`, `f`.`origin`]. SQLSTATE: 42703; line 35 pos 29
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c4-375e-19c6-a207-0db519dba44a
[0m21:20:28.652892 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: Close
[0m21:20:28.653288 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-3741-1e8f-a0f2-0b61c3994fc4) - Closing
[0m21:20:28.872631 [debug] [Thread-4 (]: On model.flights_dbt.gold_flight_metrics: Close
[0m21:20:28.873322 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-3742-153a-99dd-3941ab1fbc38) - Closing
[0m21:20:29.066352 [info ] [Thread-1 (]: 13 of 13 PASS unique_my_second_dbt_model_flight_id ............................. [[32mPASS[0m in 1.63s]
[0m21:20:29.067842 [info ] [Thread-3 (]: 12 of 13 PASS not_null_my_second_dbt_model_flight_id ........................... [[32mPASS[0m in 1.63s]
[0m21:20:29.070029 [debug] [Thread-1 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:20:29.071499 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:20:29.084383 [debug] [Thread-4 (]: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `o`.`iata` cannot be resolved. Did you mean one of the following? [`o`.`city`, `o`.`state`, `o`.`iata_code`, `o`.`country`, `f`.`origin`]. SQLSTATE: 42703; line 35 pos 29
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:20:29.084991 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28510e67-d9d5-4888-8552-02ce4a45730c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a3fc7d0>]}
[0m21:20:29.085672 [error] [Thread-4 (]: 11 of 13 ERROR creating sql table model raw.gold_flight_metrics ................ [[31mERROR[0m in 1.65s]
[0m21:20:29.086184 [debug] [Thread-4 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:20:29.086738 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'error'.  Reason: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `o`.`iata` cannot be resolved. Did you mean one of the following? [`o`.`city`, `o`.`state`, `o`.`iata_code`, `o`.`country`, `f`.`origin`]. SQLSTATE: 42703; line 35 pos 29
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql.
[0m21:20:29.088653 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:20:29.088958 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:20:29.089362 [info ] [MainThread]: 
[0m21:20:29.089616 [info ] [MainThread]: Finished running 2 table models, 4 data tests, 7 view models in 0 hours 0 minutes and 10.08 seconds (10.08s).
[0m21:20:29.091124 [debug] [MainThread]: Command end result
[0m21:20:29.114000 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:20:29.115474 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:20:29.119303 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:20:29.119444 [info ] [MainThread]: 
[0m21:20:29.119587 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:20:29.119702 [info ] [MainThread]: 
[0m21:20:29.119849 [error] [MainThread]: [31mFailure in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)[0m
[0m21:20:29.119997 [error] [MainThread]:   Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `o`.`iata` cannot be resolved. Did you mean one of the following? [`o`.`city`, `o`.`state`, `o`.`iata_code`, `o`.`country`, `f`.`origin`]. SQLSTATE: 42703; line 35 pos 29
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:20:29.120102 [info ] [MainThread]: 
[0m21:20:29.120224 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:20:29.120323 [info ] [MainThread]: 
[0m21:20:29.120452 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=13
[0m21:20:29.123170 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 11.162948, "process_in_blocks": "0", "process_kernel_time": 0.285032, "process_mem_max_rss": "248315904", "process_out_blocks": "0", "process_user_time": 3.18255}
[0m21:20:29.123358 [debug] [MainThread]: Command `dbt build` failed at 21:20:29.123320 after 11.16 seconds
[0m21:20:29.123523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c2a090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a3fc7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cd17c50>]}
[0m21:20:29.123655 [debug] [MainThread]: Flushing usage events
[0m21:20:29.888210 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:21:29.297230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108d3620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111dff890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111dffb10>]}


============================== 21:21:29.299564 | 73f7b9ef-9974-4dde-9919-6c8a2b9f7432 ==============================
[0m21:21:29.299564 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:21:29.299800 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'static_parser': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'version_check': 'True', 'printer_width': '80', 'quiet': 'False', 'empty': 'False', 'introspect': 'True', 'debug': 'False', 'profiles_dir': '/Users/artakerqeli/.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'partial_parse': 'True', 'log_format': 'default', 'write_json': 'True', 'invocation_command': 'dbt build', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'target_path': 'None', 'fail_fast': 'False'}
[0m21:21:29.600764 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:21:29.600974 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:21:29.601075 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:21:30.048721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e27360>]}
[0m21:21:30.068034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113e0aad0>]}
[0m21:21:30.068281 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:21:30.117037 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:21:30.175205 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:21:30.175454 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/gold/gold_flight_metrics.sql
[0m21:21:30.262509 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:21:30.267439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12400aa50>]}
[0m21:21:30.300992 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:21:30.301958 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:21:30.312396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124423e30>]}
[0m21:21:30.312573 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:21:30.313553 [info ] [MainThread]: 
[0m21:21:30.313677 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:21:30.313761 [info ] [MainThread]: 
[0m21:21:30.313960 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:21:30.314056 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:21:30.316712 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:21:30.316836 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:21:30.321203 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:21:30.321322 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:21:30.321410 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:21:31.073818 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c4-5cbf-15b6-b12a-11e2c77681f0) - Created
[0m21:21:31.690946 [debug] [ThreadPool]: SQL status: OK in 1.370 seconds
[0m21:21:31.700325 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c4-5cbf-15b6-b12a-11e2c77681f0, command-id=01f089c4-5ce0-1831-a870-652dc092fb97) - Closing
[0m21:21:31.701009 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:21:31.701296 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c4-5cbf-15b6-b12a-11e2c77681f0) - Closing
[0m21:21:31.930422 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:21:31.931040 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:21:31.939691 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:21:31.940103 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:21:31.940366 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:21:32.698267 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c4-5db7-1655-9409-9f651a3d6084) - Created
[0m21:21:33.325160 [debug] [ThreadPool]: SQL status: OK in 1.380 seconds
[0m21:21:33.329017 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c4-5db7-1655-9409-9f651a3d6084, command-id=01f089c4-5dd4-18e8-983d-d32b4a277621) - Closing
[0m21:21:33.330194 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:21:33.330504 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c4-5db7-1655-9409-9f651a3d6084) - Closing
[0m21:21:33.527810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1245ed1d0>]}
[0m21:21:33.532169 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_flights
[0m21:21:33.532630 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airports
[0m21:21:33.532912 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_airlines
[0m21:21:33.533135 [debug] [Thread-3 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:21:33.533558 [info ] [Thread-2 (]: 2 of 13 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:21:33.534020 [info ] [Thread-1 (]: 1 of 13 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:21:33.534427 [info ] [Thread-4 (]: 4 of 13 START sql view model raw.silver_airlines ............................... [RUN]
[0m21:21:33.534771 [info ] [Thread-3 (]: 3 of 13 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:21:33.535286 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:21:33.535652 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:21:33.535980 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airlines) - Creating connection
[0m21:21:33.536286 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:21:33.536517 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:21:33.536725 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:21:33.536925 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airlines'
[0m21:21:33.537128 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:21:33.537323 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:21:33.537505 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:21:33.537686 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_airlines
[0m21:21:33.537863 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:21:33.543750 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:21:33.545888 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_airlines"
[0m21:21:33.548783 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:21:33.549808 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:21:33.550737 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:21:33.550979 [debug] [Thread-3 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:21:33.551151 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:21:33.557239 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_airlines
[0m21:21:33.559630 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:21:33.560578 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:21:33.561620 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:21:33.562471 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:21:33.563473 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:21:33.563755 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:21:33.564044 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:21:33.564304 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:21:33.564510 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124695d90>]}
[0m21:21:33.564670 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124583a10>]}
[0m21:21:33.564814 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124500650>]}
[0m21:21:33.564959 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1245d5390>]}
[0m21:21:33.571833 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:21:33.571945 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:21:33.572349 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:21:33.572691 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_airlines`
[0m21:21:33.576801 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:21:33.577116 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:21:33.577398 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:21:33.577676 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_airlines"
[0m21:21:33.578060 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_airlines"
[0m21:21:33.578242 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:21:33.578388 [debug] [Thread-4 (]: On model.flights_dbt.silver_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airlines`
  
  as (
    select
    airline
from `flight_db`.`raw`.`bronze_airlines`
  )

[0m21:21:33.578513 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:21:33.578620 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:21:33.578752 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    -- models/bronze/bronze_flights.sql
select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m21:21:33.578895 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:21:33.579046 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    -- models/bronze/bronze_airports.sql
select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:21:33.579192 [debug] [Thread-3 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:21:33.579320 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:21:33.579509 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:21:33.579620 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:21:34.365157 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-5eb6-11bd-8785-5f7aef7a1476) - Created
[0m21:21:34.399301 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-5eba-1b2e-89c1-72addc9281c6) - Created
[0m21:21:34.400756 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-5ebb-1cbf-b89c-a806d7565888) - Created
[0m21:21:34.411860 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-5ebc-158a-bb72-856c48fad6f3) - Created
[0m21:21:35.050531 [debug] [Thread-3 (]: SQL status: OK in 1.470 seconds
[0m21:21:35.052615 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c4-5eb6-11bd-8785-5f7aef7a1476, command-id=01f089c4-5ecf-1eaf-a01e-92879779e49d) - Closing
[0m21:21:35.066320 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:21:35.069075 [debug] [Thread-3 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:21:35.069388 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-5eb6-11bd-8785-5f7aef7a1476) - Closing
[0m21:21:35.128703 [debug] [Thread-2 (]: SQL status: OK in 1.550 seconds
[0m21:21:35.130575 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c4-5eba-1b2e-89c1-72addc9281c6, command-id=01f089c4-5ed6-1a54-9fe8-93cea32b2b68) - Closing
[0m21:21:35.131675 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:21:35.210437 [debug] [Thread-1 (]: SQL status: OK in 1.630 seconds
[0m21:21:35.212046 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c4-5ebc-158a-bb72-856c48fad6f3, command-id=01f089c4-5ed8-1435-9b08-21f16544da31) - Closing
[0m21:21:35.213044 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:21:35.260014 [debug] [Thread-4 (]: SQL status: OK in 1.680 seconds
[0m21:21:35.262264 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c4-5ebb-1cbf-b89c-a806d7565888, command-id=01f089c4-5ed7-1375-9d6d-90a217160411) - Closing
[0m21:21:35.263942 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:21:35.264343 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: Close
[0m21:21:35.265275 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-5eba-1b2e-89c1-72addc9281c6) - Closing
[0m21:21:35.462443 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: Close
[0m21:21:35.463535 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-5ebc-158a-bb72-856c48fad6f3) - Closing
[0m21:21:35.675231 [debug] [Thread-4 (]: On model.flights_dbt.silver_airlines: Close
[0m21:21:35.676763 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-5ebb-1cbf-b89c-a806d7565888) - Closing
[0m21:21:35.678196 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110de9ed0>]}
[0m21:21:35.679123 [info ] [Thread-3 (]: 3 of 13 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.14s]
[0m21:21:35.679704 [debug] [Thread-3 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:21:35.680103 [debug] [Thread-3 (]: Began running node model.flights_dbt.silver_flights
[0m21:21:35.680670 [info ] [Thread-3 (]: 5 of 13 START sql view model raw.silver_flights ................................ [RUN]
[0m21:21:35.880423 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12469b0e0>]}
[0m21:21:35.881445 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125564280>]}
[0m21:21:35.882134 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:21:35.882668 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1246bdbb0>]}
[0m21:21:35.883466 [info ] [Thread-2 (]: 2 of 13 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.34s]
[0m21:21:35.884404 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:21:35.884021 [info ] [Thread-1 (]: 1 of 13 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.35s]
[0m21:21:35.885513 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:21:35.885055 [info ] [Thread-4 (]: 4 of 13 OK created sql view model raw.silver_airlines .......................... [[32mOK[0m in 2.35s]
[0m21:21:35.885917 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:21:35.886349 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:21:35.886728 [debug] [Thread-2 (]: Began running node model.flights_dbt.stg_airlines
[0m21:21:35.887266 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:21:35.889176 [debug] [Thread-1 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:21:35.890973 [info ] [Thread-2 (]: 6 of 13 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:21:35.892709 [debug] [Thread-4 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:21:35.894331 [info ] [Thread-1 (]: 7 of 13 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:21:35.901191 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:21:35.901733 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:21:35.902087 [info ] [Thread-4 (]: 8 of 13 START test unique_my_first_dbt_model_flight_id ......................... [RUN]
[0m21:21:35.902629 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:21:35.902906 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:21:35.903404 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:21:35.903727 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:21:35.904022 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:21:35.904261 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:21:35.904497 [debug] [Thread-3 (]: Began executing node model.flights_dbt.silver_flights
[0m21:21:35.904720 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:21:35.906794 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:21:35.907012 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:21:35.908615 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:21:35.916160 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:21:35.920109 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:21:35.920786 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:21:35.921068 [debug] [Thread-2 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:21:35.921514 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:21:35.927307 [debug] [Thread-1 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:21:35.930949 [debug] [Thread-2 (]: MATERIALIZING TABLE
[0m21:21:35.931155 [debug] [Thread-4 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:21:35.938853 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:21:35.951544 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:21:35.952696 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:21:35.953624 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:21:35.953808 [debug] [Thread-3 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:21:35.953988 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:21:35.954126 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:21:35.954320 [debug] [Thread-1 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:21:35.954458 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:21:35.954626 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:21:35.954732 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:21:35.954901 [debug] [Thread-2 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:21:35.955042 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:21:35.955211 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:21:35.955316 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:21:36.722370 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-601c-1049-80fc-36770ae8ea9a) - Created
[0m21:21:36.731713 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-601f-1322-9eb7-053774be48d0) - Created
[0m21:21:36.735467 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-601f-147c-a435-8be775c08775) - Created
[0m21:21:36.742781 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-601f-1cd2-a9b3-f1ba844b1b13) - Created
[0m21:21:37.217784 [debug] [Thread-1 (]: SQL status: OK in 1.260 seconds
[0m21:21:37.218440 [debug] [Thread-4 (]: SQL status: OK in 1.260 seconds
[0m21:21:37.223597 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c4-601f-1322-9eb7-053774be48d0, command-id=01f089c4-6039-1cde-adf6-2898492f4777) - Closing
[0m21:21:37.224934 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c4-601c-1049-80fc-36770ae8ea9a, command-id=01f089c4-6037-1481-a0f9-65f07ea6403d) - Closing
[0m21:21:37.227809 [debug] [Thread-1 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:21:37.228508 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-601f-1322-9eb7-053774be48d0) - Closing
[0m21:21:37.403079 [debug] [Thread-3 (]: SQL status: OK in 1.450 seconds
[0m21:21:37.405489 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c4-601f-147c-a435-8be775c08775, command-id=01f089c4-603a-18b1-a586-16f32fd05e2a) - Closing
[0m21:21:37.407168 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:21:37.448651 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:21:37.449653 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-601c-1049-80fc-36770ae8ea9a) - Closing
[0m21:21:37.647892 [debug] [Thread-3 (]: On model.flights_dbt.silver_flights: Close
[0m21:21:37.649001 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-601f-147c-a435-8be775c08775) - Closing
[0m21:21:37.856488 [info ] [Thread-1 (]: 7 of 13 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.95s]
[0m21:21:37.857978 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1246be630>]}
[0m21:21:37.857208 [info ] [Thread-4 (]: 8 of 13 PASS unique_my_first_dbt_model_flight_id ............................... [[32mPASS[0m in 1.95s]
[0m21:21:37.858701 [debug] [Thread-1 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:21:37.859999 [debug] [Thread-4 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:21:37.859520 [info ] [Thread-3 (]: 5 of 13 OK created sql view model raw.silver_flights ........................... [[32mOK[0m in 2.18s]
[0m21:21:37.860562 [debug] [Thread-1 (]: Began running node model.flights_dbt.silver_airports
[0m21:21:37.861306 [debug] [Thread-3 (]: Finished running node model.flights_dbt.silver_flights
[0m21:21:37.861641 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:21:37.862190 [info ] [Thread-1 (]: 9 of 13 START sql view model raw.silver_airports ............................... [RUN]
[0m21:21:37.862800 [info ] [Thread-4 (]: 10 of 13 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:21:37.863478 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:21:37.863972 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:21:37.864361 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:21:37.864672 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:21:37.865005 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:21:37.865409 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:21:37.870879 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:21:37.878690 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:21:37.879178 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:21:37.880899 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:21:37.881791 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:21:37.882040 [debug] [Thread-1 (]: Began executing node model.flights_dbt.silver_airports
[0m21:21:37.882614 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:21:37.888081 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:21:37.888920 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:21:37.889378 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:21:37.889683 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:21:37.889935 [debug] [Thread-4 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:21:37.890125 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:21:37.890269 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:21:37.890596 [debug] [Thread-1 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:21:37.890820 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:21:38.582228 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-6139-1c65-a70e-93a56c91df36) - Created
[0m21:21:38.597173 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-6139-1d3b-baee-929cbbb55b6c) - Created
[0m21:21:38.647650 [debug] [Thread-2 (]: SQL status: OK in 2.690 seconds
[0m21:21:38.649230 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c4-601f-1cd2-a9b3-f1ba844b1b13, command-id=01f089c4-603c-1461-9268-c6e98fe55362) - Closing
[0m21:21:38.654070 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:21:38.670237 [debug] [Thread-2 (]: On model.flights_dbt.stg_airlines: Close
[0m21:21:38.670563 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-601f-1cd2-a9b3-f1ba844b1b13) - Closing
[0m21:21:38.878471 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12450b650>]}
[0m21:21:38.879680 [info ] [Thread-2 (]: 6 of 13 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 2.98s]
[0m21:21:38.880354 [debug] [Thread-2 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:21:39.198231 [debug] [Thread-4 (]: SQL status: OK in 1.310 seconds
[0m21:21:39.199925 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c4-6139-1c65-a70e-93a56c91df36, command-id=01f089c4-6154-105e-b0b4-83f4d4f4d60a) - Closing
[0m21:21:39.201031 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:21:39.202203 [debug] [Thread-4 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:21:39.202625 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-6139-1c65-a70e-93a56c91df36) - Closing
[0m21:21:39.224145 [debug] [Thread-1 (]: SQL status: OK in 1.330 seconds
[0m21:21:39.225804 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c4-6139-1d3b-baee-929cbbb55b6c, command-id=01f089c4-6156-13bd-9e43-676403405392) - Closing
[0m21:21:39.226871 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:21:39.394644 [debug] [Thread-1 (]: On model.flights_dbt.silver_airports: Close
[0m21:21:39.395739 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-6139-1d3b-baee-929cbbb55b6c) - Closing
[0m21:21:39.600449 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1246bd610>]}
[0m21:21:39.601456 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1246bcad0>]}
[0m21:21:39.602576 [info ] [Thread-4 (]: 10 of 13 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.74s]
[0m21:21:39.603875 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:21:39.603330 [info ] [Thread-1 (]: 9 of 13 OK created sql view model raw.silver_airports .......................... [[32mOK[0m in 1.74s]
[0m21:21:39.604573 [debug] [Thread-1 (]: Finished running node model.flights_dbt.silver_airports
[0m21:21:39.605137 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:21:39.605512 [debug] [Thread-2 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:21:39.605824 [info ] [Thread-3 (]: 11 of 13 START test not_null_my_second_dbt_model_flight_id ..................... [RUN]
[0m21:21:39.606141 [debug] [Thread-4 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:21:39.606443 [info ] [Thread-2 (]: 12 of 13 START test unique_my_second_dbt_model_flight_id ....................... [RUN]
[0m21:21:39.607046 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d) - Creating connection
[0m21:21:39.607517 [info ] [Thread-4 (]: 13 of 13 START sql table model raw.gold_flight_metrics ......................... [RUN]
[0m21:21:39.607971 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580) - Creating connection
[0m21:21:39.608289 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d'
[0m21:21:39.608687 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.gold_flight_metrics) - Creating connection
[0m21:21:39.608990 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580'
[0m21:21:39.609285 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:21:39.609569 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.gold_flight_metrics'
[0m21:21:39.609845 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:21:39.611617 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.gold_flight_metrics
[0m21:21:39.625336 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:21:39.625771 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:21:39.628123 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.gold_flight_metrics"
[0m21:21:39.628846 [debug] [Thread-4 (]: Began executing node model.flights_dbt.gold_flight_metrics
[0m21:21:39.630782 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m21:21:39.631040 [debug] [Thread-2 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:21:39.631285 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:21:39.632492 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.gold_flight_metrics"
[0m21:21:39.634073 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:21:39.635720 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:21:39.636183 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.gold_flight_metrics"
[0m21:21:39.636448 [debug] [Thread-4 (]: On model.flights_dbt.gold_flight_metrics: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
    
        create or replace table `flight_db`.`raw`.`gold_flight_metrics`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with f as (select * from `flight_db`.`raw`.`silver_flights`),
al as (select * from `flight_db`.`raw`.`silver_airlines`),
ap as (select * from `flight_db`.`raw`.`silver_airports`)

select
  f.flight_date,
  f.airline,
  al.airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.dest,
  d.airport_name as dest_airport_name,
  count(*)                          as flights,
  avg(coalesce(f.dep_delay, 0))      as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0))      as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from f
left join al on f.airline = al.airline
left join ap o on f.origin = o.iata_code
left join ap d on f.dest   = d.iata
group by 1,2,3,4,5,6,7
  
[0m21:21:39.636640 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:21:39.636834 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:21:39.636966 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:21:39.637167 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:21:39.637513 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:21:39.637679 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:21:39.637894 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:21:40.349904 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-6244-1433-b326-2fed1444690b) - Created
[0m21:21:40.384030 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-6249-103d-84be-c0751d4d0b8f) - Created
[0m21:21:40.403785 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-624d-18a8-9946-4f226dad92ce) - Created
[0m21:21:40.751429 [debug] [Thread-3 (]: SQL status: OK in 1.110 seconds
[0m21:21:40.754718 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c4-6249-103d-84be-c0751d4d0b8f, command-id=01f089c4-6267-10d6-8747-c99871db620c) - Closing
[0m21:21:40.755694 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: Close
[0m21:21:40.756080 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-6249-103d-84be-c0751d4d0b8f) - Closing
[0m21:21:40.759117 [debug] [Thread-2 (]: SQL status: OK in 1.120 seconds
[0m21:21:40.761141 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c4-624d-18a8-9946-4f226dad92ce, command-id=01f089c4-6269-1fd8-9773-45406bdd1843) - Closing
[0m21:21:40.857811 [debug] [Thread-4 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
    
        create or replace table `flight_db`.`raw`.`gold_flight_metrics`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with f as (select * from `flight_db`.`raw`.`silver_flights`),
al as (select * from `flight_db`.`raw`.`silver_airlines`),
ap as (select * from `flight_db`.`raw`.`silver_airports`)

select
  f.flight_date,
  f.airline,
  al.airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.dest,
  d.airport_name as dest_airport_name,
  count(*)                          as flights,
  avg(coalesce(f.dep_delay, 0))      as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0))      as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from f
left join al on f.airline = al.airline
left join ap o on f.origin = o.iata_code
left join ap d on f.dest   = d.iata
group by 1,2,3,4,5,6,7
  
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c4-6261-1b0d-8dec-abcfe80139f5
[0m21:21:40.948723 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: Close
[0m21:21:40.949766 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-624d-18a8-9946-4f226dad92ce) - Closing
[0m21:21:41.184862 [debug] [Thread-4 (]: On model.flights_dbt.gold_flight_metrics: Close
[0m21:21:41.185591 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-6244-1433-b326-2fed1444690b) - Closing
[0m21:21:41.381439 [info ] [Thread-3 (]: 11 of 13 PASS not_null_my_second_dbt_model_flight_id ........................... [[32mPASS[0m in 1.77s]
[0m21:21:41.383418 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:21:41.382626 [info ] [Thread-2 (]: 12 of 13 PASS unique_my_second_dbt_model_flight_id ............................. [[32mPASS[0m in 1.77s]
[0m21:21:41.384909 [debug] [Thread-2 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:21:41.395916 [debug] [Thread-4 (]: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:21:41.396407 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73f7b9ef-9974-4dde-9919-6c8a2b9f7432', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1246be210>]}
[0m21:21:41.396908 [error] [Thread-4 (]: 13 of 13 ERROR creating sql table model raw.gold_flight_metrics ................ [[31mERROR[0m in 1.79s]
[0m21:21:41.397289 [debug] [Thread-4 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:21:41.397669 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'error'.  Reason: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql.
[0m21:21:41.399108 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:21:41.399320 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:21:41.399640 [info ] [MainThread]: 
[0m21:21:41.399843 [info ] [MainThread]: Finished running 2 table models, 4 data tests, 7 view models in 0 hours 0 minutes and 11.09 seconds (11.09s).
[0m21:21:41.401136 [debug] [MainThread]: Command end result
[0m21:21:41.421939 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:21:41.422968 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:21:41.426295 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:21:41.426431 [info ] [MainThread]: 
[0m21:21:41.426571 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:21:41.426675 [info ] [MainThread]: 
[0m21:21:41.426819 [error] [MainThread]: [31mFailure in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)[0m
[0m21:21:41.426953 [error] [MainThread]:   Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:21:41.427051 [info ] [MainThread]: 
[0m21:21:41.427166 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:21:41.427260 [info ] [MainThread]: 
[0m21:21:41.427372 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=13
[0m21:21:41.430216 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 12.16516, "process_in_blocks": "0", "process_kernel_time": 0.284038, "process_mem_max_rss": "244482048", "process_out_blocks": "0", "process_user_time": 3.242324}
[0m21:21:41.430411 [debug] [MainThread]: Command `dbt build` failed at 21:21:41.430374 after 12.17 seconds
[0m21:21:41.430570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d0fdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12573fd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12573fad0>]}
[0m21:21:41.430704 [debug] [MainThread]: Flushing usage events
[0m21:21:42.610001 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:22:52.994676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103beb620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066ff890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066ffb10>]}


============================== 21:22:52.997617 | ef014e3e-63b3-47d6-9125-7d29cd8d17b0 ==============================
[0m21:22:52.997617 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:22:52.997900 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'cache_selected_only': 'False', 'printer_width': '80', 'static_parser': 'True', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True', 'invocation_command': 'dbt build', 'warn_error': 'None', 'empty': 'False', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'introspect': 'True', 'profiles_dir': '/Users/artakerqeli/.dbt', 'no_print': 'None', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'log_cache_events': 'False', 'partial_parse': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'log_format': 'default'}
[0m21:22:53.305110 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:22:53.305310 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:22:53.305404 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:22:53.764556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040ef360>]}
[0m21:22:53.783775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11060aad0>]}
[0m21:22:53.784000 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:22:53.833241 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:22:53.892840 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:22:53.893106 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/gold/gold_flight_metrics.sql
[0m21:22:53.982384 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:22:53.987406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11710aa50>]}
[0m21:22:54.021231 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:22:54.022146 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:22:54.032857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117523e30>]}
[0m21:22:54.033039 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:22:54.034013 [info ] [MainThread]: 
[0m21:22:54.034151 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:22:54.034236 [info ] [MainThread]: 
[0m21:22:54.034426 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:22:54.034527 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:22:54.037061 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:22:54.037183 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:22:54.041462 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:22:54.041575 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:22:54.041662 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:22:54.798980 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c4-8ea5-1624-b6ec-9629cea78aa7) - Created
[0m21:22:55.163434 [debug] [ThreadPool]: SQL status: OK in 1.120 seconds
[0m21:22:55.171362 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c4-8ea5-1624-b6ec-9629cea78aa7, command-id=01f089c4-8ec2-1538-8114-70f5727b273d) - Closing
[0m21:22:55.171853 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:22:55.172073 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c4-8ea5-1624-b6ec-9629cea78aa7) - Closing
[0m21:22:55.372912 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:22:55.373515 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:22:55.382147 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:22:55.382608 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:22:55.382865 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:22:56.103259 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c4-8f6c-1816-b094-8c88e711a0ff) - Created
[0m21:22:56.691850 [debug] [ThreadPool]: SQL status: OK in 1.310 seconds
[0m21:22:56.696250 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c4-8f6c-1816-b094-8c88e711a0ff, command-id=01f089c4-8f8a-1155-8a3b-86dd6f5ca112) - Closing
[0m21:22:56.697187 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:22:56.697479 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c4-8f6c-1816-b094-8c88e711a0ff) - Closing
[0m21:22:56.896185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1177f51d0>]}
[0m21:22:56.900622 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_airlines
[0m21:22:56.901107 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_flights
[0m21:22:56.901479 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airports
[0m21:22:56.901764 [debug] [Thread-3 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:22:56.902196 [info ] [Thread-4 (]: 4 of 13 START sql view model raw.silver_airlines ............................... [RUN]
[0m21:22:56.902638 [info ] [Thread-2 (]: 2 of 13 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:22:56.903009 [info ] [Thread-1 (]: 1 of 13 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:22:56.903345 [info ] [Thread-3 (]: 3 of 13 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:22:56.903805 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airlines) - Creating connection
[0m21:22:56.904144 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:22:56.904456 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:22:56.904771 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:22:56.905009 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airlines'
[0m21:22:56.905226 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:22:56.905447 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:22:56.905650 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:22:56.905871 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_airlines
[0m21:22:56.906086 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:22:56.906289 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:22:56.906490 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:22:56.912603 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_airlines"
[0m21:22:56.915299 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:22:56.916443 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:22:56.919228 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:22:56.920186 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:22:56.920396 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_airlines
[0m21:22:56.920575 [debug] [Thread-3 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:22:56.920732 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:22:56.929308 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:22:56.930289 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:22:56.931360 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:22:56.932233 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:22:56.933286 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:22:56.933588 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:22:56.933839 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:22:56.934057 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:22:56.934251 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121096270>]}
[0m21:22:56.934396 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11777f290>]}
[0m21:22:56.934521 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x117704650>]}
[0m21:22:56.934642 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1177de0a0>]}
[0m21:22:56.941380 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_airlines`
[0m21:22:56.941946 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:22:56.942305 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:22:56.946178 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_airlines"
[0m21:22:56.946494 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:22:56.946791 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:22:56.947071 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:22:56.947400 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:22:56.948010 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_airlines"
[0m21:22:56.948159 [debug] [Thread-4 (]: On model.flights_dbt.silver_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airlines`
  
  as (
    select
    airline
from `flight_db`.`raw`.`bronze_airlines`
  )

[0m21:22:56.948272 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:22:56.948400 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:22:56.948493 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:22:56.948630 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    -- models/bronze/bronze_flights.sql
select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m21:22:56.948741 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:22:56.948954 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    -- models/bronze/bronze_airports.sql
select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:22:56.949071 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:22:56.949244 [debug] [Thread-3 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:22:56.949372 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:22:56.949551 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:22:57.723940 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-9062-1e69-b49d-5d331468a9ea) - Created
[0m21:22:57.727632 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-9065-1ddc-8bd4-5c50fb5832d4) - Created
[0m21:22:57.731510 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-9066-145c-8a70-c1d1ef13eba0) - Created
[0m21:22:57.736768 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-9066-17df-93c7-13cbbd43747e) - Created
[0m21:22:58.519458 [debug] [Thread-2 (]: SQL status: OK in 1.570 seconds
[0m21:22:58.524315 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c4-9062-1e69-b49d-5d331468a9ea, command-id=01f089c4-907f-17ac-8b65-8c9fe2529063) - Closing
[0m21:22:58.524773 [debug] [Thread-1 (]: SQL status: OK in 1.580 seconds
[0m21:22:58.532205 [debug] [Thread-3 (]: SQL status: OK in 1.580 seconds
[0m21:22:58.539335 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c4-9066-17df-93c7-13cbbd43747e, command-id=01f089c4-9082-1674-a7c4-cd064374de28) - Closing
[0m21:22:58.539698 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:22:58.540045 [debug] [Thread-4 (]: SQL status: OK in 1.590 seconds
[0m21:22:58.540676 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c4-9065-1ddc-8bd4-5c50fb5832d4, command-id=01f089c4-9081-10fd-a469-b0945b716c4b) - Closing
[0m21:22:58.541198 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:22:58.543536 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: Close
[0m21:22:58.544103 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c4-9066-145c-8a70-c1d1ef13eba0, command-id=01f089c4-9081-1a4a-8294-f637f213231b) - Closing
[0m21:22:58.544519 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:22:58.545038 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-9062-1e69-b49d-5d331468a9ea) - Closing
[0m21:22:58.545457 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:22:58.742545 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: Close
[0m21:22:58.743559 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-9066-17df-93c7-13cbbd43747e) - Closing
[0m21:22:58.969745 [debug] [Thread-3 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:22:58.970888 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-9065-1ddc-8bd4-5c50fb5832d4) - Closing
[0m21:22:59.167650 [debug] [Thread-4 (]: On model.flights_dbt.silver_airlines: Close
[0m21:22:59.169054 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-9066-145c-8a70-c1d1ef13eba0) - Closing
[0m21:22:59.385816 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040b1ed0>]}
[0m21:22:59.386434 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12158cc50>]}
[0m21:22:59.386738 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12109ba80>]}
[0m21:22:59.387120 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1210be690>]}
[0m21:22:59.387792 [info ] [Thread-1 (]: 1 of 13 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.48s]
[0m21:22:59.388358 [info ] [Thread-4 (]: 4 of 13 OK created sql view model raw.silver_airlines .......................... [[32mOK[0m in 2.48s]
[0m21:22:59.388994 [info ] [Thread-2 (]: 2 of 13 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.48s]
[0m21:22:59.389995 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:22:59.389508 [info ] [Thread-3 (]: 3 of 13 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.48s]
[0m21:22:59.390580 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:22:59.391003 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:22:59.391388 [debug] [Thread-1 (]: Began running node model.flights_dbt.silver_flights
[0m21:22:59.391989 [debug] [Thread-3 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:22:59.392439 [debug] [Thread-4 (]: Began running node model.flights_dbt.stg_airlines
[0m21:22:59.392808 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_airports
[0m21:22:59.393241 [info ] [Thread-1 (]: 5 of 13 START sql view model raw.silver_flights ................................ [RUN]
[0m21:22:59.394163 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:22:59.393852 [info ] [Thread-4 (]: 6 of 13 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:22:59.394580 [info ] [Thread-2 (]: 7 of 13 START sql view model raw.silver_airports ............................... [RUN]
[0m21:22:59.395193 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:22:59.395550 [info ] [Thread-3 (]: 8 of 13 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:22:59.395965 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:22:59.396337 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:22:59.396685 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:22:59.397068 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:22:59.397325 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:22:59.397567 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:22:59.397822 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:22:59.398066 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:22:59.398299 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:22:59.398506 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:22:59.400101 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:22:59.403757 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:22:59.406683 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:22:59.419152 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:22:59.421335 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:22:59.422176 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_airports
[0m21:22:59.422364 [debug] [Thread-4 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:22:59.422563 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:22:59.422751 [debug] [Thread-1 (]: Began executing node model.flights_dbt.silver_flights
[0m21:22:59.423940 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:22:59.433386 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m21:22:59.440963 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:22:59.441947 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:22:59.442414 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:22:59.455848 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:22:59.456218 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:22:59.456552 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:22:59.456898 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:22:59.457075 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:22:59.457239 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:22:59.457387 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:22:59.457489 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:22:59.457638 [debug] [Thread-4 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:22:59.457737 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:22:59.457851 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:22:59.457987 [debug] [Thread-2 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:22:59.458097 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:22:59.458212 [debug] [Thread-1 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:22:59.458390 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:22:59.458570 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:23:00.263351 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-91e6-1f9e-b17f-e5eb82b49731) - Created
[0m21:23:00.270949 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-91e8-1634-8db6-10897f234963) - Created
[0m21:23:00.404573 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-91fc-12bd-a4a9-636f1dabd1d3) - Created
[0m21:23:00.406533 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-91fc-177b-baa2-7380a8628070) - Created
[0m21:23:00.732293 [debug] [Thread-3 (]: SQL status: OK in 1.270 seconds
[0m21:23:00.737009 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c4-91fc-177b-baa2-7380a8628070, command-id=01f089c4-921a-133f-adf7-669f71442694) - Closing
[0m21:23:00.740053 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:23:00.740410 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-91fc-177b-baa2-7380a8628070) - Closing
[0m21:23:00.849909 [debug] [Thread-2 (]: SQL status: OK in 1.390 seconds
[0m21:23:00.852117 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c4-91e6-1f9e-b17f-e5eb82b49731, command-id=01f089c4-9202-1cde-bdf2-67f39b3001e3) - Closing
[0m21:23:00.852870 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:23:00.871329 [debug] [Thread-1 (]: SQL status: OK in 1.410 seconds
[0m21:23:00.872188 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c4-91e8-1634-8db6-10897f234963, command-id=01f089c4-9206-10b2-a7f7-67ac6ed1dde0) - Closing
[0m21:23:00.872733 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:23:00.936320 [debug] [Thread-2 (]: On model.flights_dbt.silver_airports: Close
[0m21:23:00.937395 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-91e6-1f9e-b17f-e5eb82b49731) - Closing
[0m21:23:01.122507 [debug] [Thread-1 (]: On model.flights_dbt.silver_flights: Close
[0m21:23:01.123619 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-91e8-1634-8db6-10897f234963) - Closing
[0m21:23:01.334532 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1210bd4f0>]}
[0m21:23:01.335375 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1215b0bf0>]}
[0m21:23:01.333503 [info ] [Thread-3 (]: 8 of 13 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.94s]
[0m21:23:01.336665 [info ] [Thread-2 (]: 7 of 13 OK created sql view model raw.silver_airports .......................... [[32mOK[0m in 1.94s]
[0m21:23:01.337368 [info ] [Thread-1 (]: 5 of 13 OK created sql view model raw.silver_flights ........................... [[32mOK[0m in 1.94s]
[0m21:23:01.338002 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:23:01.338480 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_airports
[0m21:23:01.338911 [debug] [Thread-1 (]: Finished running node model.flights_dbt.silver_flights
[0m21:23:01.339303 [debug] [Thread-3 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:23:01.339959 [info ] [Thread-3 (]: 9 of 13 START test unique_my_first_dbt_model_flight_id ......................... [RUN]
[0m21:23:01.340357 [debug] [Thread-2 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:23:01.341062 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:23:01.341573 [info ] [Thread-2 (]: 10 of 13 START sql table model raw.gold_flight_metrics ......................... [RUN]
[0m21:23:01.341937 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:23:01.342387 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.gold_flight_metrics) - Creating connection
[0m21:23:01.342712 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:23:01.343010 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.gold_flight_metrics'
[0m21:23:01.351145 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:23:01.351558 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.gold_flight_metrics
[0m21:23:01.356047 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.gold_flight_metrics"
[0m21:23:01.357474 [debug] [Thread-3 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:23:01.359479 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:23:01.359751 [debug] [Thread-2 (]: Began executing node model.flights_dbt.gold_flight_metrics
[0m21:23:01.361310 [debug] [Thread-2 (]: MATERIALIZING TABLE
[0m21:23:01.364408 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:23:01.365308 [debug] [Thread-3 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:23:01.366441 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:23:01.371409 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.gold_flight_metrics"
[0m21:23:01.372052 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.gold_flight_metrics"
[0m21:23:01.372310 [debug] [Thread-2 (]: On model.flights_dbt.gold_flight_metrics: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
    
        create or replace table `flight_db`.`raw`.`gold_flight_metrics`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with f as (select * from `flight_db`.`raw`.`silver_flights`),
al as (select * from `flight_db`.`raw`.`silver_airlines`),
ap as (select * from `flight_db`.`raw`.`silver_airports`)

select
  f.flight_date,
  f.airline,
  al.airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.destination,
  d.airport_name as dest_airport_name,
  count(*)                          as flights,
  avg(coalesce(f.dep_delay, 0))      as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0))      as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from f
left join al on f.airline = al.airline
left join ap o on f.origin = o.iata_code
left join ap d on f.dest   = d.iata
group by 1,2,3,4,5,6,7
  
[0m21:23:01.372516 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:23:02.032296 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-92f5-1444-9370-bca3a4b568ff) - Created
[0m21:23:02.147742 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-9306-1fe8-94d2-f1b8f2cc6dde) - Created
[0m21:23:02.378542 [debug] [Thread-4 (]: SQL status: OK in 2.920 seconds
[0m21:23:02.380212 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c4-91fc-12bd-a4a9-636f1dabd1d3, command-id=01f089c4-9219-1787-b35b-2f994bdc4c48) - Closing
[0m21:23:02.384642 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:23:02.396996 [debug] [Thread-4 (]: On model.flights_dbt.stg_airlines: Close
[0m21:23:02.397233 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-91fc-12bd-a4a9-636f1dabd1d3) - Closing
[0m21:23:02.513041 [debug] [Thread-3 (]: SQL status: OK in 1.150 seconds
[0m21:23:02.516235 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c4-9306-1fe8-94d2-f1b8f2cc6dde, command-id=01f089c4-9325-157e-8a10-1acefab8aa4e) - Closing
[0m21:23:02.593301 [debug] [Thread-2 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
    
        create or replace table `flight_db`.`raw`.`gold_flight_metrics`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with f as (select * from `flight_db`.`raw`.`silver_flights`),
al as (select * from `flight_db`.`raw`.`silver_airlines`),
ap as (select * from `flight_db`.`raw`.`silver_airports`)

select
  f.flight_date,
  f.airline,
  al.airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.destination,
  d.airport_name as dest_airport_name,
  count(*)                          as flights,
  avg(coalesce(f.dep_delay, 0))      as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0))      as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from f
left join al on f.airline = al.airline
left join ap o on f.origin = o.iata_code
left join ap d on f.dest   = d.iata
group by 1,2,3,4,5,6,7
  
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c4-9310-15a7-94a1-615427ffd448
[0m21:23:02.602751 [debug] [Thread-3 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:23:02.603322 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-9306-1fe8-94d2-f1b8f2cc6dde) - Closing
[0m21:23:02.816141 [debug] [Thread-2 (]: On model.flights_dbt.gold_flight_metrics: Close
[0m21:23:02.817248 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c4-92f5-1444-9370-bca3a4b568ff) - Closing
[0m21:23:03.017778 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1210bde50>]}
[0m21:23:03.018653 [info ] [Thread-3 (]: 9 of 13 PASS unique_my_first_dbt_model_flight_id ............................... [[32mPASS[0m in 1.68s]
[0m21:23:03.020189 [debug] [Thread-3 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:23:03.019662 [info ] [Thread-4 (]: 6 of 13 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.62s]
[0m21:23:03.021057 [debug] [Thread-4 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:23:03.021468 [debug] [Thread-1 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:23:03.021946 [info ] [Thread-1 (]: 11 of 13 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:23:03.022559 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:23:03.022889 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:23:03.023200 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:23:03.026655 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:23:03.027550 [debug] [Thread-1 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:23:03.031685 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:23:03.032690 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:23:03.033427 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:23:03.034067 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:23:03.034357 [debug] [Thread-1 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:23:03.034633 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:23:03.041777 [debug] [Thread-2 (]: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:23:03.042143 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1215b3ef0>]}
[0m21:23:03.042592 [error] [Thread-2 (]: 10 of 13 ERROR creating sql table model raw.gold_flight_metrics ................ [[31mERROR[0m in 1.70s]
[0m21:23:03.042937 [debug] [Thread-2 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:23:03.043257 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'error'.  Reason: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql.
[0m21:23:03.781652 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-9402-12d0-ae82-354c2eff16dc) - Created
[0m21:23:04.533119 [debug] [Thread-1 (]: SQL status: OK in 1.500 seconds
[0m21:23:04.534706 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c4-9402-12d0-ae82-354c2eff16dc, command-id=01f089c4-941c-1fde-9c67-c56da97b3af7) - Closing
[0m21:23:04.535319 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:23:04.535981 [debug] [Thread-1 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:23:04.536232 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c4-9402-12d0-ae82-354c2eff16dc) - Closing
[0m21:23:04.730971 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ef014e3e-63b3-47d6-9125-7d29cd8d17b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12155d910>]}
[0m21:23:04.732702 [info ] [Thread-1 (]: 11 of 13 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.71s]
[0m21:23:04.733512 [debug] [Thread-1 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:23:04.734543 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:23:04.734975 [debug] [Thread-4 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:23:04.735339 [info ] [Thread-3 (]: 12 of 13 START test not_null_my_second_dbt_model_flight_id ..................... [RUN]
[0m21:23:04.735743 [info ] [Thread-4 (]: 13 of 13 START test unique_my_second_dbt_model_flight_id ....................... [RUN]
[0m21:23:04.736380 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d) - Creating connection
[0m21:23:04.736816 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580) - Creating connection
[0m21:23:04.737140 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d'
[0m21:23:04.737419 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580'
[0m21:23:04.737711 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:23:04.737989 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:23:04.745793 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:23:04.751285 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:23:04.752919 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:23:04.753204 [debug] [Thread-4 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:23:04.755203 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:23:04.757330 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:23:04.757703 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:23:04.757954 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:23:04.758142 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:23:04.758364 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:23:04.758608 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:23:04.758960 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:23:05.441306 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-9500-10d0-bcd5-d81c38bfdbce) - Created
[0m21:23:05.473865 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-9502-1e78-9361-06b6e39460ce) - Created
[0m21:23:05.772373 [debug] [Thread-4 (]: SQL status: OK in 1.010 seconds
[0m21:23:05.775629 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c4-9500-10d0-bcd5-d81c38bfdbce, command-id=01f089c4-951a-1fd7-9164-61011792fd58) - Closing
[0m21:23:05.776573 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: Close
[0m21:23:05.776922 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c4-9500-10d0-bcd5-d81c38bfdbce) - Closing
[0m21:23:05.792285 [debug] [Thread-3 (]: SQL status: OK in 1.030 seconds
[0m21:23:05.795100 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c4-9502-1e78-9361-06b6e39460ce, command-id=01f089c4-9520-1185-a056-50a3d21bc479) - Closing
[0m21:23:05.980868 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: Close
[0m21:23:05.981986 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c4-9502-1e78-9361-06b6e39460ce) - Closing
[0m21:23:06.189356 [info ] [Thread-4 (]: 13 of 13 PASS unique_my_second_dbt_model_flight_id ............................. [[32mPASS[0m in 1.45s]
[0m21:23:06.190335 [info ] [Thread-3 (]: 12 of 13 PASS not_null_my_second_dbt_model_flight_id ........................... [[32mPASS[0m in 1.45s]
[0m21:23:06.191204 [debug] [Thread-4 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:23:06.191720 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:23:06.193639 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:23:06.194060 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:23:06.194641 [info ] [MainThread]: 
[0m21:23:06.194975 [info ] [MainThread]: Finished running 2 table models, 4 data tests, 7 view models in 0 hours 0 minutes and 12.16 seconds (12.16s).
[0m21:23:06.197106 [debug] [MainThread]: Command end result
[0m21:23:06.230377 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:23:06.231822 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:23:06.236235 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:23:06.236376 [info ] [MainThread]: 
[0m21:23:06.236534 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:23:06.236658 [info ] [MainThread]: 
[0m21:23:06.236813 [error] [MainThread]: [31mFailure in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)[0m
[0m21:23:06.236965 [error] [MainThread]:   Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:23:06.237078 [info ] [MainThread]: 
[0m21:23:06.237207 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:23:06.237318 [info ] [MainThread]: 
[0m21:23:06.237445 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=13
[0m21:23:06.240078 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 13.278224, "process_in_blocks": "0", "process_kernel_time": 0.286377, "process_mem_max_rss": "252018688", "process_out_blocks": "0", "process_user_time": 3.063685}
[0m21:23:06.240329 [debug] [MainThread]: Command `dbt build` failed at 21:23:06.240283 after 13.28 seconds
[0m21:23:06.240523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040181d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1210bd310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1222b24b0>]}
[0m21:23:06.240684 [debug] [MainThread]: Flushing usage events
[0m21:23:06.980707 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:27:56.369223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105acf620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cab890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cabb10>]}


============================== 21:27:56.371485 | 26d22b73-adf9-48fd-81a4-31730fb1eea6 ==============================
[0m21:27:56.371485 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:27:56.371708 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'debug': 'False', 'version_check': 'True', 'partial_parse': 'True', 'log_format': 'default', 'use_experimental_parser': 'False', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'static_parser': 'True', 'warn_error': 'None', 'write_json': 'True', 'invocation_command': 'dbt build', 'no_print': 'None', 'indirect_selection': 'eager', 'empty': 'False', 'use_colors': 'True', 'target_path': 'None', 'log_cache_events': 'False', 'profiles_dir': '/Users/artakerqeli/.dbt'}
[0m21:27:56.672475 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:27:56.672694 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:27:56.672806 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:27:57.124306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fd3360>]}
[0m21:27:57.143747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107eb6ad0>]}
[0m21:27:57.143985 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:27:57.192565 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:27:57.250916 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:27:57.251077 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:27:57.253974 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:27:57.268920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff0ee50>]}
[0m21:27:57.304624 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:27:57.305520 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:27:57.316274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1182b14f0>]}
[0m21:27:57.316494 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:27:57.317528 [info ] [MainThread]: 
[0m21:27:57.317668 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:27:57.317758 [info ] [MainThread]: 
[0m21:27:57.317965 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:27:57.318061 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:27:57.320669 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:27:57.320811 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:27:57.324997 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:27:57.325132 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:27:57.325230 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:27:58.069894 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c5-4368-1b05-92ee-81c0cbc91ef5) - Created
[0m21:27:58.672106 [debug] [ThreadPool]: SQL status: OK in 1.350 seconds
[0m21:27:58.681627 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c5-4368-1b05-92ee-81c0cbc91ef5, command-id=01f089c5-4383-1d71-9e36-ffa26301c171) - Closing
[0m21:27:58.682190 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:27:58.682421 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c5-4368-1b05-92ee-81c0cbc91ef5) - Closing
[0m21:27:58.906483 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:27:58.907107 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:27:58.920031 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:27:58.920770 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:27:58.921079 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:27:59.550819 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c5-444c-14eb-bbcc-81223d8a1b8c) - Created
[0m21:28:00.205252 [debug] [ThreadPool]: SQL status: OK in 1.280 seconds
[0m21:28:00.207870 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c5-444c-14eb-bbcc-81223d8a1b8c, command-id=01f089c5-446c-1cc7-9189-31af57c44d20) - Closing
[0m21:28:00.208658 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:28:00.208885 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c5-444c-14eb-bbcc-81223d8a1b8c) - Closing
[0m21:28:00.403987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118367d90>]}
[0m21:28:00.408758 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_airlines
[0m21:28:00.409303 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_flights
[0m21:28:00.409627 [debug] [Thread-3 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:28:00.409894 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airports
[0m21:28:00.410356 [info ] [Thread-4 (]: 4 of 13 START sql view model raw.silver_airlines ............................... [RUN]
[0m21:28:00.410777 [info ] [Thread-2 (]: 2 of 13 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:28:00.411183 [info ] [Thread-3 (]: 3 of 13 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:28:00.411504 [info ] [Thread-1 (]: 1 of 13 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:28:00.412096 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airlines) - Creating connection
[0m21:28:00.412444 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:28:00.412754 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:28:00.413057 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:28:00.413287 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airlines'
[0m21:28:00.413506 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:28:00.413710 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:28:00.413924 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:28:00.414146 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_airlines
[0m21:28:00.414350 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:28:00.414550 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:28:00.414747 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:28:00.421424 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_airlines"
[0m21:28:00.423222 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:28:00.426157 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:28:00.427815 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:28:00.428925 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_airlines
[0m21:28:00.429172 [debug] [Thread-3 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:28:00.435460 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:28:00.435617 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:28:00.438018 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:28:00.438959 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:28:00.439978 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:28:00.440888 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:28:00.441953 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:28:00.442291 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:28:00.442570 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:28:00.442788 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:28:00.442980 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11841f040>]}
[0m21:28:00.443122 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11830e090>]}
[0m21:28:00.443249 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11830fb90>]}
[0m21:28:00.443372 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11837d9c0>]}
[0m21:28:00.451162 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:28:00.451504 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:28:00.451924 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_airlines`
[0m21:28:00.452303 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:28:00.456109 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:28:00.456426 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:28:00.456712 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_airlines"
[0m21:28:00.456991 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:28:00.457791 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:28:00.457921 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_airlines"
[0m21:28:00.458094 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    -- models/bronze/bronze_airports.sql
select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:28:00.458207 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:28:00.458305 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:28:00.458444 [debug] [Thread-4 (]: On model.flights_dbt.silver_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airlines`
  
  as (
    select
    airline
from `flight_db`.`raw`.`bronze_airlines`
  )

[0m21:28:00.458581 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:28:00.458721 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    -- models/bronze/bronze_flights.sql
select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m21:28:00.458879 [debug] [Thread-3 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:28:00.459020 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:28:00.459211 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:28:00.459322 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:28:01.213796 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-4544-19ca-ad87-60c4b641b834) - Created
[0m21:28:01.216695 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-4544-1b1d-8b20-af122c38d23b) - Created
[0m21:28:01.218099 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-4549-19fe-beab-ffcc937e9b38) - Created
[0m21:28:01.218986 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-4549-17a3-a470-8edf936d56e3) - Created
[0m21:28:02.135598 [debug] [Thread-3 (]: SQL status: OK in 1.680 seconds
[0m21:28:02.137778 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c5-4544-1b1d-8b20-af122c38d23b, command-id=01f089c5-4567-1afe-a08c-9c648064133c) - Closing
[0m21:28:02.152146 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:28:02.155020 [debug] [Thread-3 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:28:02.155364 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-4544-1b1d-8b20-af122c38d23b) - Closing
[0m21:28:02.162574 [debug] [Thread-2 (]: SQL status: OK in 1.700 seconds
[0m21:28:02.162910 [debug] [Thread-1 (]: SQL status: OK in 1.700 seconds
[0m21:28:02.163712 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c5-4549-17a3-a470-8edf936d56e3, command-id=01f089c5-456a-1052-a213-665f5d7417fe) - Closing
[0m21:28:02.163972 [debug] [Thread-4 (]: SQL status: OK in 1.700 seconds
[0m21:28:02.164594 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c5-4544-19ca-ad87-60c4b641b834, command-id=01f089c5-4564-10c3-810e-638bdeca4d33) - Closing
[0m21:28:02.165105 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:28:02.165623 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c5-4549-19fe-beab-ffcc937e9b38, command-id=01f089c5-456a-19d6-a1d4-670aedc5d5d1) - Closing
[0m21:28:02.166012 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:28:02.166706 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:28:02.355089 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: Close
[0m21:28:02.356123 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-4549-17a3-a470-8edf936d56e3) - Closing
[0m21:28:02.550976 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: Close
[0m21:28:02.551981 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-4544-19ca-ad87-60c4b641b834) - Closing
[0m21:28:02.751094 [debug] [Thread-4 (]: On model.flights_dbt.silver_airlines: Close
[0m21:28:02.752161 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-4549-19fe-beab-ffcc937e9b38) - Closing
[0m21:28:02.954196 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f95ed0>]}
[0m21:28:02.954787 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1184ffa50>]}
[0m21:28:02.955092 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1184ab150>]}
[0m21:28:02.955485 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118353710>]}
[0m21:28:02.956167 [info ] [Thread-2 (]: 2 of 13 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.54s]
[0m21:28:02.956852 [info ] [Thread-4 (]: 4 of 13 OK created sql view model raw.silver_airlines .......................... [[32mOK[0m in 2.54s]
[0m21:28:02.957464 [info ] [Thread-3 (]: 3 of 13 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.54s]
[0m21:28:02.957963 [info ] [Thread-1 (]: 1 of 13 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.54s]
[0m21:28:02.958683 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:28:02.959201 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:28:02.959637 [debug] [Thread-3 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:28:02.960079 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:28:02.960477 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_flights
[0m21:28:02.960909 [debug] [Thread-4 (]: Began running node model.flights_dbt.stg_airlines
[0m21:28:02.961589 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:28:02.961876 [debug] [Thread-1 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:28:02.962250 [info ] [Thread-2 (]: 5 of 13 START sql view model raw.silver_flights ................................ [RUN]
[0m21:28:02.962624 [info ] [Thread-4 (]: 6 of 13 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:28:02.962989 [info ] [Thread-3 (]: 7 of 13 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:28:02.963330 [info ] [Thread-1 (]: 8 of 13 START test unique_my_first_dbt_model_flight_id ......................... [RUN]
[0m21:28:02.964115 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:28:02.964563 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:28:02.965776 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:28:02.967306 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:28:02.968592 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:28:02.969722 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:28:02.974029 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:28:02.974312 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:28:02.974547 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:28:02.974759 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:28:02.974952 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:28:02.976467 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:28:02.978341 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:28:02.988154 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:28:02.988350 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:28:02.992966 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:28:02.993293 [debug] [Thread-4 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:28:02.993484 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:28:02.993658 [debug] [Thread-1 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:28:02.993795 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_flights
[0m21:28:03.002439 [debug] [Thread-4 (]: MATERIALIZING TABLE
[0m21:28:03.009783 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:28:03.010784 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:28:03.011708 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:28:03.025153 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:28:03.025577 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:28:03.025935 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:28:03.026107 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:28:03.026215 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:28:03.026344 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:28:03.026456 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:28:03.026611 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:28:03.026735 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:28:03.026830 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:28:03.026955 [debug] [Thread-4 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:28:03.027073 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:28:03.027265 [debug] [Thread-2 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:28:03.027405 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:28:03.027571 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:28:03.755043 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-46cd-1e17-b879-a97c324cb40a) - Created
[0m21:28:03.788841 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-46cf-1e37-8b17-a383407e7145) - Created
[0m21:28:03.806283 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-46d5-1ba6-a1a6-2db10bed780f) - Created
[0m21:28:03.869658 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-46dd-1beb-b06c-b110ade28742) - Created
[0m21:28:04.089141 [debug] [Thread-3 (]: SQL status: OK in 1.060 seconds
[0m21:28:04.094123 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c5-46cd-1e17-b879-a97c324cb40a, command-id=01f089c5-46e8-1c59-b67a-b7f6135168f4) - Closing
[0m21:28:04.097390 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:28:04.097816 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-46cd-1e17-b879-a97c324cb40a) - Closing
[0m21:28:04.118492 [debug] [Thread-1 (]: SQL status: OK in 1.090 seconds
[0m21:28:04.121463 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c5-46d5-1ba6-a1a6-2db10bed780f, command-id=01f089c5-46f0-1757-85e3-469f3a0d152f) - Closing
[0m21:28:04.288134 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:28:04.289230 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-46d5-1ba6-a1a6-2db10bed780f) - Closing
[0m21:28:04.480177 [debug] [Thread-2 (]: SQL status: OK in 1.450 seconds
[0m21:28:04.481351 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c5-46dd-1beb-b06c-b110ade28742, command-id=01f089c5-46fb-13d2-8061-f9f9e6af488b) - Closing
[0m21:28:04.482063 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:28:04.484493 [debug] [Thread-2 (]: On model.flights_dbt.silver_flights: Close
[0m21:28:04.484239 [info ] [Thread-3 (]: 7 of 13 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.52s]
[0m21:28:04.484898 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-46dd-1beb-b06c-b110ade28742) - Closing
[0m21:28:04.485321 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:28:04.485959 [debug] [Thread-3 (]: Began running node model.flights_dbt.silver_airports
[0m21:28:04.486435 [info ] [Thread-3 (]: 9 of 13 START sql view model raw.silver_airports ............................... [RUN]
[0m21:28:04.698135 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:28:04.699107 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a3079b0>]}
[0m21:28:04.697240 [info ] [Thread-1 (]: 8 of 13 PASS unique_my_first_dbt_model_flight_id ............................... [[32mPASS[0m in 1.73s]
[0m21:28:04.699899 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:28:04.701414 [debug] [Thread-1 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:28:04.700889 [info ] [Thread-2 (]: 5 of 13 OK created sql view model raw.silver_flights ........................... [[32mOK[0m in 1.74s]
[0m21:28:04.701857 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:28:04.702556 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_flights
[0m21:28:04.702896 [debug] [Thread-1 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:28:04.706037 [info ] [Thread-1 (]: 10 of 13 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:28:04.714345 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:28:04.715915 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:28:04.716201 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:28:04.716605 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:28:04.719395 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:28:04.719907 [debug] [Thread-3 (]: Began executing node model.flights_dbt.silver_airports
[0m21:28:04.720142 [debug] [Thread-1 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:28:04.722136 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:28:04.723594 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:28:04.724407 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:28:04.725047 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:28:04.725583 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:28:04.726047 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:28:04.726407 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:28:04.726651 [debug] [Thread-3 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:28:04.726858 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:28:04.727206 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:28:04.727431 [debug] [Thread-1 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:28:04.727626 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:28:05.385620 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-47c6-1015-81af-391f25f07099) - Created
[0m21:28:05.439897 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-47cf-1039-9ed3-ac328bd19daa) - Created
[0m21:28:05.936176 [debug] [Thread-4 (]: SQL status: OK in 2.910 seconds
[0m21:28:05.937751 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c5-46cf-1e37-8b17-a383407e7145, command-id=01f089c5-46ee-1f13-a93a-77d94cdc91e1) - Closing
[0m21:28:05.942481 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:28:05.958204 [debug] [Thread-4 (]: On model.flights_dbt.stg_airlines: Close
[0m21:28:05.958529 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-46cf-1e37-8b17-a383407e7145) - Closing
[0m21:28:06.072446 [debug] [Thread-3 (]: SQL status: OK in 1.350 seconds
[0m21:28:06.074072 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c5-47c6-1015-81af-391f25f07099, command-id=01f089c5-47df-1e28-968c-572e7ac94912) - Closing
[0m21:28:06.075016 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:28:06.120419 [debug] [Thread-1 (]: SQL status: OK in 1.390 seconds
[0m21:28:06.122942 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c5-47cf-1039-9ed3-ac328bd19daa, command-id=01f089c5-47ea-1049-aefe-3201c72bcd4b) - Closing
[0m21:28:06.124510 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:28:06.150553 [debug] [Thread-3 (]: On model.flights_dbt.silver_airports: Close
[0m21:28:06.151397 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-47c6-1015-81af-391f25f07099) - Closing
[0m21:28:06.348069 [debug] [Thread-1 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:28:06.349148 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-47cf-1039-9ed3-ac328bd19daa) - Closing
[0m21:28:06.575138 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a304cb0>]}
[0m21:28:06.576159 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a307710>]}
[0m21:28:06.576808 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a304950>]}
[0m21:28:06.577768 [info ] [Thread-4 (]: 6 of 13 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.61s]
[0m21:28:06.578430 [info ] [Thread-3 (]: 9 of 13 OK created sql view model raw.silver_airports .......................... [[32mOK[0m in 2.09s]
[0m21:28:06.579685 [debug] [Thread-4 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:28:06.579200 [info ] [Thread-1 (]: 10 of 13 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.86s]
[0m21:28:06.580179 [debug] [Thread-3 (]: Finished running node model.flights_dbt.silver_airports
[0m21:28:06.580753 [debug] [Thread-1 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:28:06.581436 [debug] [Thread-2 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:28:06.581785 [debug] [Thread-4 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:28:06.582059 [debug] [Thread-3 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:28:06.582442 [info ] [Thread-2 (]: 11 of 13 START sql table model raw.gold_flight_metrics ......................... [RUN]
[0m21:28:06.582794 [info ] [Thread-4 (]: 12 of 13 START test not_null_my_second_dbt_model_flight_id ..................... [RUN]
[0m21:28:06.583111 [info ] [Thread-3 (]: 13 of 13 START test unique_my_second_dbt_model_flight_id ....................... [RUN]
[0m21:28:06.583714 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.gold_flight_metrics) - Creating connection
[0m21:28:06.584188 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d) - Creating connection
[0m21:28:06.584578 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580) - Creating connection
[0m21:28:06.584899 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.gold_flight_metrics'
[0m21:28:06.585179 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d'
[0m21:28:06.585444 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580'
[0m21:28:06.585754 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.gold_flight_metrics
[0m21:28:06.586048 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:28:06.586308 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:28:06.590893 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.gold_flight_metrics"
[0m21:28:06.595717 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:28:06.599036 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:28:06.599685 [debug] [Thread-2 (]: Began executing node model.flights_dbt.gold_flight_metrics
[0m21:28:06.601443 [debug] [Thread-2 (]: MATERIALIZING TABLE
[0m21:28:06.602725 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.gold_flight_metrics"
[0m21:28:06.603058 [debug] [Thread-4 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:28:06.603292 [debug] [Thread-3 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:28:06.604950 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:28:06.606649 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:28:06.606836 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.gold_flight_metrics"
[0m21:28:06.607177 [debug] [Thread-2 (]: On model.flights_dbt.gold_flight_metrics: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
    
        create or replace table `flight_db`.`raw`.`gold_flight_metrics`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with f as (select * from `flight_db`.`raw`.`silver_flights`),
al as (select * from `flight_db`.`raw`.`silver_airlines`),
ap as (select * from `flight_db`.`raw`.`silver_airports`)

select
  f.flight_date,
  f.airline,
  al.airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.destination,
  d.airport_name as dest_airport_name,
  count(*)                          as flights,
  avg(coalesce(f.dep_delay, 0))      as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0))      as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from f
left join al on f.airline = al.airline
left join ap o on f.origin = o.iata_code
left join ap d on f.dest   = d.iata
group by 1,2,3,4,5,6,7
  
[0m21:28:06.607388 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:28:06.607716 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:28:06.607877 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:28:06.608128 [debug] [Thread-4 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:28:06.608354 [debug] [Thread-3 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:28:06.608537 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:28:06.608697 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:28:07.284747 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-48e9-17d4-809c-3d3a79208f16) - Created
[0m21:28:07.333507 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-48f0-1e6a-a35e-b94335a42ecd) - Created
[0m21:28:07.344911 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-48f1-10d2-ae51-6db88a42a8f4) - Created
[0m21:28:07.575715 [debug] [Thread-4 (]: SQL status: OK in 0.970 seconds
[0m21:28:07.578689 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c5-48e9-17d4-809c-3d3a79208f16, command-id=01f089c5-4902-117a-98a2-aaf911e71927) - Closing
[0m21:28:07.579533 [debug] [Thread-4 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: Close
[0m21:28:07.579800 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-48e9-17d4-809c-3d3a79208f16) - Closing
[0m21:28:07.689728 [debug] [Thread-3 (]: SQL status: OK in 1.080 seconds
[0m21:28:07.692889 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c5-48f1-10d2-ae51-6db88a42a8f4, command-id=01f089c5-490c-1b0d-89af-ec8356d96a76) - Closing
[0m21:28:07.761351 [debug] [Thread-3 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: Close
[0m21:28:07.762424 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-48f1-10d2-ae51-6db88a42a8f4) - Closing
[0m21:28:07.901774 [debug] [Thread-2 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
    
        create or replace table `flight_db`.`raw`.`gold_flight_metrics`
      
      
  using delta
      
      
      
      
      
      
      
      as
      with f as (select * from `flight_db`.`raw`.`silver_flights`),
al as (select * from `flight_db`.`raw`.`silver_airlines`),
ap as (select * from `flight_db`.`raw`.`silver_airports`)

select
  f.flight_date,
  f.airline,
  al.airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.destination,
  d.airport_name as dest_airport_name,
  count(*)                          as flights,
  avg(coalesce(f.dep_delay, 0))      as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0))      as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from f
left join al on f.airline = al.airline
left join ap o on f.origin = o.iata_code
left join ap d on f.dest   = d.iata
group by 1,2,3,4,5,6,7
  
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c5-490b-16c1-b9c9-71b105949787
[0m21:28:07.976096 [debug] [Thread-2 (]: On model.flights_dbt.gold_flight_metrics: Close
[0m21:28:07.975394 [info ] [Thread-4 (]: 12 of 13 PASS not_null_my_second_dbt_model_flight_id ........................... [[32mPASS[0m in 1.39s]
[0m21:28:07.976761 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-48f0-1e6a-a35e-b94335a42ecd) - Closing
[0m21:28:07.977394 [debug] [Thread-4 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:28:08.181846 [info ] [Thread-3 (]: 13 of 13 PASS unique_my_second_dbt_model_flight_id ............................. [[32mPASS[0m in 1.60s]
[0m21:28:08.183306 [debug] [Thread-3 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:28:08.194165 [debug] [Thread-2 (]: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:28:08.194769 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '26d22b73-adf9-48fd-81a4-31730fb1eea6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a7182f0>]}
[0m21:28:08.195479 [error] [Thread-2 (]: 11 of 13 ERROR creating sql table model raw.gold_flight_metrics ................ [[31mERROR[0m in 1.61s]
[0m21:28:08.196013 [debug] [Thread-2 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:28:08.196584 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'error'.  Reason: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql.
[0m21:28:08.198797 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:28:08.199170 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:28:08.199583 [info ] [MainThread]: 
[0m21:28:08.199831 [info ] [MainThread]: Finished running 2 table models, 4 data tests, 7 view models in 0 hours 0 minutes and 10.88 seconds (10.88s).
[0m21:28:08.201388 [debug] [MainThread]: Command end result
[0m21:28:08.230193 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:28:08.231242 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:28:08.234325 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:28:08.234451 [info ] [MainThread]: 
[0m21:28:08.234585 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:28:08.234690 [info ] [MainThread]: 
[0m21:28:08.234829 [error] [MainThread]: [31mFailure in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)[0m
[0m21:28:08.234955 [error] [MainThread]:   Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`dest` cannot be resolved. Did you mean one of the following? [`o`.`city`, `d`.`city`, `o`.`state`, `d`.`state`, `f`.`origin`]. SQLSTATE: 42703; line 36 pos 18
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:28:08.235054 [info ] [MainThread]: 
[0m21:28:08.235167 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:28:08.235259 [info ] [MainThread]: 
[0m21:28:08.235370 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=13
[0m21:28:08.238193 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 11.900409, "process_in_blocks": "0", "process_kernel_time": 0.280647, "process_mem_max_rss": "241844224", "process_out_blocks": "0", "process_user_time": 3.084103}
[0m21:28:08.238381 [debug] [MainThread]: Command `dbt build` failed at 21:28:08.238342 after 11.90 seconds
[0m21:28:08.238547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10667d190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a78fef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a78fa10>]}
[0m21:28:08.238684 [debug] [MainThread]: Flushing usage events
[0m21:28:09.109217 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:29:53.612222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047e3620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dff890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dffb10>]}


============================== 21:29:53.614497 | 921a7433-02f6-461e-9190-ac3c64d01d6a ==============================
[0m21:29:53.614497 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:29:53.614710 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'target_path': 'None', 'printer_width': '80', 'use_colors': 'True', 'profiles_dir': '/Users/artakerqeli/.dbt', 'fail_fast': 'False', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'no_print': 'None', 'write_json': 'True', 'empty': 'False', 'cache_selected_only': 'False', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'partial_parse': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'quiet': 'False'}
[0m21:29:53.919847 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:29:53.920050 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:29:53.920147 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:29:54.375019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d23360>]}
[0m21:29:54.394216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d0aad0>]}
[0m21:29:54.394454 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:29:54.444641 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:29:54.503440 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:29:54.503687 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/gold/gold_flight_metrics.sql
[0m21:29:54.590238 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:29:54.595038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f20aa50>]}
[0m21:29:54.628675 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:29:54.629592 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:29:54.640252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f523c50>]}
[0m21:29:54.640426 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:29:54.641388 [info ] [MainThread]: 
[0m21:29:54.641516 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:29:54.641599 [info ] [MainThread]: 
[0m21:29:54.641784 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:29:54.641875 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:29:54.644411 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:29:54.644522 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:29:54.648821 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:29:54.648933 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:29:54.649026 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:29:55.392765 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c5-894c-12af-a977-9528ff5b9db9) - Created
[0m21:29:55.729853 [debug] [ThreadPool]: SQL status: OK in 1.080 seconds
[0m21:29:55.738280 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c5-894c-12af-a977-9528ff5b9db9, command-id=01f089c5-8969-10af-abf8-b5828124204f) - Closing
[0m21:29:55.738753 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:29:55.738948 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c5-894c-12af-a977-9528ff5b9db9) - Closing
[0m21:29:55.948002 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:29:55.948998 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:29:55.965516 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:29:55.966081 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:29:55.966316 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:29:56.614500 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c5-8a07-1011-a4ba-dcc288dd0529) - Created
[0m21:29:57.164970 [debug] [ThreadPool]: SQL status: OK in 1.200 seconds
[0m21:29:57.168652 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c5-8a07-1011-a4ba-dcc288dd0529, command-id=01f089c5-8a32-1485-8614-91d27b24e569) - Closing
[0m21:29:57.169821 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:29:57.170169 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c5-8a07-1011-a4ba-dcc288dd0529) - Closing
[0m21:29:57.363686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f6ea5f0>]}
[0m21:29:57.368361 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_flights
[0m21:29:57.368746 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airports
[0m21:29:57.369012 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:29:57.369422 [debug] [Thread-3 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:29:57.369970 [info ] [Thread-2 (]: 2 of 13 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:29:57.370439 [info ] [Thread-1 (]: 1 of 13 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:29:57.370997 [info ] [Thread-4 (]: 4 of 13 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:29:57.371539 [info ] [Thread-3 (]: 3 of 13 START sql view model raw.gold_flight_metrics ........................... [RUN]
[0m21:29:57.372084 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:29:57.372485 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:29:57.372800 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:29:57.373102 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.gold_flight_metrics) - Creating connection
[0m21:29:57.373330 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:29:57.373543 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:29:57.373747 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:29:57.373954 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.gold_flight_metrics'
[0m21:29:57.374170 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:29:57.374386 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:29:57.374586 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:29:57.374786 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.gold_flight_metrics
[0m21:29:57.381301 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:29:57.383101 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:29:57.386061 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:29:57.387199 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.gold_flight_metrics"
[0m21:29:57.388173 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:29:57.388395 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:29:57.396901 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:29:57.397057 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:29:57.397975 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:29:57.398108 [debug] [Thread-3 (]: Began executing node model.flights_dbt.gold_flight_metrics
[0m21:29:57.399164 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:29:57.400266 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:29:57.400506 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:29:57.401570 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:29:57.401769 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f796680>]}
[0m21:29:57.401985 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:29:57.402198 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f6a8a10>]}
[0m21:29:57.402461 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:29:57.409021 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f6d6a40>]}
[0m21:29:57.409607 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:29:57.410011 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:29:57.410155 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1286802d0>]}
[0m21:29:57.410501 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:29:57.414406 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:29:57.414724 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:29:57.415054 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`gold_flight_metrics`
[0m21:29:57.415325 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:29:57.415706 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.gold_flight_metrics"
[0m21:29:57.415920 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:29:57.416047 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:29:57.416202 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:29:57.416387 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    -- models/bronze/bronze_flights.sql
select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m21:29:57.416515 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:29:57.416657 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:29:57.416761 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.gold_flight_metrics"
[0m21:29:57.416885 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:29:57.417026 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    -- models/bronze/bronze_airports.sql
select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:29:57.417270 [debug] [Thread-3 (]: On model.flights_dbt.gold_flight_metrics: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
  
  create or replace view `flight_db`.`raw`.`gold_flight_metrics`
  
  as (
    -- models/gold/gold_flight_metrics.sql

select
  f.flight_date,
  f.airline,
  al.name as airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.destination,
  d.airport_name as destination_airport_name,
  count(*) as flights,
  avg(coalesce(f.dep_delay, 0)) as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0)) as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from raw.silver_flights f
left join raw.silver_airlines al on f.airline = al.airline
left join raw.silver_airports o on f.origin = o.iata_code
left join raw.silver_airports d on f.destination = d.iata_code
group by 1,2,3,4,5,6,7
  )

[0m21:29:57.417511 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:29:57.417649 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:29:58.146001 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-8aed-15bb-aef8-dc058c4075f7) - Created
[0m21:29:58.185662 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-8af8-14a6-8a5d-0a5c720a979e) - Created
[0m21:29:58.188716 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-8af7-19b6-a89a-2574ed60f12f) - Created
[0m21:29:58.199003 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-8afa-18cc-a814-269e706ccf33) - Created
[0m21:29:58.848923 [debug] [Thread-3 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
  
  create or replace view `flight_db`.`raw`.`gold_flight_metrics`
  
  as (
    -- models/gold/gold_flight_metrics.sql

select
  f.flight_date,
  f.airline,
  al.name as airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.destination,
  d.airport_name as destination_airport_name,
  count(*) as flights,
  avg(coalesce(f.dep_delay, 0)) as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0)) as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from raw.silver_flights f
left join raw.silver_airlines al on f.airline = al.airline
left join raw.silver_airports o on f.origin = o.iata_code
left join raw.silver_airports d on f.destination = d.iata_code
group by 1,2,3,4,5,6,7
  )

: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`flight_date` cannot be resolved. Did you mean one of the following? [`f`.`flight_id`, `o`.`state`, `d`.`state`, `f`.`airline`, `f`.`arr_delay`]. SQLSTATE: 42703; line 11 pos 2
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`flight_date` cannot be resolved. Did you mean one of the following? [`f`.`flight_id`, `o`.`state`, `d`.`state`, `f`.`airline`, `f`.`arr_delay`]. SQLSTATE: 42703; line 11 pos 2
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`flight_date` cannot be resolved. Did you mean one of the following? [`f`.`flight_id`, `o`.`state`, `d`.`state`, `f`.`airline`, `f`.`arr_delay`]. SQLSTATE: 42703; line 11 pos 2
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c5-8b14-1b03-81e5-9eca604f0c86
[0m21:29:58.851887 [debug] [Thread-3 (]: On model.flights_dbt.gold_flight_metrics: Close
[0m21:29:58.853667 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-8afa-18cc-a814-269e706ccf33) - Closing
[0m21:29:58.854166 [debug] [Thread-2 (]: SQL status: OK in 1.440 seconds
[0m21:29:58.854534 [debug] [Thread-4 (]: SQL status: OK in 1.440 seconds
[0m21:29:58.855883 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c5-8af8-14a6-8a5d-0a5c720a979e, command-id=01f089c5-8b13-1593-9725-422800a395b5) - Closing
[0m21:29:58.856707 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c5-8aed-15bb-aef8-dc058c4075f7, command-id=01f089c5-8b0b-13eb-9fe8-6f3d33411048) - Closing
[0m21:29:58.866321 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:29:58.867746 [debug] [Thread-1 (]: SQL status: OK in 1.450 seconds
[0m21:29:58.868203 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:29:58.871118 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c5-8af7-19b6-a89a-2574ed60f12f, command-id=01f089c5-8b13-168d-ac25-24b12177f9ac) - Closing
[0m21:29:58.871776 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:29:59.049827 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: Close
[0m21:29:59.050517 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-8af8-14a6-8a5d-0a5c720a979e) - Closing
[0m21:29:59.062501 [debug] [Thread-3 (]: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`flight_date` cannot be resolved. Did you mean one of the following? [`f`.`flight_id`, `o`.`state`, `d`.`state`, `f`.`airline`, `f`.`arr_delay`]. SQLSTATE: 42703; line 11 pos 2
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:29:59.252365 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:29:59.253440 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-8aed-15bb-aef8-dc058c4075f7) - Closing
[0m21:29:59.458205 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: Close
[0m21:29:59.458893 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-8af7-19b6-a89a-2574ed60f12f) - Closing
[0m21:29:59.670125 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1286695d0>]}
[0m21:29:59.670678 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b139dd0>]}
[0m21:29:59.670985 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11eca3150>]}
[0m21:29:59.671394 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b10e210>]}
[0m21:29:59.672133 [error] [Thread-3 (]: 3 of 13 ERROR creating sql view model raw.gold_flight_metrics .................. [[31mERROR[0m in 2.29s]
[0m21:29:59.672675 [info ] [Thread-4 (]: 4 of 13 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.30s]
[0m21:29:59.673400 [info ] [Thread-2 (]: 2 of 13 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.29s]
[0m21:29:59.673863 [info ] [Thread-1 (]: 1 of 13 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.30s]
[0m21:29:59.674486 [debug] [Thread-3 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:29:59.674941 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:29:59.675313 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:29:59.675661 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:29:59.676013 [debug] [Thread-3 (]: Began running node model.flights_dbt.silver_airlines
[0m21:29:59.676423 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'error'.  Reason: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`flight_date` cannot be resolved. Did you mean one of the following? [`f`.`flight_id`, `o`.`state`, `d`.`state`, `f`.`airline`, `f`.`arr_delay`]. SQLSTATE: 42703; line 11 pos 2
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql.
[0m21:29:59.676737 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_flights
[0m21:29:59.677024 [debug] [Thread-2 (]: Began running node model.flights_dbt.stg_airlines
[0m21:29:59.677431 [info ] [Thread-3 (]: 5 of 13 START sql view model raw.silver_airlines ............................... [RUN]
[0m21:29:59.679045 [debug] [Thread-1 (]: Began running node model.flights_dbt.silver_airports
[0m21:29:59.678714 [info ] [Thread-4 (]: 6 of 13 START sql view model raw.silver_flights ................................ [RUN]
[0m21:29:59.679441 [info ] [Thread-2 (]: 7 of 13 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:29:59.680028 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airlines) - Creating connection
[0m21:29:59.680392 [info ] [Thread-1 (]: 8 of 13 START sql view model raw.silver_airports ............................... [RUN]
[0m21:29:59.680901 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:29:59.681337 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:29:59.681615 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airlines'
[0m21:29:59.681990 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:29:59.682260 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:29:59.682501 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:29:59.682780 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.silver_airlines
[0m21:29:59.683033 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:29:59.683289 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:29:59.683530 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:29:59.684617 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:29:59.687085 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:29:59.689797 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:29:59.694394 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.silver_airlines"
[0m21:29:59.696597 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:29:59.697153 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_flights
[0m21:29:59.698284 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:29:59.698900 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:29:59.699336 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:29:59.699520 [debug] [Thread-1 (]: Began executing node model.flights_dbt.silver_airports
[0m21:29:59.699731 [debug] [Thread-3 (]: Began executing node model.flights_dbt.silver_airlines
[0m21:29:59.700822 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:29:59.701032 [debug] [Thread-2 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:29:59.702316 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:29:59.702896 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:29:59.703080 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:29:59.712584 [debug] [Thread-2 (]: MATERIALIZING TABLE
[0m21:29:59.713025 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`silver_airlines`
[0m21:29:59.713365 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:29:59.713532 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:29:59.720149 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.silver_airlines"
[0m21:29:59.728191 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:29:59.728360 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:29:59.728680 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:29:59.728791 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:29:59.728981 [debug] [Thread-1 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:29:59.729089 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.silver_airlines"
[0m21:29:59.729234 [debug] [Thread-2 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:29:59.729354 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:29:59.729481 [debug] [Thread-3 (]: On model.flights_dbt.silver_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airlines`
  
  as (
    select
    airline
from `flight_db`.`raw`.`bronze_airlines`
  )

[0m21:29:59.729598 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:29:59.729760 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:30:00.384971 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-8c46-1ba4-8cb8-ef7ed04aca76) - Created
[0m21:30:00.480252 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-8c54-105d-bab8-93e4251e27a5) - Created
[0m21:30:00.483329 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-8c54-1901-85ef-d504a7e623d2) - Created
[0m21:30:00.489378 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-8c57-1929-b9fc-214e791a5ffa) - Created
[0m21:30:00.956537 [debug] [Thread-4 (]: SQL status: OK in 1.230 seconds
[0m21:30:00.958284 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c5-8c46-1ba4-8cb8-ef7ed04aca76, command-id=01f089c5-8c61-14be-83bb-6c6d6cd1a74b) - Closing
[0m21:30:00.959247 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:30:00.960251 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: Close
[0m21:30:00.960588 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-8c46-1ba4-8cb8-ef7ed04aca76) - Closing
[0m21:30:01.140455 [debug] [Thread-1 (]: SQL status: OK in 1.410 seconds
[0m21:30:01.142770 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c5-8c54-1901-85ef-d504a7e623d2, command-id=01f089c5-8c72-18c9-a09f-5f5571d7b13f) - Closing
[0m21:30:01.143703 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:30:01.146439 [debug] [Thread-3 (]: SQL status: OK in 1.420 seconds
[0m21:30:01.147355 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c5-8c57-1929-b9fc-214e791a5ffa, command-id=01f089c5-8c73-1122-8115-76d38ba25f7a) - Closing
[0m21:30:01.147979 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:30:01.151815 [debug] [Thread-1 (]: On model.flights_dbt.silver_airports: Close
[0m21:30:01.152157 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-8c54-1901-85ef-d504a7e623d2) - Closing
[0m21:30:01.346784 [debug] [Thread-3 (]: On model.flights_dbt.silver_airlines: Close
[0m21:30:01.347824 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-8c57-1929-b9fc-214e791a5ffa) - Closing
[0m21:30:01.548041 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f7b9370>]}
[0m21:30:01.548808 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f7ba870>]}
[0m21:30:01.549447 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f7ba210>]}
[0m21:30:01.550207 [info ] [Thread-4 (]: 6 of 13 OK created sql view model raw.silver_flights ........................... [[32mOK[0m in 1.87s]
[0m21:30:01.550804 [info ] [Thread-1 (]: 8 of 13 OK created sql view model raw.silver_airports .......................... [[32mOK[0m in 1.87s]
[0m21:30:01.552056 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_flights
[0m21:30:01.551558 [info ] [Thread-3 (]: 5 of 13 OK created sql view model raw.silver_airlines .......................... [[32mOK[0m in 1.87s]
[0m21:30:01.552659 [debug] [Thread-1 (]: Finished running node model.flights_dbt.silver_airports
[0m21:30:01.553128 [debug] [Thread-4 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:30:01.553764 [debug] [Thread-3 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:30:01.554184 [debug] [Thread-1 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:30:01.554565 [info ] [Thread-4 (]: 9 of 13 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:30:01.555007 [info ] [Thread-1 (]: 10 of 13 START test unique_my_first_dbt_model_flight_id ........................ [RUN]
[0m21:30:01.555713 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:30:01.556304 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:30:01.556692 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:30:01.556991 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:30:01.557310 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:30:01.557699 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:30:01.572364 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:30:01.577935 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:30:01.578912 [debug] [Thread-4 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:30:01.586703 [debug] [Thread-1 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:30:01.590219 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:30:01.599125 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:30:01.599300 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:30:01.599521 [debug] [Thread-4 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:30:01.599683 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:30:01.599949 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:30:01.600167 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:30:01.600311 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:30:02.212635 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-8d5f-12f6-9402-be1e52de567a) - Created
[0m21:30:02.252868 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-8d64-16e8-97b6-36b52b8f4fcf) - Created
[0m21:30:02.484692 [debug] [Thread-2 (]: SQL status: OK in 2.750 seconds
[0m21:30:02.486385 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c5-8c54-105d-bab8-93e4251e27a5, command-id=01f089c5-8c72-190c-b5c4-6ef480b20d01) - Closing
[0m21:30:02.491141 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:30:02.507111 [debug] [Thread-2 (]: On model.flights_dbt.stg_airlines: Close
[0m21:30:02.507435 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-8c54-105d-bab8-93e4251e27a5) - Closing
[0m21:30:02.515331 [debug] [Thread-1 (]: SQL status: OK in 0.910 seconds
[0m21:30:02.519673 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c5-8d5f-12f6-9402-be1e52de567a, command-id=01f089c5-8d77-1eb2-bed5-1dc4be59dccd) - Closing
[0m21:30:02.563182 [debug] [Thread-4 (]: SQL status: OK in 0.960 seconds
[0m21:30:02.564972 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c5-8d64-16e8-97b6-36b52b8f4fcf, command-id=01f089c5-8d7f-17a7-80b9-1d9122f339c3) - Closing
[0m21:30:02.712933 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:30:02.713922 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-8d5f-12f6-9402-be1e52de567a) - Closing
[0m21:30:02.899512 [debug] [Thread-4 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:30:02.900608 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-8d64-16e8-97b6-36b52b8f4fcf) - Closing
[0m21:30:03.111365 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f606e10>]}
[0m21:30:03.112181 [info ] [Thread-1 (]: 10 of 13 PASS unique_my_first_dbt_model_flight_id .............................. [[32mPASS[0m in 1.56s]
[0m21:30:03.112584 [info ] [Thread-4 (]: 9 of 13 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.56s]
[0m21:30:03.114077 [debug] [Thread-1 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:30:03.113488 [info ] [Thread-2 (]: 7 of 13 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.43s]
[0m21:30:03.114610 [debug] [Thread-4 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:30:03.115245 [debug] [Thread-2 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:30:03.115866 [debug] [Thread-3 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:30:03.116371 [info ] [Thread-3 (]: 11 of 13 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:30:03.117068 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:30:03.117632 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:30:03.117995 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:30:03.127413 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:30:03.128332 [debug] [Thread-3 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:30:03.130010 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:30:03.130820 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:30:03.131383 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:30:03.132013 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:30:03.132292 [debug] [Thread-3 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:30:03.132507 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:30:03.815908 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-8e53-14a3-960b-8b394d2dddb2) - Created
[0m21:30:04.487967 [debug] [Thread-3 (]: SQL status: OK in 1.360 seconds
[0m21:30:04.490170 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c5-8e53-14a3-960b-8b394d2dddb2, command-id=01f089c5-8e6e-18df-a8ca-63eab5c7930c) - Closing
[0m21:30:04.490863 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:30:04.491615 [debug] [Thread-3 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:30:04.491871 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-8e53-14a3-960b-8b394d2dddb2) - Closing
[0m21:30:04.698877 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '921a7433-02f6-461e-9190-ac3c64d01d6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1286f9790>]}
[0m21:30:04.700578 [info ] [Thread-3 (]: 11 of 13 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.58s]
[0m21:30:04.701366 [debug] [Thread-3 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:30:04.702559 [debug] [Thread-1 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:30:04.702938 [debug] [Thread-4 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:30:04.703272 [info ] [Thread-1 (]: 12 of 13 START test not_null_my_second_dbt_model_flight_id ..................... [RUN]
[0m21:30:04.703695 [info ] [Thread-4 (]: 13 of 13 START test unique_my_second_dbt_model_flight_id ....................... [RUN]
[0m21:30:04.704414 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d) - Creating connection
[0m21:30:04.704899 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580) - Creating connection
[0m21:30:04.705221 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d'
[0m21:30:04.705492 [debug] [Thread-4 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580'
[0m21:30:04.705807 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:30:04.706081 [debug] [Thread-4 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:30:04.713312 [debug] [Thread-4 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:30:04.719913 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:30:04.721407 [debug] [Thread-1 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:30:04.721655 [debug] [Thread-4 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:30:04.723529 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:30:04.725759 [debug] [Thread-4 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:30:04.726346 [debug] [Thread-4 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:30:04.726651 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:30:04.726938 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:30:04.727121 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:30:04.727508 [debug] [Thread-1 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:30:04.727789 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:30:05.432731 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-8f48-1e8b-8d6e-ac80f010a12c) - Created
[0m21:30:05.434747 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-8f49-17b3-a8b0-5a7d32e26c42) - Created
[0m21:30:05.758426 [debug] [Thread-4 (]: SQL status: OK in 1.030 seconds
[0m21:30:05.759086 [debug] [Thread-1 (]: SQL status: OK in 1.030 seconds
[0m21:30:05.762298 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c5-8f48-1e8b-8d6e-ac80f010a12c, command-id=01f089c5-8f66-13f7-b5f7-bef2f4c4ec4b) - Closing
[0m21:30:05.763262 [debug] [Thread-4 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: Close
[0m21:30:05.764800 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c5-8f49-17b3-a8b0-5a7d32e26c42, command-id=01f089c5-8f67-11ae-8122-d77492f07fd2) - Closing
[0m21:30:05.765133 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-8f48-1e8b-8d6e-ac80f010a12c) - Closing
[0m21:30:05.958951 [debug] [Thread-1 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: Close
[0m21:30:05.959962 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-8f49-17b3-a8b0-5a7d32e26c42) - Closing
[0m21:30:06.164001 [info ] [Thread-4 (]: 13 of 13 PASS unique_my_second_dbt_model_flight_id ............................. [[32mPASS[0m in 1.46s]
[0m21:30:06.165001 [info ] [Thread-1 (]: 12 of 13 PASS not_null_my_second_dbt_model_flight_id ........................... [[32mPASS[0m in 1.46s]
[0m21:30:06.166085 [debug] [Thread-4 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:30:06.166570 [debug] [Thread-1 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:30:06.168513 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:30:06.168936 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:30:06.169471 [info ] [MainThread]: 
[0m21:30:06.169793 [info ] [MainThread]: Finished running 1 table model, 4 data tests, 8 view models in 0 hours 0 minutes and 11.53 seconds (11.53s).
[0m21:30:06.172159 [debug] [MainThread]: Command end result
[0m21:30:06.205970 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:30:06.207501 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:30:06.211358 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:30:06.211508 [info ] [MainThread]: 
[0m21:30:06.211688 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:30:06.211826 [info ] [MainThread]: 
[0m21:30:06.211994 [error] [MainThread]: [31mFailure in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)[0m
[0m21:30:06.212163 [error] [MainThread]:   Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `f`.`flight_date` cannot be resolved. Did you mean one of the following? [`f`.`flight_id`, `o`.`state`, `d`.`state`, `f`.`airline`, `f`.`arr_delay`]. SQLSTATE: 42703; line 11 pos 2
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:30:06.212276 [info ] [MainThread]: 
[0m21:30:06.212411 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:30:06.212520 [info ] [MainThread]: 
[0m21:30:06.212660 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=13
[0m21:30:06.215564 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 12.633406, "process_in_blocks": "0", "process_kernel_time": 0.291845, "process_mem_max_rss": "245841920", "process_out_blocks": "0", "process_user_time": 2.882504}
[0m21:30:06.215786 [debug] [MainThread]: Command `dbt build` failed at 21:30:06.215743 after 12.63 seconds
[0m21:30:06.216003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104772870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b146b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12b147e30>]}
[0m21:30:06.216221 [debug] [MainThread]: Flushing usage events
[0m21:30:07.028129 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:31:57.254898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10668b620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107867890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107867b10>]}


============================== 21:31:57.257254 | c4de3b00-eb64-4797-aaa5-1a1add9b4191 ==============================
[0m21:31:57.257254 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:31:57.257477 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'printer_width': '80', 'use_colors': 'True', 'debug': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'version_check': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt build', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'write_json': 'True', 'profiles_dir': '/Users/artakerqeli/.dbt', 'no_print': 'None', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'cache_selected_only': 'False', 'quiet': 'False', 'warn_error': 'None', 'log_format': 'default', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'empty': 'False'}
[0m21:31:57.570744 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:31:57.570934 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:31:57.571038 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:31:58.026309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b93360>]}
[0m21:31:58.045585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a6ead0>]}
[0m21:31:58.045821 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:31:58.101791 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:31:58.160437 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:31:58.160698 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/gold/gold_flight_metrics.sql
[0m21:31:58.248978 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:31:58.253820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5ea850>]}
[0m21:31:58.287711 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:31:58.288850 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:31:58.299725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8ffc50>]}
[0m21:31:58.299901 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:31:58.300877 [info ] [MainThread]: 
[0m21:31:58.300997 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:31:58.301082 [info ] [MainThread]: 
[0m21:31:58.301271 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:31:58.301362 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:31:58.303925 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:31:58.304046 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:31:58.308298 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:31:58.308413 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:31:58.308501 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:31:59.034930 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c5-d300-1198-9bec-d8bdb62d1a9c) - Created
[0m21:31:59.487770 [debug] [ThreadPool]: SQL status: OK in 1.180 seconds
[0m21:31:59.494858 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c5-d300-1198-9bec-d8bdb62d1a9c, command-id=01f089c5-d31e-103e-9f32-c8f8825bc169) - Closing
[0m21:31:59.495321 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:31:59.495523 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c5-d300-1198-9bec-d8bdb62d1a9c) - Closing
[0m21:31:59.691079 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:31:59.691634 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:31:59.704162 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:31:59.704517 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:31:59.704726 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:32:00.379540 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c5-d3ca-1f6e-a78a-fa436b640bb8) - Created
[0m21:32:00.911314 [debug] [ThreadPool]: SQL status: OK in 1.210 seconds
[0m21:32:00.915827 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c5-d3ca-1f6e-a78a-fa436b640bb8, command-id=01f089c5-d3e7-1c30-9ed0-4d4dae30c6da) - Closing
[0m21:32:00.916947 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:32:00.917364 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c5-d3ca-1f6e-a78a-fa436b640bb8) - Closing
[0m21:32:01.142624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ead25f0>]}
[0m21:32:01.147958 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:32:01.148451 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_flights
[0m21:32:01.148820 [debug] [Thread-3 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:32:01.149159 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airports
[0m21:32:01.149883 [info ] [Thread-4 (]: 4 of 13 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:32:01.150376 [info ] [Thread-2 (]: 2 of 13 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:32:01.150833 [info ] [Thread-3 (]: 3 of 13 START sql view model raw.gold_flight_metrics ........................... [RUN]
[0m21:32:01.151232 [info ] [Thread-1 (]: 1 of 13 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:32:01.151869 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:32:01.152359 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:32:01.152741 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.gold_flight_metrics) - Creating connection
[0m21:32:01.153093 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:32:01.153378 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:32:01.153623 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:32:01.153860 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.gold_flight_metrics'
[0m21:32:01.154141 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:32:01.154471 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:32:01.154734 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:32:01.154990 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.gold_flight_metrics
[0m21:32:01.155270 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:32:01.162400 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:32:01.164807 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.gold_flight_metrics"
[0m21:32:01.167195 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:32:01.172028 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:32:01.173135 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:32:01.173364 [debug] [Thread-3 (]: Began executing node model.flights_dbt.gold_flight_metrics
[0m21:32:01.173648 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:32:01.180198 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:32:01.183661 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:32:01.184749 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:32:01.185824 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:32:01.186682 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:32:01.188007 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:32:01.188317 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:32:01.188570 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:32:01.188806 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:32:01.189010 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb71d90>]}
[0m21:32:01.189159 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9e0dd0>]}
[0m21:32:01.189297 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9e01d0>]}
[0m21:32:01.189425 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eab6830>]}
[0m21:32:01.196468 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:32:01.197020 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`gold_flight_metrics`
[0m21:32:01.197445 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:32:01.197794 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:32:01.201799 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:32:01.202139 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.gold_flight_metrics"
[0m21:32:01.202439 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:32:01.202730 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:32:01.203433 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:32:01.203558 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:32:01.203735 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    -- models/bronze/bronze_flights.sql
select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m21:32:01.203850 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:32:01.203975 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.gold_flight_metrics"
[0m21:32:01.204143 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    -- models/bronze/bronze_airports.sql
select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:32:01.204306 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:32:01.204469 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:32:01.204642 [debug] [Thread-3 (]: On model.flights_dbt.gold_flight_metrics: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
  
  create or replace view `flight_db`.`raw`.`gold_flight_metrics`
  
  as (
    -- models/gold/gold_flight_metrics.sql

select
  f.flight_id,
  f.airline,
  al.name as airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.destination,
  d.airport_name as destination_airport_name,
  count(*) over () as flights,
  avg(coalesce(f.dep_delay, 0)) over () as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0)) over () as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) over () as on_time_rate
from raw.silver_flights f
left join raw.silver_airlines al on f.airline = al.airline
left join raw.silver_airports o on f.origin = o.iata_code
left join raw.silver_airports d on f.destination = d.iata_code
  )

[0m21:32:01.204774 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:32:01.204973 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:32:01.205087 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:32:01.957371 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-d4bd-1a25-bdb2-0cf775406c78) - Created
[0m21:32:01.961674 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-d4bb-1e1c-a85b-4af01c301904) - Created
[0m21:32:01.981649 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-d4c0-16d7-821d-319c1c50ed1e) - Created
[0m21:32:01.985560 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-d4c1-1e4f-a977-a02e010e6940) - Created
[0m21:32:02.552837 [debug] [Thread-3 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
  
  create or replace view `flight_db`.`raw`.`gold_flight_metrics`
  
  as (
    -- models/gold/gold_flight_metrics.sql

select
  f.flight_id,
  f.airline,
  al.name as airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.destination,
  d.airport_name as destination_airport_name,
  count(*) over () as flights,
  avg(coalesce(f.dep_delay, 0)) over () as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0)) over () as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) over () as on_time_rate
from raw.silver_flights f
left join raw.silver_airlines al on f.airline = al.airline
left join raw.silver_airports o on f.origin = o.iata_code
left join raw.silver_airports d on f.destination = d.iata_code
  )

: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`name` cannot be resolved. Did you mean one of the following? [`o`.`state`, `d`.`state`, `al`.`airline`, `o`.`city`, `d`.`city`]. SQLSTATE: 42703; line 13 pos 2
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`name` cannot be resolved. Did you mean one of the following? [`o`.`state`, `d`.`state`, `al`.`airline`, `o`.`city`, `d`.`city`]. SQLSTATE: 42703; line 13 pos 2
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`name` cannot be resolved. Did you mean one of the following? [`o`.`state`, `d`.`state`, `al`.`airline`, `o`.`city`, `d`.`city`]. SQLSTATE: 42703; line 13 pos 2
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c5-d4d8-1d86-8791-ceb710fa8da4
[0m21:32:02.555915 [debug] [Thread-3 (]: On model.flights_dbt.gold_flight_metrics: Close
[0m21:32:02.556382 [debug] [Thread-1 (]: SQL status: OK in 1.350 seconds
[0m21:32:02.556711 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-d4bb-1e1c-a85b-4af01c301904) - Closing
[0m21:32:02.557841 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c5-d4bd-1a25-bdb2-0cf775406c78, command-id=01f089c5-d4da-1139-8011-c6b16c9cf1b5) - Closing
[0m21:32:02.569131 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:32:02.590030 [debug] [Thread-2 (]: SQL status: OK in 1.390 seconds
[0m21:32:02.590940 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c5-d4c0-16d7-821d-319c1c50ed1e, command-id=01f089c5-d4dc-1dd4-acd5-6ba687fbdb6f) - Closing
[0m21:32:02.591483 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:32:02.602102 [debug] [Thread-4 (]: SQL status: OK in 1.400 seconds
[0m21:32:02.602771 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c5-d4c1-1e4f-a977-a02e010e6940, command-id=01f089c5-d4dc-1d65-a770-40e2e63470a4) - Closing
[0m21:32:02.603242 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:32:02.797136 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: Close
[0m21:32:02.797827 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-d4bd-1a25-bdb2-0cf775406c78) - Closing
[0m21:32:02.809310 [debug] [Thread-3 (]: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`name` cannot be resolved. Did you mean one of the following? [`o`.`state`, `d`.`state`, `al`.`airline`, `o`.`city`, `d`.`city`]. SQLSTATE: 42703; line 13 pos 2
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:32:02.994020 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: Close
[0m21:32:02.995216 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-d4c0-16d7-821d-319c1c50ed1e) - Closing
[0m21:32:03.210523 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:32:03.211445 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-d4c1-1e4f-a977-a02e010e6940) - Closing
[0m21:32:03.414499 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110868650>]}
[0m21:32:03.415070 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d35d50>]}
[0m21:32:03.415374 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e27f1c0>]}
[0m21:32:03.415789 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108e42f0>]}
[0m21:32:03.416533 [error] [Thread-3 (]: 3 of 13 ERROR creating sql view model raw.gold_flight_metrics .................. [[31mERROR[0m in 2.26s]
[0m21:32:03.417086 [info ] [Thread-2 (]: 2 of 13 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.26s]
[0m21:32:03.417776 [info ] [Thread-1 (]: 1 of 13 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.26s]
[0m21:32:03.418364 [info ] [Thread-4 (]: 4 of 13 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.26s]
[0m21:32:03.418958 [debug] [Thread-3 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:32:03.419425 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:32:03.419846 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:32:03.420223 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:32:03.420569 [debug] [Thread-3 (]: Began running node model.flights_dbt.silver_airlines
[0m21:32:03.420991 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'error'.  Reason: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`name` cannot be resolved. Did you mean one of the following? [`o`.`state`, `d`.`state`, `al`.`airline`, `o`.`city`, `d`.`city`]. SQLSTATE: 42703; line 13 pos 2
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql.
[0m21:32:03.421318 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_flights
[0m21:32:03.421602 [debug] [Thread-1 (]: Began running node model.flights_dbt.stg_airlines
[0m21:32:03.422004 [info ] [Thread-3 (]: 5 of 13 START sql view model raw.silver_airlines ............................... [RUN]
[0m21:32:03.423411 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_airports
[0m21:32:03.423154 [info ] [Thread-2 (]: 6 of 13 START sql view model raw.silver_flights ................................ [RUN]
[0m21:32:03.423823 [info ] [Thread-1 (]: 7 of 13 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:32:03.424329 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airlines) - Creating connection
[0m21:32:03.424659 [info ] [Thread-4 (]: 8 of 13 START sql view model raw.silver_airports ............................... [RUN]
[0m21:32:03.425029 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:32:03.425394 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:32:03.425773 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airlines'
[0m21:32:03.426196 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:32:03.426522 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:32:03.426869 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:32:03.427175 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.silver_airlines
[0m21:32:03.427454 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:32:03.427738 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:32:03.428047 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:32:03.429526 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:32:03.431966 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:32:03.434784 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:32:03.439231 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.silver_airlines"
[0m21:32:03.441128 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:32:03.441707 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_flights
[0m21:32:03.441930 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_airports
[0m21:32:03.443664 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:32:03.443850 [debug] [Thread-3 (]: Began executing node model.flights_dbt.silver_airlines
[0m21:32:03.444940 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:32:03.445141 [debug] [Thread-1 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:32:03.445899 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:32:03.447270 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:32:03.447791 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:32:03.457394 [debug] [Thread-1 (]: MATERIALIZING TABLE
[0m21:32:03.457843 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:32:03.458338 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`silver_airlines`
[0m21:32:03.458674 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:32:03.473391 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:32:03.473743 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.silver_airlines"
[0m21:32:03.474018 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:32:03.474182 [debug] [Thread-2 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:32:03.474310 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:32:03.474541 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:32:03.474648 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:32:03.474832 [debug] [Thread-1 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:32:03.474938 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.silver_airlines"
[0m21:32:03.475062 [debug] [Thread-4 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:32:03.475178 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:32:03.475300 [debug] [Thread-3 (]: On model.flights_dbt.silver_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airlines`
  
  as (
    select
    airline
from `flight_db`.`raw`.`bronze_airlines`
  )

[0m21:32:03.475409 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:32:03.475578 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:32:04.135421 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-d60a-1174-a3c1-9a0212c1521e) - Created
[0m21:32:04.206642 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-d615-188b-ba40-a5eb8490c485) - Created
[0m21:32:04.211064 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-d615-1f96-bdce-3cfdfba5f7d0) - Created
[0m21:32:04.213311 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-d616-1142-bdea-5603ff23775a) - Created
[0m21:32:04.696591 [debug] [Thread-2 (]: SQL status: OK in 1.220 seconds
[0m21:32:04.698344 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c5-d60a-1174-a3c1-9a0212c1521e, command-id=01f089c5-d624-138b-afcb-8a0082618b73) - Closing
[0m21:32:04.699304 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:32:04.700304 [debug] [Thread-2 (]: On model.flights_dbt.silver_flights: Close
[0m21:32:04.700654 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-d60a-1174-a3c1-9a0212c1521e) - Closing
[0m21:32:04.821965 [debug] [Thread-3 (]: SQL status: OK in 1.350 seconds
[0m21:32:04.823922 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c5-d615-188b-ba40-a5eb8490c485, command-id=01f089c5-d630-1746-b854-21e53ecba71b) - Closing
[0m21:32:04.825123 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:32:04.858566 [debug] [Thread-4 (]: SQL status: OK in 1.380 seconds
[0m21:32:04.860263 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c5-d616-1142-bdea-5603ff23775a, command-id=01f089c5-d631-1300-a10e-57c2b90899ef) - Closing
[0m21:32:04.861389 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:32:04.875507 [debug] [Thread-3 (]: On model.flights_dbt.silver_airlines: Close
[0m21:32:04.876088 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-d615-188b-ba40-a5eb8490c485) - Closing
[0m21:32:05.055524 [debug] [Thread-4 (]: On model.flights_dbt.silver_airports: Close
[0m21:32:05.056612 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-d616-1142-bdea-5603ff23775a) - Closing
[0m21:32:05.245282 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb9a8d0>]}
[0m21:32:05.246220 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb9a2d0>]}
[0m21:32:05.246644 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb982f0>]}
[0m21:32:05.247648 [info ] [Thread-2 (]: 6 of 13 OK created sql view model raw.silver_flights ........................... [[32mOK[0m in 1.82s]
[0m21:32:05.248234 [info ] [Thread-3 (]: 5 of 13 OK created sql view model raw.silver_airlines .......................... [[32mOK[0m in 1.82s]
[0m21:32:05.249577 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_flights
[0m21:32:05.249076 [info ] [Thread-4 (]: 8 of 13 OK created sql view model raw.silver_airports .......................... [[32mOK[0m in 1.82s]
[0m21:32:05.250159 [debug] [Thread-3 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:32:05.250584 [debug] [Thread-2 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:32:05.251122 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_airports
[0m21:32:05.251483 [debug] [Thread-3 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:32:05.251892 [info ] [Thread-2 (]: 9 of 13 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:32:05.252365 [info ] [Thread-3 (]: 10 of 13 START test unique_my_first_dbt_model_flight_id ........................ [RUN]
[0m21:32:05.253001 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:32:05.253482 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:32:05.253819 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:32:05.254108 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:32:05.254414 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:32:05.254726 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:32:05.267788 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:32:05.278413 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:32:05.279160 [debug] [Thread-3 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:32:05.284857 [debug] [Thread-2 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:32:05.289645 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:32:05.290816 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:32:05.291107 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:32:05.291293 [debug] [Thread-3 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:32:05.291450 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:32:05.291601 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:32:05.291769 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:32:05.292004 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:32:05.955938 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-d720-124d-869c-f6690ba7563d) - Created
[0m21:32:05.958004 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-d720-10fd-ab91-65a344d6954c) - Created
[0m21:32:06.320575 [debug] [Thread-1 (]: SQL status: OK in 2.850 seconds
[0m21:32:06.321998 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c5-d615-1f96-bdce-3cfdfba5f7d0, command-id=01f089c5-d631-191f-868e-0cc2604e11c1) - Closing
[0m21:32:06.326296 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:32:06.344110 [debug] [Thread-1 (]: On model.flights_dbt.stg_airlines: Close
[0m21:32:06.344363 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c5-d615-1f96-bdce-3cfdfba5f7d0) - Closing
[0m21:32:06.360294 [debug] [Thread-3 (]: SQL status: OK in 1.070 seconds
[0m21:32:06.363223 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c5-d720-124d-869c-f6690ba7563d, command-id=01f089c5-d73b-16bc-9dfa-a2b3c7d672fd) - Closing
[0m21:32:06.370463 [debug] [Thread-2 (]: SQL status: OK in 1.080 seconds
[0m21:32:06.371705 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c5-d720-10fd-ab91-65a344d6954c, command-id=01f089c5-d73c-1620-bc57-b5a73cc051f2) - Closing
[0m21:32:06.540958 [debug] [Thread-3 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:32:06.541979 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-d720-124d-869c-f6690ba7563d) - Closing
[0m21:32:06.743652 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:32:06.744772 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-d720-10fd-ab91-65a344d6954c) - Closing
[0m21:32:06.934431 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e401c10>]}
[0m21:32:06.935716 [info ] [Thread-3 (]: 10 of 13 PASS unique_my_first_dbt_model_flight_id .............................. [[32mPASS[0m in 1.68s]
[0m21:32:06.936395 [info ] [Thread-2 (]: 9 of 13 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.68s]
[0m21:32:06.937841 [debug] [Thread-3 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:32:06.937289 [info ] [Thread-1 (]: 7 of 13 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.51s]
[0m21:32:06.938405 [debug] [Thread-2 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:32:06.939014 [debug] [Thread-1 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:32:06.939605 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:32:06.940074 [info ] [Thread-4 (]: 11 of 13 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:32:06.940703 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:32:06.941050 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:32:06.941361 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:32:06.945510 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:32:06.947370 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:32:06.950191 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:32:06.952000 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:32:06.952735 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:32:06.953741 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:32:06.954051 [debug] [Thread-4 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:32:06.954299 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:32:07.624196 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-d81e-1c34-952c-288917b308f5) - Created
[0m21:32:08.189391 [debug] [Thread-4 (]: SQL status: OK in 1.230 seconds
[0m21:32:08.191924 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c5-d81e-1c34-952c-288917b308f5, command-id=01f089c5-d839-15c4-8a95-586e0495a606) - Closing
[0m21:32:08.193090 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:32:08.193997 [debug] [Thread-4 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:32:08.194323 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c5-d81e-1c34-952c-288917b308f5) - Closing
[0m21:32:08.384729 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4de3b00-eb64-4797-aaa5-1a1add9b4191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb982f0>]}
[0m21:32:08.386093 [info ] [Thread-4 (]: 11 of 13 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.44s]
[0m21:32:08.386911 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:32:08.388083 [debug] [Thread-2 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:32:08.388564 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:32:08.388979 [info ] [Thread-2 (]: 13 of 13 START test unique_my_second_dbt_model_flight_id ....................... [RUN]
[0m21:32:08.389359 [info ] [Thread-3 (]: 12 of 13 START test not_null_my_second_dbt_model_flight_id ..................... [RUN]
[0m21:32:08.389984 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580) - Creating connection
[0m21:32:08.390456 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d) - Creating connection
[0m21:32:08.390777 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580'
[0m21:32:08.391062 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d'
[0m21:32:08.391366 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:32:08.391639 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:32:08.397588 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:32:08.405520 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:32:08.407112 [debug] [Thread-2 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:32:08.407481 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:32:08.409781 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:32:08.411823 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:32:08.412291 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:32:08.412491 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:32:08.412771 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:32:08.413053 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:32:08.413275 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:32:08.413458 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:32:09.055474 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-d8f9-1064-bd3f-492030c4525a) - Created
[0m21:32:09.093821 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-d8fd-1e4e-a909-8cf7202d9fb4) - Created
[0m21:32:09.435978 [debug] [Thread-2 (]: SQL status: OK in 1.020 seconds
[0m21:32:09.439437 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c5-d8f9-1064-bd3f-492030c4525a, command-id=01f089c5-d912-1df8-b664-17a3d951ef53) - Closing
[0m21:32:09.440446 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: Close
[0m21:32:09.440782 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c5-d8f9-1064-bd3f-492030c4525a) - Closing
[0m21:32:09.520359 [debug] [Thread-3 (]: SQL status: OK in 1.110 seconds
[0m21:32:09.524530 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c5-d8fd-1e4e-a909-8cf7202d9fb4, command-id=01f089c5-d919-14ca-9400-07f21d23145b) - Closing
[0m21:32:09.624968 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: Close
[0m21:32:09.626073 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c5-d8fd-1e4e-a909-8cf7202d9fb4) - Closing
[0m21:32:09.852984 [info ] [Thread-2 (]: 13 of 13 PASS unique_my_second_dbt_model_flight_id ............................. [[32mPASS[0m in 1.46s]
[0m21:32:09.853986 [info ] [Thread-3 (]: 12 of 13 PASS not_null_my_second_dbt_model_flight_id ........................... [[32mPASS[0m in 1.46s]
[0m21:32:09.854883 [debug] [Thread-2 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:32:09.855431 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:32:09.857434 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:32:09.857790 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:32:09.858349 [info ] [MainThread]: 
[0m21:32:09.858695 [info ] [MainThread]: Finished running 1 table model, 4 data tests, 8 view models in 0 hours 0 minutes and 11.56 seconds (11.56s).
[0m21:32:09.860942 [debug] [MainThread]: Command end result
[0m21:32:09.893238 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:32:09.894560 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:32:09.898627 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:32:09.898782 [info ] [MainThread]: 
[0m21:32:09.898941 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:32:09.899072 [info ] [MainThread]: 
[0m21:32:09.899238 [error] [MainThread]: [31mFailure in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)[0m
[0m21:32:09.899401 [error] [MainThread]:   Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`name` cannot be resolved. Did you mean one of the following? [`o`.`state`, `d`.`state`, `al`.`airline`, `o`.`city`, `d`.`city`]. SQLSTATE: 42703; line 13 pos 2
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:32:09.899516 [info ] [MainThread]: 
[0m21:32:09.899645 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:32:09.899760 [info ] [MainThread]: 
[0m21:32:09.899891 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=13
[0m21:32:09.903413 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 12.678909, "process_in_blocks": "0", "process_kernel_time": 0.286963, "process_mem_max_rss": "248184832", "process_out_blocks": "0", "process_user_time": 2.970014}
[0m21:32:09.903689 [debug] [MainThread]: Command `dbt build` failed at 21:32:09.903635 after 12.68 seconds
[0m21:32:09.903888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10685a210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e28a3f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d42090>]}
[0m21:32:09.904050 [debug] [MainThread]: Flushing usage events
[0m21:32:10.642456 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:34:01.262121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100e3620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111aff890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111affb10>]}


============================== 21:34:01.264382 | 769fbcd4-c513-4891-9c82-ec4575ead37d ==============================
[0m21:34:01.264382 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:34:01.264617 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/artakerqeli/flights_dbt/logs', 'partial_parse': 'True', 'log_format': 'default', 'no_print': 'None', 'write_json': 'True', 'invocation_command': 'dbt build', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'warn_error': 'None', 'version_check': 'True', 'static_parser': 'True', 'quiet': 'False', 'printer_width': '80', 'target_path': 'None', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'debug': 'False', 'profiles_dir': '/Users/artakerqeli/.dbt', 'log_cache_events': 'False', 'empty': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False'}
[0m21:34:01.564992 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:34:01.565179 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:34:01.565276 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:34:02.017347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a1b360>]}
[0m21:34:02.036622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114f06ad0>]}
[0m21:34:02.036877 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:34:02.093296 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:34:02.158232 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:34:02.158489 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/gold/gold_flight_metrics.sql
[0m21:34:02.244922 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:34:02.249729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124f06850>]}
[0m21:34:02.283842 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:34:02.284897 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:34:02.296204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125223c50>]}
[0m21:34:02.296418 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:34:02.297438 [info ] [MainThread]: 
[0m21:34:02.297570 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:34:02.297662 [info ] [MainThread]: 
[0m21:34:02.297858 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:34:02.297956 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:34:02.300504 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:34:02.300618 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:34:02.304827 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:34:02.304943 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:34:02.305030 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:34:03.074157 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c6-1cec-13c4-a721-01c562d35065) - Created
[0m21:34:03.695836 [debug] [ThreadPool]: SQL status: OK in 1.390 seconds
[0m21:34:03.705639 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c6-1cec-13c4-a721-01c562d35065, command-id=01f089c6-1d0c-11bf-880f-c3ea790fa698) - Closing
[0m21:34:03.706131 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:34:03.706331 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c6-1cec-13c4-a721-01c562d35065) - Closing
[0m21:34:03.923566 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:34:03.924452 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:34:03.936490 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:34:03.936831 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:34:03.937052 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:34:04.598237 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c6-1dd6-1505-bc92-435560b7bf42) - Created
[0m21:34:05.152449 [debug] [ThreadPool]: SQL status: OK in 1.220 seconds
[0m21:34:05.156090 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c6-1dd6-1505-bc92-435560b7bf42, command-id=01f089c6-1dfa-1700-8bcf-fc073e669a71) - Closing
[0m21:34:05.157201 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:34:05.157514 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c6-1dd6-1505-bc92-435560b7bf42) - Closing
[0m21:34:05.363430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1254ee5f0>]}
[0m21:34:05.368817 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_flights
[0m21:34:05.369218 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airports
[0m21:34:05.369469 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:34:05.369708 [debug] [Thread-3 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:34:05.370222 [info ] [Thread-2 (]: 2 of 13 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:34:05.370564 [info ] [Thread-1 (]: 1 of 13 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:34:05.370932 [info ] [Thread-4 (]: 4 of 13 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:34:05.371523 [info ] [Thread-3 (]: 3 of 13 START sql view model raw.gold_flight_metrics ........................... [RUN]
[0m21:34:05.372236 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:34:05.372704 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:34:05.373108 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:34:05.373481 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.gold_flight_metrics) - Creating connection
[0m21:34:05.373759 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:34:05.374020 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:34:05.374271 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:34:05.374513 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.gold_flight_metrics'
[0m21:34:05.374781 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:34:05.375039 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:34:05.375268 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:34:05.375472 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.gold_flight_metrics
[0m21:34:05.382183 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:34:05.384114 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:34:05.387427 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:34:05.388601 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.gold_flight_metrics"
[0m21:34:05.389598 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:34:05.389821 [debug] [Thread-3 (]: Began executing node model.flights_dbt.gold_flight_metrics
[0m21:34:05.390071 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:34:05.390263 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:34:05.399270 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:34:05.400231 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:34:05.401275 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:34:05.402122 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:34:05.403140 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:34:05.403407 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:34:05.403639 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:34:05.403858 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:34:05.404054 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1255964e0>]}
[0m21:34:05.404195 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125400dd0>]}
[0m21:34:05.404321 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1254001d0>]}
[0m21:34:05.404443 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1254d83c0>]}
[0m21:34:05.411120 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`gold_flight_metrics`
[0m21:34:05.411462 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:34:05.411802 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:34:05.412115 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:34:05.416057 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.gold_flight_metrics"
[0m21:34:05.416364 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:34:05.416653 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:34:05.416933 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:34:05.417337 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.gold_flight_metrics"
[0m21:34:05.417581 [debug] [Thread-3 (]: On model.flights_dbt.gold_flight_metrics: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
  
  create or replace view `flight_db`.`raw`.`gold_flight_metrics`
  
  as (
    -- models/gold/gold_flight_metrics.sql

select
  f.airline,
  al.name as airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.destination,
  d.airport_name as destination_airport_name,
  count(*) as flights,
  avg(coalesce(f.dep_delay, 0)) as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0)) as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from raw.silver_flights f
left join raw.silver_airlines al on f.airline = al.airline
left join raw.silver_airports o on f.origin = o.iata_code
left join raw.silver_airports d on f.destination = d.iata_code
group by 1,2,3,4,5,6
  )

[0m21:34:05.417740 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:34:05.417928 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:34:05.418093 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    -- models/bronze/bronze_airports.sql
select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:34:05.418217 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:34:05.418378 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:34:05.418528 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    -- models/bronze/bronze_flights.sql
select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m21:34:05.418645 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:34:05.418807 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:34:05.418934 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:34:05.419158 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:34:06.165059 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-1ec6-1037-a2ab-8261b106a599) - Created
[0m21:34:06.184028 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-1ec9-1295-9170-560d437387dc) - Created
[0m21:34:06.201064 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-1ecb-1708-b7bf-a3586e245bd9) - Created
[0m21:34:06.202753 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-1ecc-1296-a0f4-5ee0e988b00a) - Created
[0m21:34:06.782913 [debug] [Thread-3 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
  
  create or replace view `flight_db`.`raw`.`gold_flight_metrics`
  
  as (
    -- models/gold/gold_flight_metrics.sql

select
  f.airline,
  al.name as airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.destination,
  d.airport_name as destination_airport_name,
  count(*) as flights,
  avg(coalesce(f.dep_delay, 0)) as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0)) as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from raw.silver_flights f
left join raw.silver_airlines al on f.airline = al.airline
left join raw.silver_airports o on f.origin = o.iata_code
left join raw.silver_airports d on f.destination = d.iata_code
group by 1,2,3,4,5,6
  )

: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`name` cannot be resolved. Did you mean one of the following? [`o`.`state`, `d`.`state`, `al`.`airline`, `o`.`city`, `d`.`city`]. SQLSTATE: 42703; line 12 pos 2
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`name` cannot be resolved. Did you mean one of the following? [`o`.`state`, `d`.`state`, `al`.`airline`, `o`.`city`, `d`.`city`]. SQLSTATE: 42703; line 12 pos 2
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`name` cannot be resolved. Did you mean one of the following? [`o`.`state`, `d`.`state`, `al`.`airline`, `o`.`city`, `d`.`city`]. SQLSTATE: 42703; line 12 pos 2
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c6-1ee4-1b46-909e-df38cc0e7f9b
[0m21:34:06.784184 [debug] [Thread-3 (]: On model.flights_dbt.gold_flight_metrics: Close
[0m21:34:06.784563 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-1ec9-1295-9170-560d437387dc) - Closing
[0m21:34:06.830797 [debug] [Thread-2 (]: SQL status: OK in 1.410 seconds
[0m21:34:06.833196 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c6-1ec6-1037-a2ab-8261b106a599, command-id=01f089c6-1edf-1f70-9383-546c9b6dd0d3) - Closing
[0m21:34:06.846562 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:34:06.861148 [debug] [Thread-1 (]: SQL status: OK in 1.440 seconds
[0m21:34:06.862273 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c6-1ecb-1708-b7bf-a3586e245bd9, command-id=01f089c6-1ee8-1155-9d79-f608011d6841) - Closing
[0m21:34:06.863008 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:34:06.889106 [debug] [Thread-4 (]: SQL status: OK in 1.470 seconds
[0m21:34:06.890330 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c6-1ecc-1296-a0f4-5ee0e988b00a, command-id=01f089c6-1ee7-134f-b423-a9250859997b) - Closing
[0m21:34:06.891064 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:34:06.996288 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: Close
[0m21:34:06.997018 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-1ec6-1037-a2ab-8261b106a599) - Closing
[0m21:34:07.008249 [debug] [Thread-3 (]: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`name` cannot be resolved. Did you mean one of the following? [`o`.`state`, `d`.`state`, `al`.`airline`, `o`.`city`, `d`.`city`]. SQLSTATE: 42703; line 12 pos 2
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:34:07.191405 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: Close
[0m21:34:07.192510 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-1ecb-1708-b7bf-a3586e245bd9) - Closing
[0m21:34:07.403503 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:34:07.404633 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-1ecc-1296-a0f4-5ee0e988b00a) - Closing
[0m21:34:07.618808 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1274699d0>]}
[0m21:34:07.619237 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127735cd0>]}
[0m21:34:07.619560 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124aa3150>]}
[0m21:34:07.619848 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1274f15b0>]}
[0m21:34:07.620251 [info ] [Thread-2 (]: 2 of 13 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.24s]
[0m21:34:07.620746 [info ] [Thread-4 (]: 4 of 13 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.25s]
[0m21:34:07.621363 [error] [Thread-3 (]: 3 of 13 ERROR creating sql view model raw.gold_flight_metrics .................. [[31mERROR[0m in 2.24s]
[0m21:34:07.622323 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:34:07.621933 [info ] [Thread-1 (]: 1 of 13 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.25s]
[0m21:34:07.622776 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:34:07.623155 [debug] [Thread-3 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:34:07.623487 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_airlines
[0m21:34:07.623941 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:34:07.624238 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_flights
[0m21:34:07.624679 [debug] [Thread-3 (]: Began running node model.flights_dbt.stg_airlines
[0m21:34:07.625238 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'error'.  Reason: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`name` cannot be resolved. Did you mean one of the following? [`o`.`state`, `d`.`state`, `al`.`airline`, `o`.`city`, `d`.`city`]. SQLSTATE: 42703; line 12 pos 2
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql.
[0m21:34:07.625782 [info ] [Thread-2 (]: 5 of 13 START sql view model raw.silver_airlines ............................... [RUN]
[0m21:34:07.626201 [debug] [Thread-1 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:34:07.626678 [info ] [Thread-4 (]: 6 of 13 START sql view model raw.silver_flights ................................ [RUN]
[0m21:34:07.627144 [info ] [Thread-3 (]: 7 of 13 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:34:07.628353 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airlines) - Creating connection
[0m21:34:07.628737 [info ] [Thread-1 (]: 8 of 13 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:34:07.629190 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:34:07.629610 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:34:07.629908 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airlines'
[0m21:34:07.630307 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:34:07.630577 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:34:07.630807 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:34:07.631069 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_airlines
[0m21:34:07.631294 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:34:07.631501 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:34:07.631703 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:34:07.633039 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:34:07.636171 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:34:07.638916 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:34:07.643200 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_airlines"
[0m21:34:07.650485 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:34:07.651031 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_airlines
[0m21:34:07.651195 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_flights
[0m21:34:07.652172 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:34:07.652355 [debug] [Thread-3 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:34:07.653283 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:34:07.653428 [debug] [Thread-1 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:34:07.654071 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_airlines`
[0m21:34:07.663190 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m21:34:07.663684 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:34:07.671650 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:34:07.672023 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_airlines"
[0m21:34:07.678646 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:34:07.686033 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:34:07.686385 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:34:07.686538 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:34:07.686666 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:34:07.686775 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_airlines"
[0m21:34:07.686887 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:34:07.687028 [debug] [Thread-1 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:34:07.687131 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:34:07.687249 [debug] [Thread-2 (]: On model.flights_dbt.silver_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airlines`
  
  as (
    select
    airline
from `flight_db`.`raw`.`bronze_airlines`
  )

[0m21:34:07.687449 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:34:07.687576 [debug] [Thread-3 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:34:07.687733 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:34:07.687901 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:34:08.345992 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-2013-165f-bf39-95c19188464c) - Created
[0m21:34:08.437930 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-2020-1ffd-b0a4-ffa5e31a358f) - Created
[0m21:34:08.476249 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-2026-179b-b83a-e8bf8d81e44e) - Created
[0m21:34:08.484761 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-2027-14d1-887e-884388bed97d) - Created
[0m21:34:08.849601 [debug] [Thread-1 (]: SQL status: OK in 1.160 seconds
[0m21:34:08.854247 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c6-2026-179b-b83a-e8bf8d81e44e, command-id=01f089c6-2044-1b78-b0d9-90c945923e13) - Closing
[0m21:34:08.856336 [debug] [Thread-1 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:34:08.856592 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-2026-179b-b83a-e8bf8d81e44e) - Closing
[0m21:34:08.900112 [debug] [Thread-4 (]: SQL status: OK in 1.210 seconds
[0m21:34:08.901794 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c6-2013-165f-bf39-95c19188464c, command-id=01f089c6-202c-1b2c-8e7e-e1af743ca7dd) - Closing
[0m21:34:08.902653 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:34:09.056709 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: Close
[0m21:34:09.057780 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-2013-165f-bf39-95c19188464c) - Closing
[0m21:34:09.061093 [debug] [Thread-2 (]: SQL status: OK in 1.370 seconds
[0m21:34:09.062341 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c6-2020-1ffd-b0a4-ffa5e31a358f, command-id=01f089c6-203d-1073-9b18-17f6cf248a98) - Closing
[0m21:34:09.063132 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:34:09.249977 [debug] [Thread-2 (]: On model.flights_dbt.silver_airlines: Close
[0m21:34:09.249077 [info ] [Thread-1 (]: 8 of 13 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.62s]
[0m21:34:09.250752 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-2020-1ffd-b0a4-ffa5e31a358f) - Closing
[0m21:34:09.251428 [debug] [Thread-1 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:34:09.252506 [debug] [Thread-1 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:34:09.253002 [info ] [Thread-1 (]: 9 of 13 START test unique_my_first_dbt_model_flight_id ......................... [RUN]
[0m21:34:09.443523 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1274c6a50>]}
[0m21:34:09.444719 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:34:09.445471 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1255b9b50>]}
[0m21:34:09.446706 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:34:09.446363 [info ] [Thread-4 (]: 6 of 13 OK created sql view model raw.silver_flights ........................... [[32mOK[0m in 1.81s]
[0m21:34:09.447709 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:34:09.447409 [info ] [Thread-2 (]: 5 of 13 OK created sql view model raw.silver_airlines .......................... [[32mOK[0m in 1.82s]
[0m21:34:09.448303 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_flights
[0m21:34:09.456648 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:34:09.457193 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:34:09.457513 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_airports
[0m21:34:09.458065 [info ] [Thread-4 (]: 10 of 13 START sql view model raw.silver_airports .............................. [RUN]
[0m21:34:09.458585 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:34:09.458828 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:34:09.459076 [debug] [Thread-1 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:34:09.459457 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:34:09.462463 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:34:09.464705 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:34:09.465237 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:34:09.465513 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_airports
[0m21:34:09.465848 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:34:09.469539 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:34:09.477158 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:34:09.477793 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:34:09.478211 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:34:09.478532 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:34:09.478719 [debug] [Thread-4 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:34:09.478886 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:34:10.152609 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-2125-1a9b-995b-bc2528485f9e) - Created
[0m21:34:10.178843 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-2127-12d2-af48-332a2bccabbc) - Created
[0m21:34:10.473090 [debug] [Thread-3 (]: SQL status: OK in 2.780 seconds
[0m21:34:10.474746 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c6-2027-14d1-887e-884388bed97d, command-id=01f089c6-2045-1157-b81e-fc4da77eaa81) - Closing
[0m21:34:10.479612 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:34:10.495466 [debug] [Thread-3 (]: On model.flights_dbt.stg_airlines: Close
[0m21:34:10.495777 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-2027-14d1-887e-884388bed97d) - Closing
[0m21:34:10.550203 [debug] [Thread-1 (]: SQL status: OK in 1.080 seconds
[0m21:34:10.552996 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c6-2127-12d2-af48-332a2bccabbc, command-id=01f089c6-2145-16de-a44b-2e46f2c0f89c) - Closing
[0m21:34:10.690919 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:34:10.692021 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-2127-12d2-af48-332a2bccabbc) - Closing
[0m21:34:10.765223 [debug] [Thread-4 (]: SQL status: OK in 1.290 seconds
[0m21:34:10.767664 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c6-2125-1a9b-995b-bc2528485f9e, command-id=01f089c6-2146-1ac9-91e8-430af29c5b21) - Closing
[0m21:34:10.769271 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:34:10.897628 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124a92330>]}
[0m21:34:10.898526 [debug] [Thread-4 (]: On model.flights_dbt.silver_airports: Close
[0m21:34:10.899862 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-2125-1a9b-995b-bc2528485f9e) - Closing
[0m21:34:10.899475 [info ] [Thread-3 (]: 7 of 13 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.27s]
[0m21:34:10.901078 [debug] [Thread-3 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:34:11.109758 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124a90530>]}
[0m21:34:11.108821 [info ] [Thread-1 (]: 9 of 13 PASS unique_my_first_dbt_model_flight_id ............................... [[32mPASS[0m in 1.85s]
[0m21:34:11.111708 [debug] [Thread-1 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:34:11.111153 [info ] [Thread-4 (]: 10 of 13 OK created sql view model raw.silver_airports ......................... [[32mOK[0m in 1.65s]
[0m21:34:11.112563 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_airports
[0m21:34:11.112911 [debug] [Thread-2 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:34:11.113436 [info ] [Thread-2 (]: 11 of 13 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:34:11.114044 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:34:11.114365 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:34:11.114680 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:34:11.118796 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:34:11.119825 [debug] [Thread-2 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:34:11.128888 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:34:11.129965 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:34:11.130561 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:34:11.131335 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:34:11.131632 [debug] [Thread-2 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:34:11.131874 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:34:11.804026 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-2221-1036-a817-6ddfc89dae16) - Created
[0m21:34:12.446882 [debug] [Thread-2 (]: SQL status: OK in 1.310 seconds
[0m21:34:12.448669 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c6-2221-1036-a817-6ddfc89dae16, command-id=01f089c6-223e-1091-ba2a-2e2181c184ee) - Closing
[0m21:34:12.449702 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:34:12.450750 [debug] [Thread-2 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:34:12.451089 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-2221-1036-a817-6ddfc89dae16) - Closing
[0m21:34:12.646100 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '769fbcd4-c513-4891-9c82-ec4575ead37d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1274f15b0>]}
[0m21:34:12.647893 [info ] [Thread-2 (]: 11 of 13 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.53s]
[0m21:34:12.648753 [debug] [Thread-2 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:34:12.649954 [debug] [Thread-1 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:34:12.650374 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:34:12.650806 [info ] [Thread-1 (]: 13 of 13 START test unique_my_second_dbt_model_flight_id ....................... [RUN]
[0m21:34:12.651221 [info ] [Thread-3 (]: 12 of 13 START test not_null_my_second_dbt_model_flight_id ..................... [RUN]
[0m21:34:12.651953 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580) - Creating connection
[0m21:34:12.652500 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d) - Creating connection
[0m21:34:12.652848 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580'
[0m21:34:12.653147 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d'
[0m21:34:12.653448 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:34:12.653733 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:34:12.661277 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:34:12.667066 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:34:12.667999 [debug] [Thread-1 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:34:12.668252 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:34:12.670223 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:34:12.672616 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:34:12.673133 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:34:12.673323 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:34:12.673572 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:34:12.673840 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:34:12.674065 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:34:12.674261 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:34:13.333457 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-230b-1eb0-8d6a-11a6a8da9ea1) - Created
[0m21:34:13.344389 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-230d-1861-8de0-011b5368d58c) - Created
[0m21:34:13.642326 [debug] [Thread-1 (]: SQL status: OK in 0.970 seconds
[0m21:34:13.645440 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c6-230d-1861-8de0-011b5368d58c, command-id=01f089c6-2329-11f6-abc4-98693c20498a) - Closing
[0m21:34:13.646152 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: Close
[0m21:34:13.646454 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-230d-1861-8de0-011b5368d58c) - Closing
[0m21:34:13.653684 [debug] [Thread-3 (]: SQL status: OK in 0.980 seconds
[0m21:34:13.655650 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c6-230b-1eb0-8d6a-11a6a8da9ea1, command-id=01f089c6-2326-1107-8931-dabac3888c11) - Closing
[0m21:34:13.841588 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: Close
[0m21:34:13.842640 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-230b-1eb0-8d6a-11a6a8da9ea1) - Closing
[0m21:34:14.040291 [info ] [Thread-1 (]: 13 of 13 PASS unique_my_second_dbt_model_flight_id ............................. [[32mPASS[0m in 1.39s]
[0m21:34:14.041166 [info ] [Thread-3 (]: 12 of 13 PASS not_null_my_second_dbt_model_flight_id ........................... [[32mPASS[0m in 1.39s]
[0m21:34:14.041852 [debug] [Thread-1 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:34:14.042274 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:34:14.044059 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:34:14.044426 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:34:14.044896 [info ] [MainThread]: 
[0m21:34:14.045191 [info ] [MainThread]: Finished running 1 table model, 4 data tests, 8 view models in 0 hours 0 minutes and 11.75 seconds (11.75s).
[0m21:34:14.047010 [debug] [MainThread]: Command end result
[0m21:34:14.072959 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:34:14.074198 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:34:14.077914 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:34:14.078056 [info ] [MainThread]: 
[0m21:34:14.078206 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:34:14.078333 [info ] [MainThread]: 
[0m21:34:14.078486 [error] [MainThread]: [31mFailure in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)[0m
[0m21:34:14.078637 [error] [MainThread]:   Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `al`.`name` cannot be resolved. Did you mean one of the following? [`o`.`state`, `d`.`state`, `al`.`airline`, `o`.`city`, `d`.`city`]. SQLSTATE: 42703; line 12 pos 2
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:34:14.078746 [info ] [MainThread]: 
[0m21:34:14.078877 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:34:14.078988 [info ] [MainThread]: 
[0m21:34:14.079117 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=13
[0m21:34:14.081640 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 12.850073, "process_in_blocks": "0", "process_kernel_time": 0.277672, "process_mem_max_rss": "252215296", "process_out_blocks": "0", "process_user_time": 3.011731}
[0m21:34:14.081838 [debug] [MainThread]: Command `dbt build` failed at 21:34:14.081797 after 12.85 seconds
[0m21:34:14.082001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108ff350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127743f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127743a10>]}
[0m21:34:14.082142 [debug] [MainThread]: Flushing usage events
[0m21:34:14.945879 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:36:43.195498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104db620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cff890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111cffb10>]}


============================== 21:36:43.197773 | 4c8dbef2-10a2-4e3b-945a-0d8b41a948c1 ==============================
[0m21:36:43.197773 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:36:43.198015 [debug] [MainThread]: running dbt with arguments {'empty': 'False', 'introspect': 'True', 'profiles_dir': '/Users/artakerqeli/.dbt', 'quiet': 'False', 'write_json': 'True', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt build', 'cache_selected_only': 'False', 'partial_parse': 'True', 'version_check': 'True', 'log_cache_events': 'False', 'fail_fast': 'False', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'printer_width': '80'}
[0m21:36:43.497000 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:36:43.497196 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:36:43.497294 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:36:43.941543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c23360>]}
[0m21:36:43.960793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11450aad0>]}
[0m21:36:43.961030 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:36:44.009855 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:36:44.068397 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:36:44.068643 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/gold/gold_flight_metrics.sql
[0m21:36:44.154860 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:36:44.159588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12370e850>]}
[0m21:36:44.192956 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:36:44.193985 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:36:44.204686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123a23c50>]}
[0m21:36:44.204873 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:36:44.205834 [info ] [MainThread]: 
[0m21:36:44.205961 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:36:44.206046 [info ] [MainThread]: 
[0m21:36:44.206237 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:36:44.206328 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:36:44.208815 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:36:44.208932 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:36:44.213171 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:36:44.213286 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:36:44.213377 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:36:44.986782 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c6-7d6e-110d-b914-b35c3e85c980) - Created
[0m21:36:45.402594 [debug] [ThreadPool]: SQL status: OK in 1.190 seconds
[0m21:36:45.421240 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c6-7d6e-110d-b914-b35c3e85c980, command-id=01f089c6-7d8d-1921-8b34-cba644b342b2) - Closing
[0m21:36:45.421882 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:36:45.422088 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c6-7d6e-110d-b914-b35c3e85c980) - Closing
[0m21:36:45.632592 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:36:45.633153 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:36:45.647060 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:36:45.647434 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:36:45.647692 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:36:46.339825 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c6-7e3c-16dc-8549-287a97c0df61) - Created
[0m21:36:46.831926 [debug] [ThreadPool]: SQL status: OK in 1.180 seconds
[0m21:36:46.836537 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c6-7e3c-16dc-8549-287a97c0df61, command-id=01f089c6-7e5c-1744-aac1-f57aa60e59c6) - Closing
[0m21:36:46.837648 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:36:46.837961 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c6-7e3c-16dc-8549-287a97c0df61) - Closing
[0m21:36:47.043996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123cf65f0>]}
[0m21:36:47.048746 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_flights
[0m21:36:47.049246 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:36:47.049621 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airports
[0m21:36:47.049926 [debug] [Thread-3 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:36:47.050421 [info ] [Thread-2 (]: 2 of 13 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:36:47.050949 [info ] [Thread-4 (]: 4 of 13 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:36:47.051443 [info ] [Thread-1 (]: 1 of 13 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:36:47.051855 [info ] [Thread-3 (]: 3 of 13 START sql view model raw.gold_flight_metrics ........................... [RUN]
[0m21:36:47.052325 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:36:47.052694 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:36:47.053003 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:36:47.053311 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.gold_flight_metrics) - Creating connection
[0m21:36:47.053554 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:36:47.053784 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:36:47.053996 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:36:47.054203 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.gold_flight_metrics'
[0m21:36:47.054431 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:36:47.054648 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:36:47.054852 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:36:47.055052 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.gold_flight_metrics
[0m21:36:47.060901 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:36:47.063162 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:36:47.065543 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:36:47.066616 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.gold_flight_metrics"
[0m21:36:47.067567 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:36:47.067751 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:36:47.067917 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:36:47.068085 [debug] [Thread-3 (]: Began executing node model.flights_dbt.gold_flight_metrics
[0m21:36:47.076721 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:36:47.077727 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:36:47.078781 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:36:47.079633 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:36:47.080699 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:36:47.081007 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:36:47.081266 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:36:47.081500 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:36:47.081699 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123d95640>]}
[0m21:36:47.081846 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123ca8650>]}
[0m21:36:47.081990 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123ca8950>]}
[0m21:36:47.082131 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123cdd390>]}
[0m21:36:47.089924 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:36:47.090325 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:36:47.090844 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:36:47.091191 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`gold_flight_metrics`
[0m21:36:47.095120 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:36:47.095424 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:36:47.095704 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:36:47.095980 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.gold_flight_metrics"
[0m21:36:47.096533 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:36:47.096658 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:36:47.096795 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    -- models/bronze/bronze_airports.sql
select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:36:47.096909 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:36:47.097062 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    -- models/bronze/bronze_flights.sql
select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m21:36:47.097199 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:36:47.097296 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.gold_flight_metrics"
[0m21:36:47.097426 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:36:47.097545 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:36:47.097797 [debug] [Thread-3 (]: On model.flights_dbt.gold_flight_metrics: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
  
  create or replace view `flight_db`.`raw`.`gold_flight_metrics`
  
  as (
    -- models/gold/gold_flight_metrics.sql

select
  f.airline,
  al.airline as airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.destination,
  d.airport_name as destination_airport_name,
  count(*) as flights,
  avg(coalesce(f.dep_delay, 0)) as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0)) as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from raw.silver_flights f
left join raw.silver_airlines al on f.airline = al.airline
left join raw.silver_airports o on f.origin = o.iata_code
left join raw.silver_airports d on f.destination = d.iata_code
group by 1,2,3,4,5,6
  )

[0m21:36:47.097947 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:36:47.098178 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:36:47.814173 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-7f1e-1402-b34c-8ee95f2b6223) - Created
[0m21:36:47.816393 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-7f1f-1d02-8fb5-a4f92dc55de7) - Created
[0m21:36:47.846257 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-7f25-1249-aea2-40b3b87020dc) - Created
[0m21:36:47.857907 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-7f25-19d0-97bc-85702c304955) - Created
[0m21:36:48.470760 [debug] [Thread-3 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
  
  create or replace view `flight_db`.`raw`.`gold_flight_metrics`
  
  as (
    -- models/gold/gold_flight_metrics.sql

select
  f.airline,
  al.airline as airline_name,
  f.origin,
  o.airport_name as origin_airport_name,
  f.destination,
  d.airport_name as destination_airport_name,
  count(*) as flights,
  avg(coalesce(f.dep_delay, 0)) as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0)) as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from raw.silver_flights f
left join raw.silver_airlines al on f.airline = al.airline
left join raw.silver_airports o on f.origin = o.iata_code
left join raw.silver_airports d on f.destination = d.iata_code
group by 1,2,3,4,5,6
  )

: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `o`.`airport_name` cannot be resolved. Did you mean one of the following? [`o`.`airport_id`, `d`.`airport_id`, `f`.`arr_time`, `f`.`airline`, `o`.`iata_code`]. SQLSTATE: 42703; line 14 pos 2
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `o`.`airport_name` cannot be resolved. Did you mean one of the following? [`o`.`airport_id`, `d`.`airport_id`, `f`.`arr_time`, `f`.`airline`, `o`.`iata_code`]. SQLSTATE: 42703; line 14 pos 2
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `o`.`airport_name` cannot be resolved. Did you mean one of the following? [`o`.`airport_id`, `d`.`airport_id`, `f`.`arr_time`, `f`.`airline`, `o`.`iata_code`]. SQLSTATE: 42703; line 14 pos 2
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f089c6-7f3b-1429-a42f-5e25f020b374
[0m21:36:48.471869 [debug] [Thread-4 (]: SQL status: OK in 1.370 seconds
[0m21:36:48.472458 [debug] [Thread-3 (]: On model.flights_dbt.gold_flight_metrics: Close
[0m21:36:48.473777 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c6-7f1e-1402-b34c-8ee95f2b6223, command-id=01f089c6-7f39-1604-87ee-da4e423752b1) - Closing
[0m21:36:48.474139 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-7f1f-1d02-8fb5-a4f92dc55de7) - Closing
[0m21:36:48.487065 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:36:48.516593 [debug] [Thread-2 (]: SQL status: OK in 1.420 seconds
[0m21:36:48.517589 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c6-7f25-19d0-97bc-85702c304955, command-id=01f089c6-7f41-13eb-a2b0-6b975d11d9ab) - Closing
[0m21:36:48.518243 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:36:48.521881 [debug] [Thread-1 (]: SQL status: OK in 1.420 seconds
[0m21:36:48.522619 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c6-7f25-1249-aea2-40b3b87020dc, command-id=01f089c6-7f3f-1742-a82a-1b7c152fa678) - Closing
[0m21:36:48.523084 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:36:48.678569 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:36:48.679281 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-7f1e-1402-b34c-8ee95f2b6223) - Closing
[0m21:36:48.691030 [debug] [Thread-3 (]: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `o`.`airport_name` cannot be resolved. Did you mean one of the following? [`o`.`airport_id`, `d`.`airport_id`, `f`.`arr_time`, `f`.`airline`, `o`.`iata_code`]. SQLSTATE: 42703; line 14 pos 2
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:36:48.868159 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: Close
[0m21:36:48.869725 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-7f25-19d0-97bc-85702c304955) - Closing
[0m21:36:49.103711 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: Close
[0m21:36:49.104489 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-7f25-1249-aea2-40b3b87020dc) - Closing
[0m21:36:49.326109 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1243650d0>]}
[0m21:36:49.326681 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124536050>]}
[0m21:36:49.326974 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1232a31c0>]}
[0m21:36:49.327391 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1243f55b0>]}
[0m21:36:49.328115 [info ] [Thread-4 (]: 4 of 13 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.27s]
[0m21:36:49.329031 [info ] [Thread-1 (]: 1 of 13 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.27s]
[0m21:36:49.329617 [error] [Thread-3 (]: 3 of 13 ERROR creating sql view model raw.gold_flight_metrics .................. [[31mERROR[0m in 2.27s]
[0m21:36:49.330706 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:36:49.330217 [info ] [Thread-2 (]: 2 of 13 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.27s]
[0m21:36:49.331223 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:36:49.331661 [debug] [Thread-3 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:36:49.332070 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_airlines
[0m21:36:49.332677 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:36:49.333126 [debug] [Thread-1 (]: Began running node model.flights_dbt.silver_flights
[0m21:36:49.333475 [debug] [Thread-3 (]: Began running node model.flights_dbt.stg_airlines
[0m21:36:49.333914 [debug] [Thread-7 (]: Marking all children of 'model.flights_dbt.gold_flight_metrics' to be skipped because of status 'error'.  Reason: Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `o`.`airport_name` cannot be resolved. Did you mean one of the following? [`o`.`airport_id`, `d`.`airport_id`, `f`.`arr_time`, `f`.`airline`, `o`.`iata_code`]. SQLSTATE: 42703; line 14 pos 2
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql.
[0m21:36:49.334357 [info ] [Thread-4 (]: 5 of 13 START sql view model raw.silver_airlines ............................... [RUN]
[0m21:36:49.334816 [debug] [Thread-2 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:36:49.335230 [info ] [Thread-1 (]: 6 of 13 START sql view model raw.silver_flights ................................ [RUN]
[0m21:36:49.335629 [info ] [Thread-3 (]: 7 of 13 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:36:49.336720 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airlines) - Creating connection
[0m21:36:49.337025 [info ] [Thread-2 (]: 8 of 13 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:36:49.337406 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:36:49.337729 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:36:49.337984 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airlines'
[0m21:36:49.338307 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:36:49.338529 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:36:49.338926 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:36:49.339212 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_airlines
[0m21:36:49.339487 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:36:49.339746 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:36:49.339998 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:36:49.341150 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:36:49.343833 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:36:49.346621 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:36:49.351127 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_airlines"
[0m21:36:49.359004 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:36:49.359416 [debug] [Thread-1 (]: Began executing node model.flights_dbt.silver_flights
[0m21:36:49.360448 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:36:49.360976 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:36:49.361440 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:36:49.361723 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_airlines
[0m21:36:49.362863 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:36:49.363333 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_airlines`
[0m21:36:49.363697 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_airlines"
[0m21:36:49.363879 [debug] [Thread-3 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:36:49.370248 [debug] [Thread-2 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:36:49.373173 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m21:36:49.373317 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:36:49.380796 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:36:49.380944 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_airlines"
[0m21:36:49.393555 [debug] [Thread-1 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:36:49.394738 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:36:49.394940 [debug] [Thread-4 (]: On model.flights_dbt.silver_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airlines`
  
  as (
    select
    airline
from `flight_db`.`raw`.`bronze_airlines`
  )

[0m21:36:49.395085 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:36:49.395235 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:36:49.395365 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:36:49.395606 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:36:49.395762 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:36:49.395932 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:36:49.396051 [debug] [Thread-3 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:36:49.396249 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:36:50.100269 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-807c-186b-b226-183cb502105f) - Created
[0m21:36:50.127182 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-8081-118f-a9ea-ed8a529b5e3a) - Created
[0m21:36:50.153472 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-8083-1e6a-a391-b0550700e7b3) - Created
[0m21:36:50.156535 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-8082-1b54-93eb-2d79b39de4c0) - Created
[0m21:36:50.506391 [debug] [Thread-2 (]: SQL status: OK in 1.110 seconds
[0m21:36:50.512267 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c6-8082-1b54-93eb-2d79b39de4c0, command-id=01f089c6-80a3-1dbd-aead-247a2b420fd0) - Closing
[0m21:36:50.515290 [debug] [Thread-2 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:36:50.515661 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-8082-1b54-93eb-2d79b39de4c0) - Closing
[0m21:36:50.667442 [debug] [Thread-1 (]: SQL status: OK in 1.270 seconds
[0m21:36:50.669175 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c6-807c-186b-b226-183cb502105f, command-id=01f089c6-8095-1edf-b5af-15b5c362e13b) - Closing
[0m21:36:50.670134 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:36:50.716519 [debug] [Thread-1 (]: On model.flights_dbt.silver_flights: Close
[0m21:36:50.717420 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-807c-186b-b226-183cb502105f) - Closing
[0m21:36:50.776616 [debug] [Thread-4 (]: SQL status: OK in 1.380 seconds
[0m21:36:50.778406 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c6-8083-1e6a-a391-b0550700e7b3, command-id=01f089c6-80a4-10f5-83c7-723dfb798bc2) - Closing
[0m21:36:50.779222 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:36:50.899593 [debug] [Thread-4 (]: On model.flights_dbt.silver_airlines: Close
[0m21:36:50.899065 [info ] [Thread-2 (]: 8 of 13 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.56s]
[0m21:36:50.900158 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-8083-1e6a-a391-b0550700e7b3) - Closing
[0m21:36:50.900711 [debug] [Thread-2 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:36:50.901732 [debug] [Thread-2 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:36:50.902214 [info ] [Thread-2 (]: 9 of 13 START test unique_my_first_dbt_model_flight_id ......................... [RUN]
[0m21:36:51.115559 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123db82f0>]}
[0m21:36:51.116735 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:36:51.117409 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123db95b0>]}
[0m21:36:51.118327 [info ] [Thread-1 (]: 6 of 13 OK created sql view model raw.silver_flights ........................... [[32mOK[0m in 1.78s]
[0m21:36:51.118774 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:36:51.119908 [debug] [Thread-1 (]: Finished running node model.flights_dbt.silver_flights
[0m21:36:51.119441 [info ] [Thread-4 (]: 5 of 13 OK created sql view model raw.silver_airlines .......................... [[32mOK[0m in 1.78s]
[0m21:36:51.120347 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:36:51.120748 [debug] [Thread-1 (]: Began running node model.flights_dbt.silver_airports
[0m21:36:51.121250 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:36:51.129853 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:36:51.130329 [info ] [Thread-1 (]: 10 of 13 START sql view model raw.silver_airports .............................. [RUN]
[0m21:36:51.131119 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:36:51.131391 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:36:51.131624 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:36:51.134025 [debug] [Thread-2 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:36:51.137357 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:36:51.142688 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:36:51.143322 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:36:51.143581 [debug] [Thread-1 (]: Began executing node model.flights_dbt.silver_airports
[0m21:36:51.143859 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:36:51.145281 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:36:51.145505 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:36:51.146292 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:36:51.146993 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:36:51.147357 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:36:51.147549 [debug] [Thread-1 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:36:51.147714 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:36:51.821244 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-8182-1bf5-a3ce-2a010e2ae48c) - Created
[0m21:36:51.865194 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-8189-149e-afb9-0c359e91c043) - Created
[0m21:36:52.060859 [debug] [Thread-3 (]: SQL status: OK in 2.660 seconds
[0m21:36:52.062640 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c6-8081-118f-a9ea-ed8a529b5e3a, command-id=01f089c6-809b-1ec3-89a5-6dee46b632b5) - Closing
[0m21:36:52.067117 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:36:52.081258 [debug] [Thread-3 (]: On model.flights_dbt.stg_airlines: Close
[0m21:36:52.081537 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-8081-118f-a9ea-ed8a529b5e3a) - Closing
[0m21:36:52.198813 [debug] [Thread-2 (]: SQL status: OK in 1.050 seconds
[0m21:36:52.201788 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c6-8189-149e-afb9-0c359e91c043, command-id=01f089c6-81a4-1b9b-bf10-1ce61f34bf49) - Closing
[0m21:36:52.274332 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:36:52.275345 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-8189-149e-afb9-0c359e91c043) - Closing
[0m21:36:52.412748 [debug] [Thread-1 (]: SQL status: OK in 1.260 seconds
[0m21:36:52.415173 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c6-8182-1bf5-a3ce-2a010e2ae48c, command-id=01f089c6-819d-1dbc-99c1-97612cf0a0ee) - Closing
[0m21:36:52.416732 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:36:52.478128 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12396a930>]}
[0m21:36:52.478893 [debug] [Thread-1 (]: On model.flights_dbt.silver_airports: Close
[0m21:36:52.480276 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-8182-1bf5-a3ce-2a010e2ae48c) - Closing
[0m21:36:52.479873 [info ] [Thread-3 (]: 7 of 13 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.14s]
[0m21:36:52.481311 [debug] [Thread-3 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:36:52.677151 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12374adb0>]}
[0m21:36:52.676220 [info ] [Thread-2 (]: 9 of 13 PASS unique_my_first_dbt_model_flight_id ............................... [[32mPASS[0m in 1.77s]
[0m21:36:52.678914 [debug] [Thread-2 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:36:52.678336 [info ] [Thread-1 (]: 10 of 13 OK created sql view model raw.silver_airports ......................... [[32mOK[0m in 1.55s]
[0m21:36:52.679775 [debug] [Thread-1 (]: Finished running node model.flights_dbt.silver_airports
[0m21:36:52.680139 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:36:52.680698 [info ] [Thread-4 (]: 11 of 13 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:36:52.681311 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:36:52.681644 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:36:52.681936 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:36:52.685943 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:36:52.686978 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:36:52.689941 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:36:52.691048 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:36:52.691718 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:36:52.692653 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:36:52.692954 [debug] [Thread-4 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:36:52.693294 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:36:53.376316 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-826f-1286-b039-fee03b1e006b) - Created
[0m21:36:53.930299 [debug] [Thread-4 (]: SQL status: OK in 1.240 seconds
[0m21:36:53.931956 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c6-826f-1286-b039-fee03b1e006b, command-id=01f089c6-828b-1819-b3ed-aaaf8cc9d875) - Closing
[0m21:36:53.932912 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:36:53.933948 [debug] [Thread-4 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:36:53.934301 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-826f-1286-b039-fee03b1e006b) - Closing
[0m21:36:54.135125 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c8dbef2-10a2-4e3b-945a-0d8b41a948c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123caf590>]}
[0m21:36:54.136965 [info ] [Thread-4 (]: 11 of 13 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.45s]
[0m21:36:54.137853 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:36:54.138866 [debug] [Thread-3 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:36:54.139333 [debug] [Thread-2 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:36:54.139661 [info ] [Thread-3 (]: 12 of 13 START test not_null_my_second_dbt_model_flight_id ..................... [RUN]
[0m21:36:54.140237 [info ] [Thread-2 (]: 13 of 13 START test unique_my_second_dbt_model_flight_id ....................... [RUN]
[0m21:36:54.141049 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d) - Creating connection
[0m21:36:54.141787 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580) - Creating connection
[0m21:36:54.142420 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d'
[0m21:36:54.143006 [debug] [Thread-2 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580'
[0m21:36:54.143467 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:36:54.143859 [debug] [Thread-2 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:36:54.149957 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:36:54.158366 [debug] [Thread-2 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:36:54.159056 [debug] [Thread-3 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:36:54.159339 [debug] [Thread-2 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:36:54.161302 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:36:54.163077 [debug] [Thread-2 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:36:54.163485 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:36:54.163660 [debug] [Thread-2 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:36:54.163916 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:36:54.164175 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:36:54.164387 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:36:54.164568 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:36:54.850970 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-834f-1eb0-a0cf-a0a952099f2d) - Created
[0m21:36:54.882495 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-8355-1704-96c8-56200e915b6f) - Created
[0m21:36:55.167301 [debug] [Thread-3 (]: SQL status: OK in 1.000 seconds
[0m21:36:55.170530 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c6-834f-1eb0-a0cf-a0a952099f2d, command-id=01f089c6-836a-1efb-9753-215c9d7f239c) - Closing
[0m21:36:55.171429 [debug] [Thread-3 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: Close
[0m21:36:55.171806 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-834f-1eb0-a0cf-a0a952099f2d) - Closing
[0m21:36:55.236038 [debug] [Thread-2 (]: SQL status: OK in 1.070 seconds
[0m21:36:55.239111 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c6-8355-1704-96c8-56200e915b6f, command-id=01f089c6-8371-110c-a7ae-7e2f420ebf06) - Closing
[0m21:36:55.374173 [debug] [Thread-2 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: Close
[0m21:36:55.375243 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-8355-1704-96c8-56200e915b6f) - Closing
[0m21:36:55.577914 [info ] [Thread-3 (]: 12 of 13 PASS not_null_my_second_dbt_model_flight_id ........................... [[32mPASS[0m in 1.44s]
[0m21:36:55.578862 [info ] [Thread-2 (]: 13 of 13 PASS unique_my_second_dbt_model_flight_id ............................. [[32mPASS[0m in 1.44s]
[0m21:36:55.580328 [debug] [Thread-3 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:36:55.580846 [debug] [Thread-2 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:36:55.582809 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:36:55.583196 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:36:55.583723 [info ] [MainThread]: 
[0m21:36:55.584066 [info ] [MainThread]: Finished running 1 table model, 4 data tests, 8 view models in 0 hours 0 minutes and 11.38 seconds (11.38s).
[0m21:36:55.586281 [debug] [MainThread]: Command end result
[0m21:36:55.617337 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:36:55.618464 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:36:55.622026 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:36:55.622165 [info ] [MainThread]: 
[0m21:36:55.622321 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m21:36:55.622440 [info ] [MainThread]: 
[0m21:36:55.622600 [error] [MainThread]: [31mFailure in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)[0m
[0m21:36:55.622752 [error] [MainThread]:   Database Error in model gold_flight_metrics (models/gold/gold_flight_metrics.sql)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `o`.`airport_name` cannot be resolved. Did you mean one of the following? [`o`.`airport_id`, `d`.`airport_id`, `f`.`arr_time`, `f`.`airline`, `o`.`iata_code`]. SQLSTATE: 42703; line 14 pos 2
  compiled code at target/run/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:36:55.622863 [info ] [MainThread]: 
[0m21:36:55.622995 [info ] [MainThread]:   compiled code at target/compiled/flights_dbt/models/gold/gold_flight_metrics.sql
[0m21:36:55.623100 [info ] [MainThread]: 
[0m21:36:55.623225 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=13
[0m21:36:55.626378 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": false, "command_wall_clock_time": 12.461438, "process_in_blocks": "0", "process_kernel_time": 0.288403, "process_mem_max_rss": "251494400", "process_out_blocks": "0", "process_user_time": 2.905202}
[0m21:36:55.626586 [debug] [MainThread]: Command `dbt build` failed at 21:36:55.626543 after 12.46 seconds
[0m21:36:55.626765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b404d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124543f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124543a10>]}
[0m21:36:55.626913 [debug] [MainThread]: Flushing usage events
[0m21:36:56.442532 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:38:30.469328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a4f620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c2b890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c2bb10>]}


============================== 21:38:30.471692 | a318bf99-7424-465c-b5a8-f63051454e44 ==============================
[0m21:38:30.471692 [info ] [MainThread]: Running with dbt=1.10.9
[0m21:38:30.471945 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'invocation_command': 'dbt build', 'log_format': 'default', 'version_check': 'True', 'quiet': 'False', 'write_json': 'True', 'log_cache_events': 'False', 'printer_width': '80', 'log_path': '/Users/artakerqeli/flights_dbt/logs', 'target_path': 'None', 'profiles_dir': '/Users/artakerqeli/.dbt', 'partial_parse': 'True', 'no_print': 'None', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'empty': 'False', 'introspect': 'True', 'static_parser': 'True', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'fail_fast': 'False', 'cache_selected_only': 'False'}
[0m21:38:30.778468 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m21:38:30.778656 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m21:38:30.778752 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m21:38:31.219256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f57360>]}
[0m21:38:31.238667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e36ad0>]}
[0m21:38:31.238906 [info ] [MainThread]: Registered adapter: databricks=1.10.11
[0m21:38:31.287995 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m21:38:31.346223 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:38:31.346490 [debug] [MainThread]: Partial parsing: updated file: flights_dbt://models/gold/gold_flight_metrics.sql
[0m21:38:31.436022 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.flights_dbt.raw
[0m21:38:31.440798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d9a6850>]}
[0m21:38:31.474837 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:38:31.475816 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:38:31.486531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dcc7c50>]}
[0m21:38:31.486713 [info ] [MainThread]: Found 10 models, 4 data tests, 7 sources, 686 macros
[0m21:38:31.487694 [info ] [MainThread]: 
[0m21:38:31.487826 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:38:31.487914 [info ] [MainThread]: 
[0m21:38:31.488109 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:38:31.488198 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:38:31.490743 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db) - Creating connection
[0m21:38:31.490859 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db'
[0m21:38:31.495048 [debug] [ThreadPool]: Using databricks connection "list_flight_db"
[0m21:38:31.495156 [debug] [ThreadPool]: On list_flight_db: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db"} */

    show databases
  
[0m21:38:31.495239 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:38:32.196751 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c6-bd56-155c-8a1f-f0da0f070c00) - Created
[0m21:38:32.532451 [debug] [ThreadPool]: SQL status: OK in 1.040 seconds
[0m21:38:32.544113 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c6-bd56-155c-8a1f-f0da0f070c00, command-id=01f089c6-bd70-1f5a-9458-5e5856c28ead) - Closing
[0m21:38:32.544707 [debug] [ThreadPool]: On list_flight_db: Close
[0m21:38:32.544944 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c6-bd56-155c-8a1f-f0da0f070c00) - Closing
[0m21:38:32.734302 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_flight_db_raw) - Creating connection
[0m21:38:32.734943 [debug] [ThreadPool]: Acquiring new databricks connection 'list_flight_db_raw'
[0m21:38:32.749611 [debug] [ThreadPool]: Using databricks connection "list_flight_db_raw"
[0m21:38:32.750081 [debug] [ThreadPool]: On list_flight_db_raw: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "connection_name": "list_flight_db_raw"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'flight_db' 
  AND table_schema = 'raw'

  
[0m21:38:32.750355 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:38:33.413889 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c6-be10-132b-895e-f74005fe2ccf) - Created
[0m21:38:33.937451 [debug] [ThreadPool]: SQL status: OK in 1.190 seconds
[0m21:38:33.940720 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f089c6-be10-132b-895e-f74005fe2ccf, command-id=01f089c6-be2d-136a-910c-15176787a67c) - Closing
[0m21:38:33.941594 [debug] [ThreadPool]: On list_flight_db_raw: Close
[0m21:38:33.941883 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f089c6-be10-132b-895e-f74005fe2ccf) - Closing
[0m21:38:34.136152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de965f0>]}
[0m21:38:34.140674 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_first_dbt_model
[0m21:38:34.141125 [debug] [Thread-3 (]: Began running node model.flights_dbt.gold_flight_metrics
[0m21:38:34.141415 [debug] [Thread-1 (]: Began running node model.flights_dbt.bronze_airports
[0m21:38:34.141671 [debug] [Thread-2 (]: Began running node model.flights_dbt.bronze_flights
[0m21:38:34.142128 [info ] [Thread-4 (]: 4 of 13 START sql view model raw.my_first_dbt_model ............................ [RUN]
[0m21:38:34.142554 [info ] [Thread-3 (]: 3 of 13 START sql view model raw.gold_flight_metrics ........................... [RUN]
[0m21:38:34.142929 [info ] [Thread-1 (]: 1 of 13 START sql view model raw.bronze_airports ............................... [RUN]
[0m21:38:34.143292 [info ] [Thread-2 (]: 2 of 13 START sql view model raw.bronze_flights ................................ [RUN]
[0m21:38:34.143802 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_first_dbt_model) - Creating connection
[0m21:38:34.144135 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.gold_flight_metrics) - Creating connection
[0m21:38:34.144428 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_airports) - Creating connection
[0m21:38:34.144720 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.bronze_flights) - Creating connection
[0m21:38:34.144943 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_first_dbt_model'
[0m21:38:34.145158 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.gold_flight_metrics'
[0m21:38:34.145359 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_airports'
[0m21:38:34.145557 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.bronze_flights'
[0m21:38:34.145770 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_first_dbt_model
[0m21:38:34.145980 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.gold_flight_metrics
[0m21:38:34.146182 [debug] [Thread-1 (]: Began compiling node model.flights_dbt.bronze_airports
[0m21:38:34.146383 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.bronze_flights
[0m21:38:34.151493 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_first_dbt_model"
[0m21:38:34.154218 [debug] [Thread-1 (]: Writing injected SQL for node "model.flights_dbt.bronze_airports"
[0m21:38:34.156518 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.gold_flight_metrics"
[0m21:38:34.158152 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.bronze_flights"
[0m21:38:34.159079 [debug] [Thread-1 (]: Began executing node model.flights_dbt.bronze_airports
[0m21:38:34.159327 [debug] [Thread-2 (]: Began executing node model.flights_dbt.bronze_flights
[0m21:38:34.159478 [debug] [Thread-3 (]: Began executing node model.flights_dbt.gold_flight_metrics
[0m21:38:34.165215 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_first_dbt_model
[0m21:38:34.168476 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m21:38:34.169501 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:38:34.170597 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m21:38:34.171483 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:38:34.172570 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:38:34.172872 [warn ] [Thread-2 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:38:34.173140 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:38:34.173362 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m21:38:34.173566 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df31cc0>]}
[0m21:38:34.173715 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dda0dd0>]}
[0m21:38:34.173855 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dda01d0>]}
[0m21:38:34.173982 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de7a780>]}
[0m21:38:34.181751 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`bronze_flights`
[0m21:38:34.181935 [debug] [Thread-1 (]: Creating view `flight_db`.`raw`.`bronze_airports`
[0m21:38:34.182282 [debug] [Thread-3 (]: Creating view `flight_db`.`raw`.`gold_flight_metrics`
[0m21:38:34.182610 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_first_dbt_model`
[0m21:38:34.190278 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.bronze_flights"
[0m21:38:34.190635 [debug] [Thread-1 (]: Writing runtime sql for node "model.flights_dbt.bronze_airports"
[0m21:38:34.190955 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.gold_flight_metrics"
[0m21:38:34.191248 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_first_dbt_model"
[0m21:38:34.191843 [debug] [Thread-1 (]: Using databricks connection "model.flights_dbt.bronze_airports"
[0m21:38:34.191973 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.bronze_flights"
[0m21:38:34.192084 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.gold_flight_metrics"
[0m21:38:34.192216 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_airports`
  
  as (
    -- models/bronze/bronze_airports.sql
select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`airports`
  )

[0m21:38:34.192379 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.bronze_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`bronze_flights`
  
  as (
    -- models/bronze/bronze_flights.sql
select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`flights`
  )

[0m21:38:34.192515 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_first_dbt_model"
[0m21:38:34.192701 [debug] [Thread-3 (]: On model.flights_dbt.gold_flight_metrics: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.gold_flight_metrics"} */

  
  
  create or replace view `flight_db`.`raw`.`gold_flight_metrics`
  
  as (
    -- models/gold/gold_flight_metrics.sql

select
  f.airline,
  al.airline as airline_name,
  f.origin,
  o.city as origin_airport_name,
  f.destination,
  d.city as destination_airport_name,
  count(*) as flights,
  avg(coalesce(f.dep_delay, 0)) as avg_dep_delay,
  avg(coalesce(f.arr_delay, 0)) as avg_arr_delay,
  avg(case when coalesce(f.arr_delay, 0) <= 0 then 1.0 else 0.0 end) as on_time_rate
from raw.silver_flights f
left join raw.silver_airlines al on f.airline = al.airline
left join raw.silver_airports o on f.origin = o.iata_code
left join raw.silver_airports d on f.destination = d.iata_code
group by 1,2,3,4,5,6
  )

[0m21:38:34.192851 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:38:34.192973 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:38:34.193103 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_first_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_first_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:38:34.193226 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:38:34.193483 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:38:34.895708 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-bef1-1a0f-be18-7c14d258d9f9) - Created
[0m21:38:34.909545 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-bef6-131d-9a45-8312892d731a) - Created
[0m21:38:34.935650 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-bef8-1e8b-930a-ce37c40e3d40) - Created
[0m21:38:34.952468 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-befb-11f0-80bb-a51f2d821bcd) - Created
[0m21:38:35.541848 [debug] [Thread-2 (]: SQL status: OK in 1.350 seconds
[0m21:38:35.543640 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c6-bef1-1a0f-be18-7c14d258d9f9, command-id=01f089c6-bf0b-1ee3-b4c3-8b1552ae92e1) - Closing
[0m21:38:35.556907 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:38:35.561336 [debug] [Thread-2 (]: On model.flights_dbt.bronze_flights: Close
[0m21:38:35.561699 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-bef1-1a0f-be18-7c14d258d9f9) - Closing
[0m21:38:35.602548 [debug] [Thread-3 (]: SQL status: OK in 1.410 seconds
[0m21:38:35.603922 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c6-bef6-131d-9a45-8312892d731a, command-id=01f089c6-bf0f-1b91-b541-1121d79b6a63) - Closing
[0m21:38:35.604835 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:38:35.623558 [debug] [Thread-1 (]: SQL status: OK in 1.430 seconds
[0m21:38:35.624917 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c6-bef8-1e8b-930a-ce37c40e3d40, command-id=01f089c6-bf14-1668-80b9-34a2aa88416b) - Closing
[0m21:38:35.626403 [debug] [Thread-1 (]: Applying tags to relation None
[0m21:38:35.642815 [debug] [Thread-4 (]: SQL status: OK in 1.450 seconds
[0m21:38:35.644225 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c6-befb-11f0-80bb-a51f2d821bcd, command-id=01f089c6-bf16-1ca1-b83e-3385de897455) - Closing
[0m21:38:35.645140 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:38:35.749151 [debug] [Thread-3 (]: On model.flights_dbt.gold_flight_metrics: Close
[0m21:38:35.750220 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-bef6-131d-9a45-8312892d731a) - Closing
[0m21:38:35.941934 [debug] [Thread-1 (]: On model.flights_dbt.bronze_airports: Close
[0m21:38:35.943051 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-bef8-1e8b-930a-ce37c40e3d40) - Closing
[0m21:38:36.148274 [debug] [Thread-4 (]: On model.flights_dbt.my_first_dbt_model: Close
[0m21:38:36.149052 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-befb-11f0-80bb-a51f2d821bcd) - Closing
[0m21:38:36.345746 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044595d0>]}
[0m21:38:36.346333 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111226d0>]}
[0m21:38:36.346632 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df370e0>]}
[0m21:38:36.346891 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df959b0>]}
[0m21:38:36.347642 [info ] [Thread-2 (]: 2 of 13 OK created sql view model raw.bronze_flights ........................... [[32mOK[0m in 2.20s]
[0m21:38:36.348106 [info ] [Thread-4 (]: 4 of 13 OK created sql view model raw.my_first_dbt_model ....................... [[32mOK[0m in 2.20s]
[0m21:38:36.348691 [info ] [Thread-3 (]: 3 of 13 OK created sql view model raw.gold_flight_metrics ...................... [[32mOK[0m in 2.20s]
[0m21:38:36.349142 [info ] [Thread-1 (]: 1 of 13 OK created sql view model raw.bronze_airports .......................... [[32mOK[0m in 2.20s]
[0m21:38:36.349581 [debug] [Thread-2 (]: Finished running node model.flights_dbt.bronze_flights
[0m21:38:36.349962 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_first_dbt_model
[0m21:38:36.350349 [debug] [Thread-3 (]: Finished running node model.flights_dbt.gold_flight_metrics
[0m21:38:36.350856 [debug] [Thread-1 (]: Finished running node model.flights_dbt.bronze_airports
[0m21:38:36.351345 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_airlines
[0m21:38:36.351942 [debug] [Thread-4 (]: Began running node model.flights_dbt.silver_flights
[0m21:38:36.352366 [debug] [Thread-3 (]: Began running node model.flights_dbt.stg_airlines
[0m21:38:36.352929 [debug] [Thread-1 (]: Began running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:38:36.353556 [info ] [Thread-2 (]: 5 of 13 START sql view model raw.silver_airlines ............................... [RUN]
[0m21:38:36.354073 [info ] [Thread-4 (]: 6 of 13 START sql view model raw.silver_flights ................................ [RUN]
[0m21:38:36.354500 [info ] [Thread-3 (]: 7 of 13 START sql table model raw.stg_airlines ................................. [RUN]
[0m21:38:36.354917 [info ] [Thread-1 (]: 8 of 13 START test not_null_my_first_dbt_model_flight_id ....................... [RUN]
[0m21:38:36.355610 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airlines) - Creating connection
[0m21:38:36.356319 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_flights) - Creating connection
[0m21:38:36.356734 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.stg_airlines) - Creating connection
[0m21:38:36.357135 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00) - Creating connection
[0m21:38:36.357696 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airlines'
[0m21:38:36.357977 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.silver_flights'
[0m21:38:36.358243 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.flights_dbt.stg_airlines'
[0m21:38:36.358630 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00'
[0m21:38:36.358947 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_airlines
[0m21:38:36.359211 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.silver_flights
[0m21:38:36.359464 [debug] [Thread-3 (]: Began compiling node model.flights_dbt.stg_airlines
[0m21:38:36.359711 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:38:36.362402 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.silver_flights"
[0m21:38:36.366294 [debug] [Thread-3 (]: Writing injected SQL for node "model.flights_dbt.stg_airlines"
[0m21:38:36.375497 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:38:36.381013 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_airlines"
[0m21:38:36.381497 [debug] [Thread-4 (]: Began executing node model.flights_dbt.silver_flights
[0m21:38:36.381706 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_airlines
[0m21:38:36.382870 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:38:36.383915 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:38:36.384091 [debug] [Thread-3 (]: Began executing node model.flights_dbt.stg_airlines
[0m21:38:36.384270 [debug] [Thread-1 (]: Began executing node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:38:36.385031 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`silver_flights`
[0m21:38:36.385531 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_airlines`
[0m21:38:36.394505 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m21:38:36.401971 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:38:36.402339 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.silver_flights"
[0m21:38:36.402643 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_airlines"
[0m21:38:36.416099 [debug] [Thread-3 (]: Writing runtime sql for node "model.flights_dbt.stg_airlines"
[0m21:38:36.416401 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_airlines"
[0m21:38:36.416516 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"
[0m21:38:36.416629 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.silver_flights"
[0m21:38:36.416762 [debug] [Thread-2 (]: On model.flights_dbt.silver_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airlines"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airlines`
  
  as (
    select
    airline
from `flight_db`.`raw`.`bronze_airlines`
  )

[0m21:38:36.416852 [debug] [Thread-3 (]: Using databricks connection "model.flights_dbt.stg_airlines"
[0m21:38:36.416980 [debug] [Thread-1 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:38:36.417109 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_flights"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_flights`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from flight_db.raw.flights
  )

[0m21:38:36.417218 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:38:36.417336 [debug] [Thread-3 (]: On model.flights_dbt.stg_airlines: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.stg_airlines"} */

  
    
        create or replace table `flight_db`.`raw`.`stg_airlines`
      
      
  using delta
      
      
      
      
      
      
      
      as
      select
  1            as airline_id,
  'Test Air'   as airline_name
  
[0m21:38:36.417440 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:38:36.417538 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:38:36.417704 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:38:37.115051 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-c046-125c-b320-f1822f2a9b18) - Created
[0m21:38:37.136219 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-c047-1fbb-b8d9-621399f1e60b) - Created
[0m21:38:37.171492 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-c04d-1272-a88b-cbb8d890e179) - Created
[0m21:38:37.173980 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-c04d-1cd6-a2f3-5e0f8f747a45) - Created
[0m21:38:37.515150 [debug] [Thread-1 (]: SQL status: OK in 1.100 seconds
[0m21:38:37.520161 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c6-c04d-1272-a88b-cbb8d890e179, command-id=01f089c6-c069-1730-bdf2-0639c4965e85) - Closing
[0m21:38:37.522537 [debug] [Thread-1 (]: On test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00: Close
[0m21:38:37.522826 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-c04d-1272-a88b-cbb8d890e179) - Closing
[0m21:38:37.711555 [info ] [Thread-1 (]: 8 of 13 PASS not_null_my_first_dbt_model_flight_id ............................. [[32mPASS[0m in 1.35s]
[0m21:38:37.712993 [debug] [Thread-1 (]: Finished running node test.flights_dbt.not_null_my_first_dbt_model_flight_id.42d41aed00
[0m21:38:37.713712 [debug] [Thread-1 (]: Began running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:38:37.714222 [info ] [Thread-1 (]: 9 of 13 START test unique_my_first_dbt_model_flight_id ......................... [RUN]
[0m21:38:37.714994 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8) - Creating connection
[0m21:38:37.715420 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8'
[0m21:38:37.715767 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:38:37.725370 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:38:37.727924 [debug] [Thread-2 (]: SQL status: OK in 1.310 seconds
[0m21:38:37.728963 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c6-c046-125c-b320-f1822f2a9b18, command-id=01f089c6-c05f-1087-823a-efb5746a48a3) - Closing
[0m21:38:37.729794 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:38:37.730540 [debug] [Thread-2 (]: On model.flights_dbt.silver_airlines: Close
[0m21:38:37.730876 [debug] [Thread-1 (]: Began executing node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:38:37.731227 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-c046-125c-b320-f1822f2a9b18) - Closing
[0m21:38:37.735714 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:38:37.741715 [debug] [Thread-4 (]: SQL status: OK in 1.320 seconds
[0m21:38:37.742489 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c6-c047-1fbb-b8d9-621399f1e60b, command-id=01f089c6-c063-1404-b856-5b982643daa7) - Closing
[0m21:38:37.742972 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:38:37.919893 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"
[0m21:38:37.920897 [debug] [Thread-4 (]: On model.flights_dbt.silver_flights: Close
[0m21:38:37.921326 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_first_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:38:37.921779 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-c047-1fbb-b8d9-621399f1e60b) - Closing
[0m21:38:37.922110 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:38:38.124392 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df5bb30>]}
[0m21:38:38.124821 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111ba810>]}
[0m21:38:38.125467 [info ] [Thread-2 (]: 5 of 13 OK created sql view model raw.silver_airlines .......................... [[32mOK[0m in 1.77s]
[0m21:38:38.126321 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_airlines
[0m21:38:38.125907 [info ] [Thread-4 (]: 6 of 13 OK created sql view model raw.silver_flights ........................... [[32mOK[0m in 1.77s]
[0m21:38:38.126684 [debug] [Thread-2 (]: Began running node model.flights_dbt.silver_airports
[0m21:38:38.127079 [debug] [Thread-4 (]: Finished running node model.flights_dbt.silver_flights
[0m21:38:38.127399 [info ] [Thread-2 (]: 10 of 13 START sql view model raw.silver_airports .............................. [RUN]
[0m21:38:38.127898 [debug] [Thread-2 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.silver_airports) - Creating connection
[0m21:38:38.128140 [debug] [Thread-2 (]: Acquiring new databricks connection 'model.flights_dbt.silver_airports'
[0m21:38:38.128358 [debug] [Thread-2 (]: Began compiling node model.flights_dbt.silver_airports
[0m21:38:38.130682 [debug] [Thread-2 (]: Writing injected SQL for node "model.flights_dbt.silver_airports"
[0m21:38:38.131252 [debug] [Thread-2 (]: Began executing node model.flights_dbt.silver_airports
[0m21:38:38.138574 [debug] [Thread-2 (]: MATERIALIZING VIEW
[0m21:38:38.139306 [debug] [Thread-2 (]: Creating view `flight_db`.`raw`.`silver_airports`
[0m21:38:38.139756 [debug] [Thread-2 (]: Writing runtime sql for node "model.flights_dbt.silver_airports"
[0m21:38:38.140200 [debug] [Thread-2 (]: Using databricks connection "model.flights_dbt.silver_airports"
[0m21:38:38.140400 [debug] [Thread-2 (]: On model.flights_dbt.silver_airports: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.silver_airports"} */

  
  
  create or replace view `flight_db`.`raw`.`silver_airports`
  
  as (
    select
    airport_id,
    iata_code,
    city,
    state,
    country
from `flight_db`.`raw`.`bronze_airports`
  )

[0m21:38:38.140576 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m21:38:38.606287 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-c129-121b-9012-65d3b6335e8a) - Created
[0m21:38:38.816511 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-c149-17d5-96c4-d6b08107fad0) - Created
[0m21:38:39.130513 [debug] [Thread-1 (]: SQL status: OK in 1.210 seconds
[0m21:38:39.133940 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c6-c129-121b-9012-65d3b6335e8a, command-id=01f089c6-c144-1a31-b35e-fee8c30951c1) - Closing
[0m21:38:39.135057 [debug] [Thread-1 (]: On test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8: Close
[0m21:38:39.135502 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-c129-121b-9012-65d3b6335e8a) - Closing
[0m21:38:39.263033 [debug] [Thread-3 (]: SQL status: OK in 2.840 seconds
[0m21:38:39.264703 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c6-c04d-1cd6-a2f3-5e0f8f747a45, command-id=01f089c6-c069-1282-9064-a5c2ff3f49bd) - Closing
[0m21:38:39.269106 [debug] [Thread-3 (]: Applying tags to relation None
[0m21:38:39.339146 [debug] [Thread-3 (]: On model.flights_dbt.stg_airlines: Close
[0m21:38:39.339723 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-c04d-1cd6-a2f3-5e0f8f747a45) - Closing
[0m21:38:39.495462 [debug] [Thread-2 (]: SQL status: OK in 1.350 seconds
[0m21:38:39.498025 [debug] [Thread-2 (]: Databricks adapter: Cursor(session-id=01f089c6-c149-17d5-96c4-d6b08107fad0, command-id=01f089c6-c164-1417-9cad-6877e63ad9d1) - Closing
[0m21:38:39.499188 [debug] [Thread-2 (]: Applying tags to relation None
[0m21:38:39.532369 [debug] [Thread-2 (]: On model.flights_dbt.silver_airports: Close
[0m21:38:39.531983 [info ] [Thread-1 (]: 9 of 13 PASS unique_my_first_dbt_model_flight_id ............................... [[32mPASS[0m in 1.82s]
[0m21:38:39.532881 [debug] [Thread-2 (]: Databricks adapter: Connection(session-id=01f089c6-c149-17d5-96c4-d6b08107fad0) - Closing
[0m21:38:39.533407 [debug] [Thread-1 (]: Finished running node test.flights_dbt.unique_my_first_dbt_model_flight_id.bf2f32ffd8
[0m21:38:39.534564 [debug] [Thread-4 (]: Began running node model.flights_dbt.my_second_dbt_model
[0m21:38:39.535059 [info ] [Thread-4 (]: 11 of 13 START sql view model raw.my_second_dbt_model .......................... [RUN]
[0m21:38:39.718618 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df5b470>]}
[0m21:38:39.719764 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.flights_dbt.my_second_dbt_model) - Creating connection
[0m21:38:39.720456 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df5b830>]}
[0m21:38:39.721738 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.flights_dbt.my_second_dbt_model'
[0m21:38:39.721369 [info ] [Thread-3 (]: 7 of 13 OK created sql table model raw.stg_airlines ............................ [[32mOK[0m in 3.36s]
[0m21:38:39.722870 [debug] [Thread-4 (]: Began compiling node model.flights_dbt.my_second_dbt_model
[0m21:38:39.722538 [info ] [Thread-2 (]: 10 of 13 OK created sql view model raw.silver_airports ......................... [[32mOK[0m in 1.59s]
[0m21:38:39.723436 [debug] [Thread-3 (]: Finished running node model.flights_dbt.stg_airlines
[0m21:38:39.725843 [debug] [Thread-2 (]: Finished running node model.flights_dbt.silver_airports
[0m21:38:39.731790 [debug] [Thread-4 (]: Writing injected SQL for node "model.flights_dbt.my_second_dbt_model"
[0m21:38:39.733893 [debug] [Thread-4 (]: Began executing node model.flights_dbt.my_second_dbt_model
[0m21:38:39.736031 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m21:38:39.737271 [debug] [Thread-4 (]: Creating view `flight_db`.`raw`.`my_second_dbt_model`
[0m21:38:39.738042 [debug] [Thread-4 (]: Writing runtime sql for node "model.flights_dbt.my_second_dbt_model"
[0m21:38:39.739131 [debug] [Thread-4 (]: Using databricks connection "model.flights_dbt.my_second_dbt_model"
[0m21:38:39.739570 [debug] [Thread-4 (]: On model.flights_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "model.flights_dbt.my_second_dbt_model"} */

  
  
  create or replace view `flight_db`.`raw`.`my_second_dbt_model`
  
  as (
    select
    flight_id,
    airline,
    origin,
    destination,
    dep_delay,
    arr_delay,
    arr_time
from `flight_db`.`raw`.`my_first_dbt_model`
  )

[0m21:38:39.739902 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:38:40.380798 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-c236-18b6-9fe0-9dbe4cb09488) - Created
[0m21:38:40.945810 [debug] [Thread-4 (]: SQL status: OK in 1.210 seconds
[0m21:38:40.947371 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f089c6-c236-18b6-9fe0-9dbe4cb09488, command-id=01f089c6-c252-1a80-aa4d-9434674de96a) - Closing
[0m21:38:40.948337 [debug] [Thread-4 (]: Applying tags to relation None
[0m21:38:40.949357 [debug] [Thread-4 (]: On model.flights_dbt.my_second_dbt_model: Close
[0m21:38:40.949707 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f089c6-c236-18b6-9fe0-9dbe4cb09488) - Closing
[0m21:38:41.146220 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a318bf99-7424-465c-b5a8-f63051454e44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df594f0>]}
[0m21:38:41.147547 [info ] [Thread-4 (]: 11 of 13 OK created sql view model raw.my_second_dbt_model ..................... [[32mOK[0m in 1.61s]
[0m21:38:41.148246 [debug] [Thread-4 (]: Finished running node model.flights_dbt.my_second_dbt_model
[0m21:38:41.149264 [debug] [Thread-1 (]: Began running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:38:41.149682 [debug] [Thread-3 (]: Began running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:38:41.150011 [info ] [Thread-1 (]: 12 of 13 START test not_null_my_second_dbt_model_flight_id ..................... [RUN]
[0m21:38:41.150423 [info ] [Thread-3 (]: 13 of 13 START test unique_my_second_dbt_model_flight_id ....................... [RUN]
[0m21:38:41.151121 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d) - Creating connection
[0m21:38:41.151635 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580) - Creating connection
[0m21:38:41.151968 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d'
[0m21:38:41.152258 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580'
[0m21:38:41.152551 [debug] [Thread-1 (]: Began compiling node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:38:41.152824 [debug] [Thread-3 (]: Began compiling node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:38:41.160601 [debug] [Thread-3 (]: Writing injected SQL for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:38:41.166990 [debug] [Thread-1 (]: Writing injected SQL for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:38:41.168875 [debug] [Thread-3 (]: Began executing node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:38:41.169149 [debug] [Thread-1 (]: Began executing node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:38:41.171120 [debug] [Thread-3 (]: Writing runtime sql for node "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:38:41.173270 [debug] [Thread-1 (]: Writing runtime sql for node "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:38:41.173746 [debug] [Thread-3 (]: Using databricks connection "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"
[0m21:38:41.173987 [debug] [Thread-1 (]: Using databricks connection "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"
[0m21:38:41.174303 [debug] [Thread-3 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    flight_id as unique_field,
    count(*) as n_records

from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is not null
group by flight_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m21:38:41.174577 [debug] [Thread-1 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: /* {"app": "dbt", "dbt_version": "1.10.9", "dbt_databricks_version": "1.10.11", "databricks_sql_connector_version": "4.0.5", "profile_name": "flights_dbt", "target_name": "dev", "node_id": "test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select flight_id
from `flight_db`.`raw`.`my_second_dbt_model`
where flight_id is null



  
  
      
    ) dbt_internal_test
[0m21:38:41.174803 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:38:41.174995 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m21:38:41.881128 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-c31d-1b29-9c65-41adcf0e2b7b) - Created
[0m21:38:41.891128 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-c31e-171d-a0da-8e35913014c1) - Created
[0m21:38:42.204916 [debug] [Thread-1 (]: SQL status: OK in 1.030 seconds
[0m21:38:42.208292 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f089c6-c31d-1b29-9c65-41adcf0e2b7b, command-id=01f089c6-c338-1083-afe4-96e9a9d971d0) - Closing
[0m21:38:42.209262 [debug] [Thread-1 (]: On test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d: Close
[0m21:38:42.209651 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f089c6-c31d-1b29-9c65-41adcf0e2b7b) - Closing
[0m21:38:42.216798 [debug] [Thread-3 (]: SQL status: OK in 1.040 seconds
[0m21:38:42.219000 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f089c6-c31e-171d-a0da-8e35913014c1, command-id=01f089c6-c339-1633-bc8f-c4aa416d2844) - Closing
[0m21:38:42.410340 [debug] [Thread-3 (]: On test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580: Close
[0m21:38:42.411410 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f089c6-c31e-171d-a0da-8e35913014c1) - Closing
[0m21:38:42.608759 [info ] [Thread-1 (]: 12 of 13 PASS not_null_my_second_dbt_model_flight_id ........................... [[32mPASS[0m in 1.46s]
[0m21:38:42.609722 [info ] [Thread-3 (]: 13 of 13 PASS unique_my_second_dbt_model_flight_id ............................. [[32mPASS[0m in 1.46s]
[0m21:38:42.610800 [debug] [Thread-1 (]: Finished running node test.flights_dbt.not_null_my_second_dbt_model_flight_id.718e911b9d
[0m21:38:42.611360 [debug] [Thread-3 (]: Finished running node test.flights_dbt.unique_my_second_dbt_model_flight_id.80fe921580
[0m21:38:42.613344 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m21:38:42.613703 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m21:38:42.614240 [info ] [MainThread]: 
[0m21:38:42.614571 [info ] [MainThread]: Finished running 1 table model, 4 data tests, 8 view models in 0 hours 0 minutes and 11.13 seconds (11.13s).
[0m21:38:42.616843 [debug] [MainThread]: Command end result
[0m21:38:42.649094 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/artakerqeli/flights_dbt/target/manifest.json
[0m21:38:42.650958 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/artakerqeli/flights_dbt/target/semantic_manifest.json
[0m21:38:42.655357 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/artakerqeli/flights_dbt/target/run_results.json
[0m21:38:42.655509 [info ] [MainThread]: 
[0m21:38:42.655682 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:38:42.655816 [info ] [MainThread]: 
[0m21:38:42.655970 [info ] [MainThread]: Done. PASS=13 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=13
[0m21:38:42.659759 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 12.220951, "process_in_blocks": "0", "process_kernel_time": 0.285488, "process_mem_max_rss": "244006912", "process_out_blocks": "0", "process_user_time": 3.007839}
[0m21:38:42.660018 [debug] [MainThread]: Command `dbt build` succeeded at 21:38:42.659971 after 12.22 seconds
[0m21:38:42.660277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a6c4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111bbad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111bb890>]}
[0m21:38:42.660466 [debug] [MainThread]: Flushing usage events
[0m21:38:43.454277 [debug] [MainThread]: An error was encountered while trying to flush usage events
